{
    "abstractText": "Erlang implements a message-passing execution model in which concurrent processes send each other messages asynchronously. This model is inherently non-deterministic: a process can receive messages sent by any process which knows its process identifier, leading to an exponential number of possible executions based on the number messages received. Concurrent programs in nondeterministic languages are notoriously hard to prove correct and have led to well-known disasters. Furthermore, Erlang natively provides distribution and process clustering. This enables processes to asynchronously communicate between different virtual machines across the network, which increases the potential non-determinism. We propose a new execution model for Erlang, \u201cDeterministic Dataflow Programming\u201d, based on a highly available, scalable single-assignment data store implemented on top of the riak core distributed systems framework. This execution model provides concurrent communication between Erlang processes, yet has no observable non-determinism. Given the same input values, a deterministic dataflow program will always return the same output values, or never return; liveness under failures is sacrificed to ensure safety. Our proposal provides a distributed deterministic dataflow solution that operates transparently over distributed Erlang, providing the ability to have highly-available, fault-tolerant, deterministic computations.",
    "authors": [
        {
            "affiliations": [],
            "name": "Manuel Bravo"
        },
        {
            "affiliations": [],
            "name": "Zhongmiao Li"
        },
        {
            "affiliations": [],
            "name": "Peter Van Roy"
        },
        {
            "affiliations": [],
            "name": "Christopher Meiklejohn"
        }
    ],
    "id": "SP:07b5a0f2a3ff9d28ee4090a9bc35535c76925f72",
    "references": [
        {
            "authors": [
                "P. Abdulla",
                "S. Aronis",
                "B. Jonsson",
                "K. Sagonas"
            ],
            "title": "Optimal dynamic partial order reduction",
            "venue": "In Proceedings of the 41st ACM SIGPLAN- SIGACT Symposium on Principles of Programming Languages,",
            "year": 2014
        },
        {
            "authors": [
                "R. Collet"
            ],
            "title": "The Limits of Network Transparency in a Distributed Programming Language",
            "venue": "PhD thesis, Universite\u0301 catholique de Louvain, Louvain-la-Neuve,",
            "year": 2007
        },
        {
            "authors": [
                "J. Dean",
                "S. Ghemawat"
            ],
            "title": "Mapreduce: Simplified data processing on large clusters",
            "venue": "In Proceedings of the 6th Conference on Symposium on Opearting Systems Design & Implementation - Volume 6,",
            "year": 2004
        },
        {
            "authors": [
                "G. DeCandia",
                "D. Hastorun",
                "M. Jampani",
                "G. Kakulapati",
                "A. Lakshman",
                "A. Pilchin",
                "S. Sivasubramanian",
                "P. Vosshall",
                "W. Vogels"
            ],
            "title": "Dynamo: Amazon\u2019s highly available key-value store",
            "venue": "In Proceedings of Twenty-first ACM SIGOPS Symposium on Operating Systems Principles,",
            "year": 2007
        },
        {
            "authors": [
                "S. Doeraene",
                "P. Van Roy"
            ],
            "title": "A new concurrency model for Scala based on a declarative dataflow core",
            "venue": "In Proceedings of the 4th Workshop on Scala,",
            "year": 2013
        },
        {
            "authors": [
                "C. Hewitt",
                "P. Bishop",
                "R. Steiger"
            ],
            "title": "A universal modular actor formalism for artificial intelligence",
            "venue": "In Proceedings of the 3rd International Joint Conference on Artificial Intelligence,",
            "year": 1973
        },
        {
            "authors": [
                "C.A.R. Hoare"
            ],
            "title": "Monitors: An operating system structuring concept",
            "venue": "Commun. ACM,",
            "year": 1974
        },
        {
            "authors": [
                "Joel Reymont"
            ],
            "title": "erlang-questions] is there an elephant in the room? mnesia network partition. http://erlang.org/pipermail/ erlang-questions/2008-November/039537.html",
            "year": 2008
        },
        {
            "authors": [
                "G. Kahn"
            ],
            "title": "The semantics of a simple language for parallel programming",
            "venue": "Proceedings of the IFIP Congress,",
            "year": 1974
        },
        {
            "authors": [
                "G. Kahn",
                "D. MacQueen"
            ],
            "title": "Coroutines and networks of parallel processes",
            "venue": "In Proc. of the IFIP Congress,",
            "year": 1977
        },
        {
            "authors": [
                "L. Kuper",
                "R.R. Newton"
            ],
            "title": "Lvars: Lattice-based data structures for deterministic parallelism",
            "venue": "In Proceedings of the 2Nd ACM SIG- PLAN Workshop on Functional High-performance Computing,",
            "year": 2013
        },
        {
            "authors": [
                "S. Lu",
                "S. Park",
                "E. Seo",
                "Y. Zhou"
            ],
            "title": "Learning from mistakes: A comprehensive study on real world concurrency bug characteristics",
            "venue": "In Proceedings of the 13th International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS XIII,",
            "year": 2008
        },
        {
            "authors": [
                "N.M. Pregui\u00e7a",
                "C. Baquero",
                "P.S. Almeida",
                "V. Fonte",
                "R. Gon\u00e7alves"
            ],
            "title": "Dotted version vectors: Logical clocks for optimistic replication",
            "venue": "CoRR, abs/1011.5808,",
            "year": 2010
        },
        {
            "authors": [
                "M. Shapiro",
                "N. Pregui\u00e7a",
                "C. Baquero",
                "M. Zawirski"
            ],
            "title": "Conflictfree replicated data types",
            "year": 2011
        },
        {
            "authors": [
                "H. Svensson",
                "L.-A. Fredlund"
            ],
            "title": "Programming distributed erlang applications: Pitfalls and recipes",
            "venue": "In Proceedings of the 2007 SIGPLAN Workshop on ERLANG Workshop,",
            "year": 2007
        },
        {
            "authors": [
                "P. Van Roy",
                "S. Haridi"
            ],
            "title": "Concepts, techniques, and models of computer programming",
            "venue": "MIT press,",
            "year": 2004
        },
        {
            "authors": [
                "D. Wyatt"
            ],
            "title": "Akka concurrency: Building reliable software in a multicore world",
            "venue": "Artima,",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "Furthermore, Erlang natively provides distribution and process clustering. This enables processes to asynchronously communicate between different virtual machines across the network, which increases the potential non-determinism.\nWe propose a new execution model for Erlang, \u201cDeterministic Dataflow Programming\u201d, based on a highly available, scalable single-assignment data store implemented on top of the riak core distributed systems framework. This execution model provides concurrent communication between Erlang processes, yet has no observable non-determinism. Given the same input values, a deterministic dataflow program will always return the same output values, or never return; liveness under failures is sacrificed to ensure safety. Our proposal provides a distributed deterministic dataflow solution that operates transparently over distributed Erlang, providing the ability to have highly-available, fault-tolerant, deterministic computations.\nCategories and Subject Descriptors D.1.3 [Programming Techniques]: Concurrent Programming\nKeywords Dynamo; Erlang; Riak"
        },
        {
            "heading": "1. Introduction",
            "text": "Erlang implements a message-passing execution model in which concurrent processes send each other asynchronous messages. This\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Erlang \u201914, September 5, 2014, Gothenburg, Sweden. Copyright c\u00a9 2014 ACM 978-1-4503-3038-1/14/09. . . $15.00. http://dx.doi.org/10.1145/http://dx.doi.org/10.1145/2633448.2633451\nmodel is inherently non-deterministic, in that a process can receive messages sent by any process which knows its process identifier, leading to an exponential number of possible executions based on the number of messages received. Concurrent programs in nondeterministic languages, are notoriously hard to prove correct, and have lead to many well-known disasters. [15]\nWhen reasoning about the correctness of our programs, we treat every message received by a process as a \u2018choice\u2019. A series of these \u2018choices\u2019 define one execution of a program. Given this, to prove a program is correct requires proving that each of these executions are correct; that is, for each execution all possible inputs are able to be processed resulting in termination. While there is work underway on making this approach more viable [2], we believe that limiting the ability to write non-deterministic code provides a reasonable alternative to exhaustively checking our applications for correctness.\nIn addition, Erlang natively provides distribution and clustering as part of the runtime environment. This provides the ability to have processes asynchronously communicate across the network between different instances of the virtual machine. When using asynchronous communication across the network, one can provide even fewer guarantees regarding message delivery and reordering [18]. Erlang, in an effort to solve both of these problems, uses programming patterns and libraries (e.g. OTP) that are designed to reduce the number of choices and to maintain invariants for the remaining choices.\nWe propose a new execution model for Erlang, namely deterministic dataflow programming. This execution model provides concurrency, while also eliminating all observable nondeterminism. Given the same input values, a program written in deterministic dataflow style will always return the same output values, or never return. These input values can be data streams as well, which is a natural generalization of functional programming to the concurrent setting. Our proposed solution provides a distributed deterministic dataflow solution which operates transparently over distributed Erlang, providing the ability to have highly-available, fault-tolerant, deterministic computations.\nThe major contributions of this paper are the following:\n\u2022 Prototype implementation of a deterministic dataflow extension to Erlang called Derflow, with examples of its usage for common computations.\n\u2022 Transparent distribution of computations, through the usage of the Dynamo-inspired [6] distributed systems framework, riak core. [3].\nThe remainder of this paper is organized as follows: Section 2 introduces background material related to distributed dataflow programming and the riak core distribution model; Section 3 describes the semantics of Derflow; Section 4 discusses the implementation challenges; Section 5 discusses a few application of Derflow; then, Section 6 discusses integration with non-determinism; finally, Section 7 discusses future work and concludes the paper."
        },
        {
            "heading": "2. Background",
            "text": "The following subsections provide background on Dynamo, the riak core library, and deterministic dataflow programming."
        },
        {
            "heading": "2.1 Dynamo",
            "text": "Consistent hashing, hash-space partitioning and a configurable data replication factor are the concepts critical for understanding riak core\u2019s implementation of the Dynamo mode. We discuss in Section 4.2 how Derflow is built on top of riak core."
        },
        {
            "heading": "2.1.1 Consistent Hashing",
            "text": "The Amazon Dynamo paper describes a key-value based storage system made up of a cluster of nodes, where every node in the cluster stores some subset of the total data. To distribute this data, a consistent hashing algorithm applied to the data\u2019s key is then used to determine a token in the hash-space for where this data should be distributed."
        },
        {
            "heading": "2.1.2 Hash-Space Partitioning",
            "text": "The entirety of the hash space is then evenly divided between the nodes. Each even portion of the hash space is called a partition, and each partition is managed by a virtual node. Each physical node in the cluster hosts a number of virtual nodes, one for each partition assigned to that physical node. The hash resulting from running a key through the consistent hashing algorithm determines which partition is responsible for storing the data associated with that key."
        },
        {
            "heading": "2.1.3 Replication Factor",
            "text": "Dynamo replicates data on consecutive partitions. The replication factorN determines the number of replicas. When a key is mapped to a particular partition in the hash-space, the (N \u2212 1) consecutive partitions are used to store replicas of the data. This collection of partitions is called the preference list or primaries."
        },
        {
            "heading": "2.1.4 Dynamic Cluster Membership",
            "text": "As the cluster grows and shrinks, partitions are redistributed to nodes, minimizing the amount of partitions that have to move between nodes to cut down on data transfer between nodes. This is a property of the consistent hashing algorithm described in section 2.1.1."
        },
        {
            "heading": "2.2 Deterministic dataflow programming",
            "text": "Deterministic dataflow was first proposed by Gilles Kahn in 1974, in a programming model that is now known as Kahn networks [12]. In 1977, a lazy version of this same model was proposed by Kahn and David MacQueen [13]. However, up until recently this model has never become part of mainstream concurrent programming. This may be due to either the model\u2019s inability to express nondeterminism or the simultaneous invention of two other models for handling concurrent programming: the actor model (message passing) and monitors (shared state) [9, 10].\nHowever, deterministic dataflow is now becoming a more important model in mainstream programming due to the increasing prominence of parallel computing, both in distributed computing and in multicore processors. Recent examples include the Oz deterministic dataflow execution model [19], the Akka library for concurrent and distributed programming in Scala [1, 20], and Ozma, which is a Scala language extension that adds deterministic dataflow [7]."
        },
        {
            "heading": "3. Semantics of Derflow",
            "text": "This section presents the semantics of Derflow in four subsections. First, we focus on the primitive semantics which support deterministic dataflow; then, we introduce data streams, a programming technique that enriches deterministic dataflow. Then, we discuss a lazy execution extension. Finally, we discuss issues of failure handling."
        },
        {
            "heading": "3.1 Deterministic dataflow",
            "text": "The deterministic dataflow model uses a single-assignment store. This store is shared through all the processes that participate in the deterministic dataflow program. We represent the singleassignment store as: \u03c3 = {x1, . . . , xn} where xi represents a variable declared in \u03c3. The stored variables are called dataflow variables. Dataflow variables are assigned to dataflow values. A dataflow value is either an Erlang term or a previously declared dataflow variable.\nContrary to Erlang variables, a dataflow variable is allowed to be unbound. Thus, the possible states of a dataflow variable are the following: unbound, bound to a term, partially bound. The former is the initial state of a dataflow variable after is created. After the initial state, the dataflow variable can be either assigned to an Erlang term or to another dataflow variable. If the dataflow variable is assigned to another dataflow variable, we say that the variable is partially bound if the second dataflow variable is unbound. Figure 1 diagrams the states that a dataflow variable can visit.\nTherefore, the following single-assignment dataflow store is consistent with the previous definitions: \u03c3 = {x1 = x2, x2 = \u2205, x3 = 5, x4 = [a, b, c], . . . , xn = 9} where x1 is bound to another dataflow variable (x2), therefore, partially bound; x2 is unbound and x3; x4 and xn are bound to terms.\nDuring the rest of the section, we use the following notation to specify the state of a dataflow variable:\n\u2022 xi = \u2205: Variable xi is unbound. \u2022 xi = xm: Variable xi is partially bound; therefore, it is as-\nsigned to another dataflow variable (xm). This also implies that xm is unbound.\n\u2022 xi = vi: Variable xi is bound to a term (vi).\n\u2022 if xi does not appear assigned to anything, it means it is not relevant to which kind of value is assigned.\nEach dataflow variable has to keep some extra information in order to implement the primitive operations on which deterministic dataflow relies. A dataflow variable is composed as follows: xi = {value, bound variables, waiting processes} where value is either empty or a dataflow value, bound variables is a set of dataflow variables that are partially bound to xi, and waiting processes is a set of processes waiting for xi to be bound. The set of waiting processes is used by the read and the bind primitive operations later described.\nThe deterministic dataflow model is an extension of the functional programming model with concurrency, dataflow variables and synchronization on them. The model then guarantees that under a particular input, a deterministic dataflow program will always produce the same result. It is well known that determinism is a desired property that simplifies the development of applications.\nWe now look at which primitives are required to transform a functional program into a deterministic dataflow program. The following primitives we aim to provide are: declare(), bind(x, v) and read(x). declare() creates a new dataflow variable into the singleassignment store. The operation returns the identifier of the newly created dataflow variable. More precisely, this operation can be expressed as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xn} \u2022 xn+1 = declare()\ncreate a unique dataflow variable xn+1 store xn+1 into \u03c3\n\u2022 After: \u03c3 = {x1, . . . , xn+1 = \u2205}\nbind(xi, vi) binds the dataflow variable xi to the value vi. More precisely, this operation can be expressed as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xi = \u2205, . . . , xn} \u2022 bind(xi, vi)\n\u2200p \u2208 xi.waiting processes, notify p \u2200x \u2208 xi.bound variables, bind(x, vi) xi.value = vi\n\u2022 After: \u03c3 = {x1, . . . , xi = vi, . . . , xn}\nIn case the program binds xi to another dataflow variable (bind(xi, xw)), xi become equivalent to xw. Thus, xi will be bound to the same term than xw when xw becomes bound (in case it was not bound when bind(xi, xw) was issued). Binding xi with the same value for several times introduces no side effect, i.e. it is idempotent. On the other hand, if xi was already bound to the term vw and vi do not match vw, the execution of the deterministic dataflow program terminates due to a programming error.\nread(xi) returns the term bound to xi. More precisely, this operation can be expressed as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xi, . . . , xn} \u2022 vi = read(xi)\nif xi.value == (xm \u2228\u2205) \u2212 xi.waiting processes \u222a {self()} \u2212 wait until xi is bound vi = xi.value\n\u2022 After: \u03c3 = {x1, . . . , xi = vi, . . . , xn}\nFinally, Derflow uses the Erlang spawn primitive to add concurrency to the deterministic dataflow model, a fundamental feature of the deterministic dataflow model. Furthermore, useful properties such as transparent concurrency are added. Section 5 shows why transparency concurrency is a desirable property and how programmer can use it."
        },
        {
            "heading": "3.2 Streams",
            "text": "Streams are a useful technique which allow threads, or processes, to communicate and synchronize in concurrent programming. A stream is represented here as a list of dataflow variables, with an unbound dataflow variable as the final element of the list. For instance, a stream variable can be expressed as the following: si = x1 | . . . | xn\u22121 | xn, xn = \u2205 where x1, . . . , xn\u22121 are dataflow variables either bound or partially bound, and xn is an unbound dataflow variable. In order to add streams to Derflow, we extended the metadata kept by a dataflow variable with a new parameter called next. This new parameter stores the id of the dataflow variable that represents the successor element in the stream. Thus, a dataflow variable is now composed as follows: xi = {value, bound variables, waiting processes, next} There are two basic operations applicable to a stream: produce(x, v) and consume(x). produce(xn, vn) extends the stream by binding the tail xn to vn and creating a new tail xn+1. It returns the new tail. More precisely, this operation can be expressed as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xn = \u2205} \u2022 xn+1 = produce(xn, vn)\nbind(xn, vn)\nxn+1 = declare()\nxn.next = xn+1\n\u2022 After: \u03c3 = {x1, . . . , xn = vn, xn+1 = \u2205}\nconsume(xi) reads the element of the stream represented by xi. It returns the read value (vi) and the identifier of the next element in the stream (xi+1). More precisely, this operation can be expressed as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xi = vi \u2228 xm \u2228\u2205, xi+1, . . . , xn} \u2022 {vi, xi+1} = consume(xi)\nvi = read(xi)\nxi+1 = xi.next\n\u2022 After: \u03c3 = {x1, . . . , xi = vi, xi+1, . . . , xn}\nDifferent processes can read from the stream simultaneously. This do not compromise determinism. Nevertheless, the number of producers is restricted to one in order to keep determinism."
        },
        {
            "heading": "3.3 Laziness",
            "text": "Lazy, non-strict evaluation, or demand-driven execution, delays the evaluation of an expression until the value is needed somewhere else in the program. Lazy execution can improve the performance of programs by avoiding unnecessary computation. Lazy execution also enables the possibility of creating potentially infinite data structures, e.g. infinite lists and infinite trees, since each element will only be created when it is needed by the program.\nThe intuition of lazy evaluation is simple: a process that wants to assign a lazy variable to a value will be suspended until the value is needed by other process.\nThe only primitive we need to add is wait needed(x). This operation suspends the caller process until the dataflow variable\nx is needed. As a consequence of this new primitive, the metadata kept by the dataflow variable has to be extended once more. A new parameter called lazy is added to the metadata. lazy is the set of the processes that called wait needed(x) for the variable x. The dataflow variable is now composed as follows: xi = {value, bound variables, waiting processes, next, lazy} More precisely, the wait needed(x) primitive can be expressed as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xi = \u2205, . . . , xn} \u2022 wait needed(xi)\nif xi.waiting processes == \u2205 \u2212 xi.lazy \u222a {self()} \u2212 wait until a read(xi) is issued\n\u2022 After: \u03c3 = {x1, . . . , xi, . . . , xn}\nIn case xi was already bound, wait needed(x) returns immediately.\nFurthermore, the primitive read(x) has to be changed to notify the processes that called wait needed(x) . More precisely, the new read(x) primitive can be expressed as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xi, . . . , xn} \u2022 vi = read(xi)\n\u2200p \u2208 xi.lazy, notify p if xi.value == (xm \u2228\u2205) \u2212 xi.waiting processes \u222a {self()} \u2212 wait until xi is bound vi = xi.value\n\u2022 After: \u03c3 = {x1, . . . , xi = vi, . . . , xn}"
        },
        {
            "heading": "3.4 Failure handling",
            "text": "Failures introduce non-determinism. Therefore, a deterministic program can easily become non-deterministic if care is not taken to handle failures in a deterministic manner.\nOne simple approach to ensure determinism in the presence of failures is to force processes to wait forever if a dataflow variable is either unbound or not reachable. Obviously, this approach does not ensure progress. Consider the following example:\n\u2022 Process p0 is supposed to bind a dataflow variable, however fails before completing its task.\n\u2022 Processes p1 . . . pn are waiting on p0 to bind. \u2022 Processes p1 . . . pn wait forever, resulting in non-termination.\nHowever, determinism and dataflow variables provide a very useful property for failure handling: redundant computation will not affect the correctness of a deterministic dataflow program. We propose a failure handling model where failed processes or temporarily unreachable processes, can be restarted while still providing the guarantees of the deterministic programming model.\nWe classify the failures into two groups:\n\u2022 Computing process failure: Failure of an individual Erlang process which uses a value in the single-assignment store. Given other processes may be waiting for the result of this processes computation, this can cause the program to block forever.\n\u2022 Dataflow variable failure: A dataflow variable stored in the single-assignment store is not reachable. This means that computing processes issuing operations on the unreachable variable will block until the dataflow\nvariable becomes accesible again. This may never happen and the computing process would block forever."
        },
        {
            "heading": "3.4.1 Computing process failure handling",
            "text": "Computing process failures are rather straightforward to handle; execution can continue by re-executing the failing process without having to worry about duplicate processing introducing nondeterminism.\nConsider the following example:\n\u2022 Process p0 reads a dataflow variable, x1. \u2022 Process p0 performs a computation based on the value of x1,\nand binds the result of computation to x2.\nTwo possible failure conditions can occur:\n\u2022 If the output variable never binds, process p0 can be restarted and will allow the program to continue executing deterministically.\n\u2022 If the output variable binds, restarting process p0 has no effect, given the single-assignment nature of variables.\nDerflow does not provide any primitive for handling this computation, as the Erlang primitives are sufficient to handle these failures. Section 5.4 provides an example on how to successfully handle computing process failures."
        },
        {
            "heading": "3.4.2 Dataflow variable failure handling",
            "text": "Dataflow variable failures are more difficult to handle, given that re-execution of a blocked or failed process does not guarantee progress.\nConsider the following example:\n\u2022 Process p0 attempts to compute value for dataflow variable x1 and fails.\n\u2022 Process p1 blocks on x1 to be bound by p0, which will not complete successfully.\nThe re-execution of blocked process p1 will result in the process immediately blocking again. Therefore we must provide a way to identify dependencies between processes and dataflow variables in order to provide a deterministic restart strategy which guarantees progress. A common strategy to ensure progress in this situation is to restart the process that declared the failed dataflow variable. In addition, all the processes depending on the restarted process should also be restarted.\nWe can use the Erlang primitives monitor/2 and link/1 to build custom supervision trees which will guarantee a proper restart strategy which will ensure progress. Nevertheless, we still need to provide a way of monitoring and killing dataflow variables of the single-assignment store. To facilitate this, we extend our model with two additional primitives: monitor(x) and kill(x). These primitives are inspired by the failure model of Collet [4].\nTo support these two primitives, we extend dataflow variables as follows:\n\u2022 We extend dataflow variables allowing them to bind to a nonusable value, represented by >. A read or bind operation on a non-usable dataflow variable blocks the caller process forever.\n\u2022 We extend dataflow variables allowing them to track processes which have placed monitors on them. These monitors are tracked to support the kill primitive.\nBelow is the updated definition of dataflow variables: xi = {value, bound variables, waiting processes, next, lazy,\nmonitors}\nThe call monitor(xi) sets a monitor to the dataflow variable xi and returns a stream (initially, an unbound dataflow variable y) that will contain the reachability states that the dataflow variable xi visits on the node that did the monitor call. The new metadata monitors is a set that contains all the identifiers of the processes monitoring the dataflow variable.\nIf the reachability state of xi changes on a node, the new state is inserted at the end of each monitor stream that was created on that node. A dataflow variable can visit three reachability states: perm fail, temp fail and normal. perm fail means that the dataflow variable is permanently unreachable. temp fail means that the dataflow variable is temporarily unreachable but it may become reachable again. Finally, normal means that the dataflow variable is reachable. A dataflow variable can only visit the reachability state normal after visiting temp fail. Figure 2 diagrams the reachability states that a dataflow variable can visit.\nMore precisely, the execution of monitor(xi) can be defined as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xi, . . . , xn} \u2022 y = monitor(xi)\nxi.monitors \u222a {self()} y = declare()\n\u2022 After: \u03c3 = {x1, . . . , xi, . . . , xn, y}\nkill(xi) sets the dataflow variable xi to non-usable. It is a synchronous operation; therefore, the caller will block until the operation is completed. All processes monitoring a killed dataflow variable must be notified. This implies that if there are reachability problems the operation may never return. More precisely, the execution of this operation can be defined as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xi, . . . , xn} \u2022 kill(xi)\nxi.value = > \u2200p \u2208 xi.monitors, notify p\n\u2022 After: \u03c3 = {x1, . . . , xi = >, . . . , xn}"
        },
        {
            "heading": "4. Implementation",
            "text": "The following section discusses the implementation of Derflow."
        },
        {
            "heading": "4.1 Derflow API",
            "text": "Derflow currently provides the following functions:\nDeterministic dataflow \u2022 {ok, Id::term()} = declare():\nCreates a new unbound dataflow variable in the store. It returns the id of the newly created variable.\n\u2022 ok = bind(Id, Value): Binds the dataflow variable Id to Value. Value can either be an Erlang term or any other dataflow variable.\n\u2022 ok = bind(Id, Mod, Fun, Args): Binds the dataflow variable Id to the result of evaluating Mod:Fun(Args).\n\u2022 {ok, Value::term()} = read(Id): Returns the value bound to the dataflow variable Id. If the variable represented by Id is not bound, the caller blocks until it is bound.\nStreams\n\u2022 {ok, NextId::term()} = produce(Id, Value): Binds the variable Id to Value. It returns the pair composed by the atom ok and the variable NextId that represents the id of the next element of the stream.\n\u2022 {ok, NextId::term()} = produce(Id, Mod, Fun, Args): Binds the variable Id to the result of evaluating Mod:Fun(Args). It returns the pair composed by the atom ok and the variable NextId that represents the id of the next element of the stream.\n\u2022 {ok, Value::term(), NextId::term()} = consume(Id): Returns the value bound to the dataflow variable Id and the id of the next element in the stream. If the variable represented by Id is not bound, the caller blocks until it is bound.\n\u2022 {ok, NextId::term()} = extend(Id): Declares the variable that follows the variable Id in the stream. It returns the id of the next element of the stream. This function is useful for achieving concurrency in some cases (e.g. The Sieve of Eratosthenes).\nLaziness\n\u2022 ok = wait needed(Id): Used for adding laziness to the execution. The caller blocks until the variable represented by Id is needed when attempting to read the value.\nDataflow variable failure handling\n\u2022 {ok, IdStream::term()} = monitor(Id): Registers the caller as monitor of the dataflow variable Id. Returns the head of a stream that will contain the states that the dataflow variable Id visits, from the caller process view.\n\u2022 ok = kill(Id): Set the dataflow variable represented by Id to non-usable."
        },
        {
            "heading": "4.2 Distribution",
            "text": "Derflow is implemented as an Erlang library, which relies on a single-assignment store. This store needs to be accessible by all the processes that participate in the execution of the Derflow program."
        },
        {
            "heading": "4.2.1 Partition strategies",
            "text": "In a single system, the design of such a store is simpler as the memory is accessible and shared by all the communicating processes. Nevertheless, in a distributed fashion, the implementation becomes tricky and keeping consistency guarantees and high grade of scalability is challenging.\nWe considered three approaches:\n\u2022 Each dataflow variable has a \u2019home process\u2019, where it was initially created. Therefore, binding the variable always sends a message to the \u2019home process\u2019, which then broadcasts the binding to all the instances.\n\u2022 Each instance of a dataflow variable knows all the other instances. There are no \u2019home processes\u2019. Therefore, after binding the local instance, the operation is directly broadcast to the other instances.\n\u2022 Each computing node has a partition of the single-assignment store. All processes on a given computing node will reference the local partition. Binding a variable sends the operation to the local partition, which will then send it to the partition replicas.\nWe chose the third approach. In the first two approaches, every process that knows about a particular dataflow variable creates a new instance; therefore, it will eventually participate in the corresponding bind operation. In some cases, the number of instances can be large. This would result in poor performance. Nevertheless, in the third approach, each computing node is responsible for a partition of the single-assignment store; therefore no matter how many processes know about a particular dataflow variable, the binding operation would always be sent to the responsible and to the corresponding replicas."
        },
        {
            "heading": "4.2.2 Design considerations",
            "text": "When choosing to implement our distributed single-assignment store, we examined two possible choices: riak core and mnesia [8]. mnesia provides a native Erlang implementation of a relational database management system, which supports atomic transactions and the ability to distribute tables across nodes through replication. However, we look at two specific problems with mnesia:\n\u2022 Problems arise in the presence of network partitions [11] where the mnesia nodes on either side of the network partition are able to make progress independently. Currently, no mechanisms exist for reconciling the changes made to the database when nodes reconnect, nor reasoning about concurrent or causally influenced operations. While the functionality for reasoning about concurrent events is not necessary for the implementation of the single-assignment store, Section 7 discusses a generalization of our single-assignment variables to conflict-free replicated data types, or CRDTs [17], where causality is desired.\n\u2022 mnesia performs replication to all nodes which share a table of data. This requires writing a custom distribution layer for distributing the data if we want to have it partitioned to ensure even load distribution given dynamic membership and node failures.\nGiven the background discussed in Section 2.1, riak core provides solutions to both of these problems:\n\u2022 riak core provides a dotted version vector [16] and vector clock facility as a causality tracking mechanism which can be used to reason about concurrent operations. In addition, riak core provides mechanisms, such as active anti-entropy and handoff, which allow us to reason about divergences between replicas.\n\u2022 riak core\u2019s distribution layer provides minimal reshuffling of data, and predictable hashing through hash-space partitioning, consistent hashing, and a virtual node abstraction.\n4.2.3 Implementation on riak core In implementing the partitioned single-assignment store on riak core, we made the following design decisions:\n\u2022 Data is partitioned across a series of nodes, using the hashspace partitioning and consistent hashing techniques described in Section 2.1.1 and Section 2.1.2.\n\u2022 When declaring new dataflow variables, we write the variable into the replica set for that variable, requiring that the write be acknowledged by a strict quorum to ensure fault-tolerance of the variable as described in Section 2.1.3.\n\u2022 As dataflow variables become bound, we rely again on a strict quorum to acknowledge the write, and notify all processes waiting for the value that the variable has been bound. Given that n/2 \u2212 1 nodes might not accept the write or be available, we ensure that an active anit-entropy mechanism exists to notify any processes on the node which did not receive the update which might be waiting when the bound value is replicated.\n\u2022 If a strict quorum is not available because of a network partition, operations on dataflow variables do not make progress until the partition has healed.\nIn the event of ownership transfer, during dynamic membership changes within the cluster, we perform the following:\n\u2022 Each replica\u2019s portion of single-assignment store is transferred over to the target replica. As this occurs, each dataflow variable, if bound, notifies all waiting processes on the target replica allowing any processes which were waiting during the partition to proceed.\n\u2022 As each variable is transferred over, monitors are removed locally and reapplied for each dataflow variable on the target vnode, given the processes which are waiting.\n\u2022 Given that the process notification of a bound variable operation is idempotent, duplicate notifications to the same process produces no result."
        },
        {
            "heading": "5. Examples",
            "text": "In this section we describe some use cases for Derflow."
        },
        {
            "heading": "5.1 Concurrency transparency",
            "text": "In Derflow, any function that uses dataflow variables can be run in a different process while keeping the final result same. Thus, programmers can transparently add concurrency to their programs (either parallelism or distribution) in a secure way without thinking about data races and possible bugs.\nOne such example is a map function, that receives a stream of inputs and applies a function to each element resulting an output stream of equal length. The code in Derflow for a sequential map function is the following:\nmap(S1, M, F, S2) -> case derflow:consume(S1) of {ok, nil, _} -> derflow:bind(S2, nil);\n{ok, Value, Next} -> {ok, NextOut} = derflow:produce(S2, M, F, Value), map(Next, F, NextOut)\nend.\nNevertheless, due to the concurrency transparency property, the programmer could easily upgrade his sequential map to a concurrent implementation without compromising determinism. The code in Derflow for the concurrent implementation of the map function is the following:\nconcurrent_map(S1, M, F, S2) -> case derflow:consume(S1) of {ok, nil, _} -> derflow:bind(S2, nil);\n{ok, Value, Next} -> {ok, NextOut} = derflow:extend(S2), spawn(derflow, bind, [S2, M, F, Value]), concurrent_map(Next, F, NextOut)\nend.\nIn this case, the programmer explicitly specified (by using the primitive spawn(module, function, args)) that the evaluation of the\nfunction F is done asynchronously. Therefore, the map function can read the next element from the input stream without waiting for the function to be evaluated. The concurrent map, when leveraging parallel execution, will be faster than its sequential counterpart."
        },
        {
            "heading": "5.2 Concurrent deployment",
            "text": "In concurrent deployment, we could further leverage concurrency transparency to concurrently and incrementally start new processes according to need. There is no need to start all processes when initializing programs, instead only a few processes will be started at first and they will launch new processes during runtime according to need. The launched processes are executed concurrently and will terminate when it finishes its computation, without affecting the execution of other processes.\nThe following example is a pipeline that implements the Sieve of Eratosthenes. This program receives a stream of integers and returns a stream with the integers that are prime. At each iteration of the sieve, the stream of candidates is filtered by using the latest prime found. Thus, one filter process is created per iteration. The output of a filter is used as an input of the next filter. Filters are pipelined; therefore, as soon as a filter outputs the first element of its output stream, the next filter can start its execution. The code in Erlang using Derflow is the following:\nsieve(S1, S2) -> case derflow:consume(S1) of {ok, nil, _} -> derflow:bind(S2, nil);\n{ok, Value, Next} -> {ok, SN} = derflow:declare(), F = fun(Y) -> Y rem Value =/= 0 end, spawn(sieve, filter, [Next, F, SN]), {ok, NextOut} = derflow:produce(S2, Value), sieve(SN, NextOut)\nend.\nfilter(S1, F, S2) -> case derflow:consume(S1) of {ok, nil, _} -> derflow:bind(S2, nil);\n{ok, Value, Next} -> case F(Value) of false -> filter(Next, F, S2);\ntrue-> {ok, NextOut} = derflow:produce(S2, Value), filter(Next, F, NextOut)\nend end."
        },
        {
            "heading": "5.3 Laziness",
            "text": "The following examples show how the wait needed primitive can be used to implement lazy functions.\nThe first example implements a lazy version of a sorting algorithm that sorts a list of numbers in ascending order. The Derflow implementation is the following:\ninsort(List, S) -> case List of [H|T] -> {ok, OutS} = derflow:declare(), insort(T, OutS), spawn(getmin, insert, [H, OutS, S]);\n[] -> derflow:bind(S, nil)\nend.\ninsert(X, In, Out) -> ok = derflow:wait_needed(Out);\ncase derflow:consume(In) of {ok, nil, _} -> {ok, Next} = derflow:produce(Out, X), derflow:bind(Next, nil);\n{ok, V, SNext} -> if X < V -> {ok, Next} = derflow:produce(Out, X), derflow:produce(Next, In);\ntrue -> {ok, Next} = derflow:produce(Out,V), insert(X, SNext, Next)\nend end.\nThe primitives that contributes to the laziness of this program are spawn on the fourth line of insort and the wait needed function call in the first line of the insert function. The spawn operation creates a process when an insertion should be executed. The wait needed causes the created process to suspend until the result is needed by some other process. When only partial results are needed for the sorting algorithm, the lazy implementation can have a performance gain over the eager version.\nFor instance, if only the smallest number of the sorted list is needed, we can simply read the first element of the output list. When the input list is [1,2,3,4,5,6,7,8,9,10], both eager execution and lazy execution performs insertion ten times. However, when the input is [10,9,8,7,6,5,4,3,2,1], the eager version executes insertion for 54 times; in contrast, the lazy version only executes insertion 19 times.\nThe second example combines lazy execution and eager execution. We implemented a bounded-buffer that connects a producer and a consumer. Thus, the producer only produces on demand when the consumer needs to consume. Nevertheless, the producer is allowed to generate some elements in advance in order to be more efficient. The Derflow implementation is the following:\nproducer(Value, N, Output) -> if (N > 0) -> ok = derflow:wait_needed(Output), {ok, Next} = derflow:produce(Output, Value), producer(Value+1, N-1, Next);\ntrue -> derflow:bind(Output, nil)\nend.\nloop(S1, S2, End) -> ok = derflow:wait_needed(S2), {ok, S1Value, S1Next} = derflow:consume(S1), {ok, S2Next} = derflow:produce(S2, S1Value), case derflow:extend(End) of {ok, nil} -> ok;\n{ok, EndNext} -> loop(S1Next, S2Next, EndNext)\nend.\nbuffer(S1, BUFFER_SIZE, S2) -> End = drop_list(S1, BUFFER_SIZE), loop(S1, S2, End).\ndrop_list(S, Size) -> if Size == 0 -> S;\ntrue -> {ok, Next} = derflow:extend(S), drop_list(Next, Size-1)\nend.\nconsumer(S2, Size, F, Output) -> if Size == 0 ->\nok; true -> case derflow:consume(S2) of {ok, nil, _} -> derflow:bind(Output, nil);\n{ok, Value, Next} -> {ok, NextOut} = derflow:produce(Output, F(Value)), consumer(Next, Size-1, F, NextOut)\nend end.\nThe above code has three main components:\n\u2022 The producer that only produces items when it is needed. This is achieved by calling wait needed for the next element after it has produced an item.\n\u2022 The bounded buffer: It takes the output stream of the producer and the input stream of the consumer. It firstly asks for a number of items (BUFFER SIZE) to the producer by extending the producer\u2019s stream (drop list), then it keeps checking if the consumer asks for items. In case the consumer has asked, the bounded buffer copies an element from the producer\u2019s stream to the consumer\u2019s stream and extend the producer\u2019s stream by one more element.\n\u2022 The consumer that asks for items eagerly."
        },
        {
            "heading": "5.4 MapReduce-style example",
            "text": "We implement a simple framework that can concurrently launch tasks from multiple clients, similar to MapReduce [5]. It combines the use of dataflow variables, concurrency transparency, concurrent deployment, and non-determinism.\nIn the example, clients send a MapReduce-style task to a proxy through send task. The proxy appends received tasks to a stream and keeps waiting for tasks. The job tracker checks the task stream, spawns mappers and reducers concurrently for incoming tasks and continues checking for tasks.\nsend_task(Proxy, Map, Reduce, Input, Output) -> Proxy ! {Map, Reduce, Input, Output}.\njobproxy(TaskStream) -> receive Task -> {ok, Next} = derflow:produce(TaskStream, Task), jobproxy(Next)\nend.\njobtracker(Superv, Tasks) -> case derflow:consume(Tasks) of {ok, nil, _} -> io:format(\"All job finished!~n\");\n{ok, Value, Next} -> {MapTask, ReduceTask, In, Out} = Value, {Mod, MapFun} = MapTask, {Mod2, RedFun} = ReduceTask, MapOut = spawn_map(Superv, In, Mod, MapFun, []), spawn_mon(Superv, Mod2, RedFun, [MapOut, Out]), jobtracker(Next)\nend.\nspawn_map(Superv, Inputs, Mod, Fun, Outputs) -> case Inputs of [H|T] -> {ok, S} = derflow:declare(), spawn_mon(Superv, Mod, Fun, [H, S]), spawnmap(T, Mod, Fun, lists:append(Outputs,[S]));\n[] -> Outputs\nend.\nspawn_mon(Superv, Mod, Fun, Args) -> Pid = spawn(Module, Function, Args), Superv ! {\u2019SUPERVISE\u2019, Pid, Mod, Fun, Args}.\nThe implementation of the proxy embodies non-determinism, as tasks may be received in different orders due to the process scheduler or network congestion.\nHowever, since the proxy can not predict the arriving order of tasks, it is impossible to write the program in a deterministic way. In fact, this level of non-determinism only affects the order that tasks are launched. Since each task is executed in parallel without interaction between each other, users can not perceive nondeterminism.\nThe job tracker also exemplifies several concepts we proposed. Firstly, the job tracker starts a job when it receives a new task incrementally and does not need to wait for all tasks before it starts any, which is concurrent deployment. Secondly, in each job, mappers and reducers are launched concurrently. This exploits the concurrency transparency property. Each mapper has its own output stream. The reducer reads from the mappers output streams sequentially. Thus, it uses the dataflow variables to synchronize the concurrent execution.\nIn addition, the example handles computing processes failures. The first argument (Superv), of the jobtracker function, is the process id of a supervisor process. Thus, all new dataflow processes created in jobtracker (using the function spawn mon) are supervised by it.\nAccording to the semantics of Derflow, redundant computation does not affect the correctness of the program. Therefore, deterministic dataflow functions are idempotent. Considering this property, we implemented a simple supervisor that restarts the failing deterministic dataflow processes when a problem is detected. The code is the following:\nsupervisor(Dict) -> receive {\u2019DOWN\u2019, Ref, process, _, _} -> case dict:find(Ref, Dict) of {ok, {Module, Function, Args}} -> spawn_mon(self(), Module, Function, Args);\nerror -> supervisor(Dict)\nend; {\u2019SUPERVISE\u2019, PID, Information} -> Ref = erlang:monitor(process, PID), Dict2 = dict:store(Ref, Information, Dict), supervisor(Dict2)\nend.\nThe above supervisor receives supervise and down messages. The former is a monitoring request; therefore, the supervisor simply uses the Erlang monitor primitive to set the monitor. The latter is received when a monitored process does not exist, it is not reachable or it has died. The supervisor behaves the same in all situations by re-executing the deterministic dataflow process. The supervisor uses dict to store the information regarding the monitored processes such as the function executed by the process and its arguments.\nNevertheless, the shown supervisor is only one example. More sophisticated supervisors can be implemented. For instance, the supervisor could behave differently for temporary failures. Then, it can decide to wait longer before restarting the computation. In some cases, it is not efficient to restart the execution."
        },
        {
            "heading": "6. Integration with non-determinism",
            "text": "Deterministic dataflow is a powerful concurrent programming model that eliminates all race conditions by design. However, it is clear that practical applications sometimes need non-determinism. In most cases, the non-determinism is only needed in a small part\nof the program. But the need cannot be reduced to zero. For example, a simple client-server application needs non-determinism since the server must accept requests from any client. There is only one point of non-deterministic choice, at the server, but it cannot be eliminated. So our deterministic model must cohabit in a simple way with non-deterministic execution. In this section, we show to integrate our model with non-deterministic execution.\n6.1 is det primitive Derflow provides one primitive which allows us to support nondeterministic execution: is det(x). This operation checks whether a dataflow variable (x) is bound or not, which introduces nondeterminism due to different process scheduling or network delays in each program execution.\nis det(x) primitive is useful for stream management. For instance, in a producer-consumer application, where the producer is faster than the consumer, the latter might be interested in only consuming the latest element produced until that point. Thus, it would like to skip some of the produced elements.\nMore precisely, is det can be described as follows:\n\u2022 Before: \u03c3 = {x1, . . . , xi, . . . , xn} \u2022 bool = is det(xi)\nbool = xi.value == vi\n\u2022 After: \u03c3 = {x1, . . . , xi, . . . , xn}\nAccordingly, the Derflow API is extended as follows:\n\u2022 {ok, Value::boolean()} = is det(Id): Returns true if the dataflow variable Id is bound, false otherwise.\nA good example of the use of is det(x) is a live-streaming video displayer. The displayer always tries to display the latest frame sent and skip the intermediate ones. A simplified version of this program can be written in Derflow as follows:\nskip(Input, Output) -> case derflow:consume(Input) of {ok, nil, _} -> derflow:bind(Output, nil);\n{ok, _, Next} -> {ok, Bound} = derflow:is_det(Next), if Bound -> skip(Next, Output);\ntrue -> derflow:produce(Output, {ok, Input})\nend end.\ndisplay(Input) -> {ok, Output} = derflow:declare(), skip(Input, Output), case derflow:consume(Output) of {ok, Value, Next} -> display_frame(Value), display(Next)\nend.\nThe skip function traverses the input stream and returns the latest frame until that point. The display function displays the frame returned by skip."
        },
        {
            "heading": "6.2 Integration with Erlang",
            "text": "One of the main limitations of the deterministic dataflow model is that only one process can write into a stream; therefore, a simple client-server application cannot be implemented. By using communication channels, this limitation can be overcome.\nThe following example shows how to do this by taking advantage of the message-passing primitives of Erlang. The example implements a monitoring system. It is composed of a centralized component that receives messages from multiple sensor entities placed elsewhere. In this example, we monitor the number of failures per datacenter in a geo-replicated application. There is one sensor per datacenter that sends a failure message to the central component (through a proxy) each time a computer is down. The centralized component registers the failures to eventually analyze the statistics. The proxy is the component that uses the Erlang communication channels. It receives spontaneous messages from the sensors and serializes them by appending them to an associated stream.\nobserver_proxy(S) -> receive {Msg, From} -> {ok, Next} = derflow:produce(S, {Msg, From}), observer_proxy(Next)\nend.\nsensor(Proxy, Identifier) -> Random = random:uniform(), Milliseconds = round(timer:seconds(Random)), timer:sleep(Milliseconds), Proxy ! {computer_down, Identifier}, sensor(Proxy, Identifier).\ndcs_observer(Input, Output, State) -> case derflow:consume(Input) of {ok, {computer_down, Identifier}, NextInput} -> State2 = register(Identifier, State), {ok, NextOut} = derflow:produce(Output, State2), dcs_observer(NextInput, NextOut, State2);\n{ok, _, NextInput} -> % Ignore dcs_observer(NextInput, Output, State)\nend. end.\nThe above application is mainly composed by three functions:\n\u2022 observer proxy that continuously waits for messages. If a message is received, it immediately appends it to the associated stream. It intentionally waits forever if no messages are sent.\n\u2022 sensor that sends a message to the observer proxy every time a computer fails. The computer failure is modeled by a random wait.\n\u2022 dcs observer that registers the failures by reading the stream associated to the observer proxy."
        },
        {
            "heading": "7. Conclusions and future work",
            "text": "In this paper, we have proposed Derflow, a deterministic dataflow extension for Erlang. Derflow relies on a robust, highly available and scalable single-assignment store built using riak core, a distributed systems framework. We have shown examples of its usage and explained how it can be integrated with non-deterministic computations.\nThe following paragraphs outline a series of planned extensions to Derflow that will provide a more expressive and complete computational model for large-scale distributed applications.\nGeneralizing to semilattices Given that our dataflow variables can be seen as simple semilattices with two states: bound and unbound, we would like to extend them to more expressive semilattices used to build CRDTs. This is very similar to the approach taken by LVars [14] to provide deterministic parallel programming. Our work expands on this work by providing this deterministic parallelism across computing nodes, in a fault-tolerant manner.\nSimilarly to LVars, we would also like to provide a threshold read primitive over these datatypes, which would cause an application to block and synchronize on a value until a particular threshold is passed. However, we are still uncertain what difficulties arise when introducing distribution into this model, given the various failure conditions that can be experienced over computer networks. Furthermore, some CRDTs composed by multiple semi-lattices do not behave monotonically. This may restrict the use of threshold reads.\nExtending the Erlang syntax and runtime system Our current model is implemented with a set of library functions. Compiler and run-time modifications can be done to provide a simple syntax for deterministic dataflow programs and to provide simpler ways to control non-determinism in programs. These extensions would provide a much more compelling computational model for the user."
        },
        {
            "heading": "Acknowledgments",
            "text": "We thank Nicholas Rutherford and Sean Cribbs for comments that helped to improve the paper. This work was partially funded by the SyncFree project in the European Seventh Framework Programme (FP7/2007-2013) under Grant Agreement no 609551 and by the Erasmus Mundus Joint Doctorate Programme under Grant Agreement 2012-0030."
        }
    ],
    "title": "Derflow: Distributed Deterministic Dataflow Programming for Erlang",
    "year": 2014
}