{
    "abstractText": "Reproducibility is the ability of recreating identical binaries under pre-de\u0080ned build environments. Due to the need of quality assurance and the bene\u0080t of be\u008aer detecting a\u008aacks against build environments, the practice of reproducible builds has gained popularity in many open-source so\u0089ware repositories such as Debian and Bitcoin. However, identifying the unreproducible issues remains a labour intensive and time consuming challenge, because of the lacking of information to guide the search and the diversity of the causes that may lead to the unreproducible binaries. In this paper we propose an automated framework called RepLoc to localize the problematic \u0080les for unreproducible builds. RepLoc features a query augmentation component that utilizes the information extracted from the build logs, and a heuristic rule-based \u0080ltering component that narrows the search scope. By integrating the two components with a weighted \u0080le ranking module, RepLoc is able to automatically produce a ranked list of \u0080les that are helpful in locating the problematic \u0080les for the unreproducible builds. We have implemented a prototype and conducted extensive experiments over 671 real-world unreproducible Debian packages in four di\u0082erent categories. By considering the topmost ranked \u0080le only, RepLoc achieves an accuracy rate of 47.09%. If we expand our examination to the top ten ranked \u0080les in the list produced by RepLoc, the accuracy rate becomes 79.28%. Considering that there are hundreds of source code, scripts, Make\u0080les, etc., in a package, RepLoc signi\u0080cantly reduces the scope of localizing problematic \u0080les. Moreover, with the help of RepLoc, we successfully identi\u0080ed and \u0080xed six new unreproducible packages from Debian and Guix.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhilei Ren"
        },
        {
            "affiliations": [],
            "name": "He Jiang"
        },
        {
            "affiliations": [],
            "name": "Jifeng Xuan"
        },
        {
            "affiliations": [],
            "name": "Zijiang Yang"
        }
    ],
    "id": "SP:3f7411cb35e4ac8dc3d3cc9e862d785f38de098f",
    "references": [
        {
            "authors": [
                "Ludovic Court\u00e8s"
            ],
            "title": "Reproducible builds: a means to an end. h\u008aps://www. gnu.org/so\u0089ware/guix/news/reproducible-builds-a-means-to-an-end.html",
            "year": 2015
        },
        {
            "authors": [
                "Steven Davies",
                "Marc Roper",
                "Murray Wood"
            ],
            "title": "Using bug report similarity to enhance bug localisation",
            "venue": "In Reverse Engineering (WCRE),",
            "year": 2012
        },
        {
            "authors": [
                "Xavier de Carn\u00e9 de Carnavalet",
                "Mohammad Mannan"
            ],
            "title": "Challenges and Implications of Veri\u0080able Builds for Security-critical Open-source So\u0089ware",
            "venue": "In Proceedings of the 30th Annual Computer Security Applications Conference (ACSAC \u201914)",
            "year": 2014
        },
        {
            "authors": [
                "Andrea H\u00f6ller",
                "Nermin Kajtazovic",
                "Tobias Rauter",
                "Kay R\u00f6mer",
                "Christian Kreiner"
            ],
            "title": "Evaluation of diverse compiling for so\u0089ware-fault detection",
            "venue": "In Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition. EDA Consortium,",
            "year": 2015
        },
        {
            "authors": [
                "Nima Honarmand",
                "Josep Torrellas"
            ],
            "title": "Replay Debugging: Leveraging Record and Replay for Program Debugging",
            "venue": "In Proceeding of the 41st Annual International Symposium on Computer Architecuture (ISCA",
            "year": 2014
        },
        {
            "authors": [
                "Pavneet Singh Kochhar",
                "Yuan Tian",
                "David Lo"
            ],
            "title": "Potential biases in bug localization: Do they ma\u008aer",
            "venue": "In Proceedings of the 29th ACM/IEEE international conference on Automated so\u0087ware engineering",
            "year": 2014
        },
        {
            "authors": [
                "An Ngoc Lam",
                "Anh Tuan Nguyen",
                "Hoan Anh Nguyen",
                "Tien N Nguyen"
            ],
            "title": "Combining Deep Learning with Information Retrieval to Localize Buggy Files for Bug Reports (N)",
            "venue": "In Automated So\u0087ware Engineering (ASE),",
            "year": 2015
        },
        {
            "authors": [
                "Hang Li"
            ],
            "title": "Learning to rank for information retrieval and natural language processing",
            "venue": "Synthesis Lectures on Human Language Technologies 7,",
            "year": 2014
        },
        {
            "authors": [
                "Stacy K Lukins",
                "Nicholas A Kra",
                "Letha H Etzkorn"
            ],
            "title": "Bug localization using latent Dirichlet allocation",
            "venue": "Information and So\u0087ware Technology 52,",
            "year": 2010
        },
        {
            "authors": [
                "Kevin Moran",
                "Mario Linares V\u00e1squez",
                "Carlos Bernal-C\u00e1rdenas",
                "Christopher Vendome",
                "Denys Poshyvanyk"
            ],
            "title": "Automatically Discovering, Reporting and Reproducing Android Application Crashes",
            "venue": "In 2016 IEEE International Conference on So\u0087ware Testing, Veri\u0080cation and Validation,",
            "year": 2016
        },
        {
            "authors": [
                "Robert O\u2019Callahan",
                "Chris Jones",
                "Nathan Froyd",
                "Kyle Huey",
                "Albert Noll",
                "Nimrod Partush"
            ],
            "title": "Engineering Record and Replay for Deployability",
            "venue": "In Proceedings of the 2017 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC \u201917)",
            "year": 2017
        },
        {
            "authors": [
                "Shivani Rao",
                "Henry Medeiros",
                "Avinash Kak"
            ],
            "title": "Comparing Incremental Latent Semantic Analysis Algorithms for E\u0081cient Retrieval from So\u0089ware Libraries for Bug Localization",
            "venue": "ACM SIGSOFT So\u0087ware Engineering Notes",
            "year": 2015
        },
        {
            "authors": [
                "Cristian Ruiz",
                "Salem Harrache",
                "Michael Mercier",
                "Olivier Richard"
            ],
            "title": "Reconstructable So\u0089ware Appliances with Kameleon",
            "venue": "SIGOPS Oper. Syst. Rev. 49,",
            "year": 2015
        },
        {
            "authors": [
                "Davide Di Ruscio",
                "Patrizio Pelliccione"
            ],
            "title": "Simulating upgrades of complex systems: \u008ce case of Free and Open Source So\u0089ware",
            "venue": "Information and So\u0087ware Technology 56,",
            "year": 2014
        },
        {
            "authors": [
                "Ripon K Saha",
                "Ma\u008ahew Lease",
                "Sarfraz Khurshid",
                "Dewayne E Perry"
            ],
            "title": "Improving bug localization using structured information retrieval",
            "venue": "In Automated So\u0087ware Engineering (ASE),",
            "year": 2013
        },
        {
            "authors": [
                "Bunyamin Sisman",
                "Avinash C Kak"
            ],
            "title": "Incorporating version histories in information retrieval based bug localization",
            "venue": "In Proceedings of the 9th IEEE Working Conference on Mining So\u0087ware Repositories",
            "year": 2012
        },
        {
            "authors": [
                "Chakkrit Tantithamthavorn",
                "Akinori Ihara",
                "Ken-ichi Matsumoto"
            ],
            "title": "Using co-change histories to improve bug localization performance. In So\u0087ware Engineering, Arti\u0080cial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",
            "venue": "14th ACIS International Conference on",
            "year": 2013
        },
        {
            "authors": [
                "Qianqian Wang",
                "Chris Parnin",
                "Alessandro Orso"
            ],
            "title": "Evaluating the Usefulness of IR-based Fault Localization Techniques",
            "venue": "In Proceedings of the 2015 International Symposium on So\u0087ware Testing and Analysis (ISSTA 2015). ACM,",
            "year": 2015
        },
        {
            "authors": [
                "Shaowei Wang",
                "David Lo"
            ],
            "title": "Version history, similar report, and structure: Pu\u008aing them together for improved bug localization",
            "venue": "In Proceedings of the 22nd International Conference on Program Comprehension",
            "year": 2014
        },
        {
            "authors": [
                "Shaowei Wang",
                "David Lo",
                "Julia Lawall"
            ],
            "title": "Compositional vector space models for improved bug localization",
            "venue": "In 2014 IEEE International Conference on So\u0087ware Maintenance and Evolution (ICSME)",
            "year": 2014
        },
        {
            "authors": [
                "David A Wheeler"
            ],
            "title": "Countering trusting trust through diverse doublecompiling",
            "venue": "In Computer Security Applications Conference,",
            "year": 2005
        },
        {
            "authors": [
                "Chu-Pan Wong",
                "Yingfei Xiong",
                "Hongyu Zhang",
                "Dan Hao",
                "Lu Zhang",
                "Hong Mei"
            ],
            "title": "Boosting bug-report-oriented fault localization with segmentation and stack-trace analysis",
            "venue": "IEEE International Conference on So\u0087ware Maintenance and Evolution (ICSME)",
            "year": 2014
        },
        {
            "authors": [
                "Jifeng Xuan",
                "Xiaoyuan Xie",
                "Martin Monperrus"
            ],
            "title": "Crash reproduction via test case mutation: let existing test cases help",
            "venue": "In Proceedings of the 2015 10th Joint Meeting on Foundations of So\u0087ware Engineering,",
            "year": 2015
        },
        {
            "authors": [
                "Xin Ye",
                "Razvan Bunescu",
                "Chang Liu"
            ],
            "title": "Learning to rank relevant \u0080les for bug reports using domain knowledge",
            "venue": "In Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of So\u0087ware Engineering",
            "year": 2014
        },
        {
            "authors": [
                "Jian Zhou",
                "Hongyu Zhang",
                "David Lo"
            ],
            "title": "Where should the bugs be \u0080xed? more accurate information retrieval-based bug localization based on bug reports",
            "venue": "In So\u0087ware Engineering (ICSE),",
            "year": 2012
        }
    ],
    "sections": [
        {
            "text": "In this paper we propose an automated framework called RepLoc to localize the problematic les for unreproducible builds. RepLoc features a query augmentation component that utilizes the information extracted from the build logs, and a heuristic rule-based ltering component that narrows the search scope. By integrating the two components with a weighted le ranking module, RepLoc is able to automatically produce a ranked list of les that are helpful in locating the problematic les for the unreproducible builds. We have implemented a prototype and conducted extensive experiments over 671 real-world unreproducible Debian packages in four di erent categories. By considering the topmost ranked le only, RepLoc achieves an accuracy rate of 47.09%. If we expand our examination to the top ten ranked les in the list produced by RepLoc, the accuracy rate becomes 79.28%. Considering that there are hundreds of source code, scripts, Make les, etc., in a package, RepLoc signi cantly reduces the scope of localizing problematic les. Moreover, with the help of RepLoc, we successfully identi ed and xed six new unreproducible packages from Debian and Guix.\nKEYWORDS Unreproducible Build; Localization; So ware Maintenance"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "As an indicator of the ability that the binaries could be recreated consistently from source, recent years have witnessed the emerging idea of reproducible builds. Given the source les, the reproducibility is described as the ability of building identical binary under pre-de ned build environments [15]. In this study, source les include source code, scripts, Make les, build con gurations, etc [6]. Checking the reproducibility of so ware creates a veri able\nlinkage that bridges the gap between the readable source les and the binary packages, which is important from various perspectives.\nFirstly, reproducibility is very important for the safety of build environments. For so ware ecosystems, a acks against the build environment may lead to serious consequences. By compromising the system to produce packages with backdoors [26, 45], malicious behaviors such as trusting trust a ack [41] may be introduced during the build time. For example, in 2015, over 4,000 iOS applications were infected by a counterfeit version of Apple\u2019s Xcode development environment (known as XcodeGhost) [1]. XcodeGhost injected malicious code during compiling time so that developers unknowingly distributed malware embedded in their applications [21]. Obviously, a solution is to ensure that the same source les always lead to the same binary packages so that an infected different binary immediately raises alarms. Unfortunately, a major obstacle of detecting such a acks lies in the transparency gap between the source les and their compiled binary packages. Due to non-deterministic issues such as timestamps and locales, it is not uncommon that rebuilding an application yields di erent binaries even within secure build environments. erefore, these kinds of a acks o en elude detection because di erent binaries of the same application is normal.\nBesides detecting a acks against build environments, validating the reproducibility is also helpful in debugging and nding certain release-critical bugs (e.g., libical-dev 1.0-1.1) [2]. Furthermore, in the context of and continuous integration and so ware upgrade [37], reproducible packages could be helpful in caching, and reducing redundant operations, e.g., by eliminating the necessity of delivering the di erent binaries compiled from the same source les. Due to the signi cant bene ts, many open-source so ware repositories have initiated their validation processes. ese repositories include GNU/Linux distributions such as Debian and Guix, as well as so ware systems like Bitcoin [19]. For instance, since 2014, the number of Debian\u2019s reproducible packages has been steadily increasing. Figure 1 presents the trend of the reproducible builds in Debian [14]. As of August 2017, over 85% of Debian\u2019s packages could be reproducibly built.\nDespite the e ort towards reproducibility, many packages remain unreproducible. For example, according to Debian\u2019s Bug Tracking System (BTS), as of August 23, 2017, there are 2,342 packages that are not reproducible [14] for the unstable branch targeting\nar X\niv :1\n80 3.\n06 76\n6v 1\n[ cs\n.S E\n] 1\n9 M\nar 2\nthe AMD64 architecture. Such large number of unreproducible packages implies the challenges in detecting and then xing the unreproducible issues. In particular, the localization task for the problematic les is the activity of identifying the source les that cause unreproducibility, which ranks source les based on their likelihood of containing unreproducible issues. Currently, the localization task is mostly manually conducted by developers. Since there may be hundreds to thousands of source les for a package, the localization tends to be labor intensive and time consuming.\nTo address this problem, we consider the source les as text corpus, and leverages the di log1 generated by comparing the di erent binaries to guide the search. As such, the localization of the problematic les can be modeled as a classic Information Retrieval (IR) problem: given the source les and the di log, determine those problematic les from the source les that are relevant to the unreproducible issues. e IR model has the potential to automate the localization task. However, the localization task is challenging, due to its unique characteristics.\nFirst, the information for locating the problematic les within the source les is very limited. e di log generated by comparing the di erent binaries, which is considered as the input of the IR process, may not be su ciently informative. We call this challenge an information barrier. In addition, there are many causes that may lead to unreproducible builds, such as embedding timestamps in les and recording le lists in non-deterministic order. e detailed issues are manually listed in Debian\u2019s documentation [12]. Moreover, the diverse types of les in a package also add to the complexity of localizing the problematic les, which may reside in not only the source code, but also other types of les such as scripts, Make les and build con gurations. We call this challenge a diverse-cause barrier.\nTo break through the barriers, we propose a localization framework called RepLoc that targets the localization task in search of problematic les for unreproducible builds. Given an unreproducible package with two di erent built binaries as the input, RepLoc produces a list of ranked source les. RepLoc features two components that address the two aforementioned challenges. For the information barrier, we develop a ery Augmentation (QA) component that utilizes the information extracted from the build logs to enhance the quality of the queries (represented by the le names extracted from the di logs, see Section 2). For the diversecause barrier, we develop a Heuristic rule-based Filtering (HF) component. More speci cally, we propose 14 heuristic rules that are obtained by summarizing the information presented in Debian\u2019s documents. Furthermore, we employ a weighted File Ranking (FR) component to combine the QA and HF components, and build an integrated framework to automate the localization of the problematic les for unreproducible builds.\nTo evaluate RepLoc, we have collected a real-world dataset that consists of 671 unreproducible packages. Since these packages were later xed with patches from Debian\u2019s BTS, we know exactly which les caused the unreproducibility and thus can use the facts to evaluate the accuracy of RepLoc. If we consider the topmost ranked le only, RepLoc achieves an accuracy rate of 47.09%. If we expand the range to include top ten ranked les, the accuracy rate becomes\n1Generated by diffoscope, h ps://di oscope.org\n79.28%. For other metrics such as precision and recall, RepLoc also outperforms the comparative approaches signi cantly. To further evaluate the e ectiveness of our approach, we use RepLoc on unreproducible packages that have never been xed before. With the help of RepLoc, we successfully identi ed the problematic les, then manually xed the unreproducible issues over three Debian packages. Moreover, the usefulness of RepLoc is examined over a di erent so ware repository (Guix [11] in this study). Under the guidance of RepLoc, problematic les for three unreproducible packages from Guix are detected and xed.\nis paper makes the following main contributions. \u2022 To the best of our knowledge, this is the rst work to address\nthe localization task for unreproducible builds. \u2022 We propose an e ective framework RepLoc that integrates heuris-\ntic ltering and query augmentation. A prototype has been implemented based on the approach. \u2022 We have evaluated RepLoc on 671 unproducibile packages that were later xed in the Debian repository. e experimental results show that RepLoc is e ective. We have made the benchmarks publicly available at h ps://reploc.bitbucket.io. \u2022 Under the guidance of RepLoc, we xed six unreproducible packages from Debian and Guix, and submi ed the patches to the BTSs of the two repositories. Among the submi ed patches, four have been accepted. e rest of this paper is organized as follows. In Section 2, we give the background of this work. Our approach is presented in Section 3, followed by experimental study in Section 4. e threats to validity and related work are described in Sections 5\u20136. Finally, Section 7 concludes the paper."
        },
        {
            "heading": "2 BACKGROUND",
            "text": "Taking Debian as a typical example, Figure 2 illustrates the common work ow of validating the reproducibility of packages [17].\nFirst, the source les are compiled under two pre-de ned build environments (steps 1\u20132). More speci cally, the build environments are constructed by se ing up altered environment variables or so ware con gurations. For instance, within Debian\u2019s continuous integration system,2 altered environment variables include locales, timezones, user privileges, etc. Table 1 presents a snippet of the altered environment (see [22] for more detailed information). Two versions of binaries can be generated with respect to each environment. e two versions are then compared against each other (step 3). If they are not bit-to-bit identical, the localization of problematic les that lead to unreproducible builds is required, based on the di log and the source les (step 4).\ne build and the comparison procedures (steps 1\u20133) can easily be automated, but the localization (step 4) mainly relies on the developers. Unfortunately, manual e ort to identify the les that lead to unreproducible builds is nontrivial. As shown in Figure 2, the di logs are the major source of the information to guide the localization of the problematic les, which, unfortunately, are not always su ciently informative.\nFigure 3 gives a snippet of the di log for dietlibc, a libc implementation optimized for small size. In the original version (0.33\u02dccvs20120325-6), a static library le di ers between the two versions during the build time (/usr/lib/diet/lib/libcompat.a). As shown in the di log, diffoscope indicates the di erence via the output of the GNU binary utility readelf. However, since the di content may not be well comprehensible (e.g., lines 7\u20138 in Figure 3), we do not leverage such information in this study. Meanwhile, Figure 4 presents a snippet of a problematic le (/Makefile) and the patch that xes the issue. In Figure 4(b), line 8 indicates that the root cause of the unreproducibility lies in the non-stable order of the object les, which are fed to the ar utility to generate libcompat.a (lines 6\u20137 of Figure 4(a)). e di culty in this example is that, the di log may fail to provide su cient information. ough it is possible to match the correct le with only the le\n2h ps://jenkins.debian.net\nname, i.e., line 6 of Figure 4(a), chances are that other irrelevant les containing the same le name might be matched as well.\ne aforementioned example illustrates how problematic les can be detected and xed. In reality there are multiple altered build con gurations and can be many corresponding causes that lead to unreproducible builds. For example, changing the timezone environment variable (env TZ) may cause the C/C++ packages that embed DATE macro to be unreproducible, and the locale environment variable (env LC *) may trigger unreproducible issues of packages that capture the text generated by programs. ese diverse unreproducible causes make the localization task di cult."
        },
        {
            "heading": "3 OUR APPROACH",
            "text": "In this section, we discuss the details of RepLoc. Figure 5 depicts the work ow of RepLoc that consists of three components QA, HF, and FR. For each component, we shall explain its design and implementation, companioned with the intermediate results over the running example dietlibc."
        },
        {
            "heading": "3.1 ery Augmentation Component",
            "text": "e upper part of Figure 5 depicts the QA component, which enriches the queried information by matching the les in the di log and the build logs, to tackle the information barrier.\nFirst, the di log is generated using diffoscope. en, the query extraction module takes the di log as the input, and generates the basic query. In this study, the basic query consists of the le names in the di log. As mentioned, due to the information barrier, the information that can be utilized to localize the problematic les is limited other than a list of les that are di erent within the two build processes. us, we enhance the quality of the queries with the build command retrieval module. e motivation for this module is that, during the build process, the build information such as the executed commands can be obtained. Moreover, based on the co-occurrence relationship between the le names in the di log and the build commands, we can identify the build commands with which the les mentioned in the di log are built. Hence, it is rational to augment the query by supplementing the build commands from the build log.\nFigure 6 illustrates a snippet of the build log of the exemplifying package dietlibc. It can be observed that the build log is more informative and provides supplementary information with respect to the di log. More speci cally, we rst split the build log into build command segments, with respect to the \u201cEntering/Leaving directory\u201d tags generated by make (e.g., lines 1 and 10 of Figure 6). With this operation, the commands invoked under the same directory can be grouped together, as a le of the augmentation corpus (denoted as a command le). Note that though there are two versions of build logs with respect to the two build environments, since we are interested in the build command, the choice of either version of build log does not have an impact on the results. en, the relevant les in the corpus are obtained by utilizing an IR model. In essence, any IR model can be adopted. In this study, we employ the Vector Space Model (VSM), due to its simplicity and e ectiveness.\nTo realize the VSM based augmentation, we calculate the cosine similarity between basic query and the command les. erea er, the matched commands from the most relevant command les are obtained. In particular, for the VSM model, we assign weight value for each le with the TF-IDF (Term Frequency-Inverse Document Frequency) measurement, which is widely used in IR [32]. In this paper, for a term t in a document d , its TF-IDFt,d value is calculated based on ft,d \u00d7 Nnt , where ft,d indicates the number of t \u2019s occurrences in d , nt denotes the number of les in which t appears, and N means the number of source les. With TF-IDF de ned, each le is represented as a vector, and the cosine similarity with the basic query is used to rank the command les.\nSim(\u00ael , \u00aes) = \u00ael \u00b7 \u00aes |\u00ael | |\u00aes | , (1)\nwhere \u00ael \u00b7 \u00aes represents the inner product of the basic query and the command le, and |\u00ael | |\u00aes | denotes the product of 2-norm of the vectors. A er that, the basic query and the retrieved contents, which are commands executed during the build process, are concatenated together as the enhanced query.\nRunning example: For dietlibc, all the le names in the di log, e.g., ./usr/lib/diet/lib/libcompat.a, are extracted as the basic query. en, within the augmentation, ar cru bin-x86 - 64/libcompat.a [. . . ] (line 3 of Figure 6) and the build commands in the same command le are retrieved. Finally, the contents of the retrieved command les are appended a er the basic query, as the nal query."
        },
        {
            "heading": "3.2 Heuristic Filtering Component",
            "text": "e HF component is designed to capture the problematic les by incorporating the domain knowledge, which is represented as frequently observed pa erns. In HF, the heuristic rules are constructed based on the following criteria: (1) e rules are manually constructed based on Debian\u2019s documentation [13]. (2) e rules are summarized for the four major categories of unreproducible issues (see Setcion 4.2). We traverse the notes in the documentation, and capture those issues that are described as Perl Compatible Regular Expression (PCRE). For example, invoking gzip without \u201c-n\u201d argument could be expressed using the negative assertions feature of PCRE (rule 3 in Table 2). Meanwhile, as a counterexample, the timestamps embedded in Portable Executable (PE) binaries are hard to be identi ed by heuristic rules or even by developers [20]. A er manual inspection based on the criteria, we obtain 14 heuristic rules, which are presented in Table 2, and described as follows:\n(1) TIME MACRO: using C time preprocessing macro in source les will embed di erent timestamps when compiled at di erent times. (2) DATE MACRO: embedding C date preprocessing macro in source les is similar as the previous case. (3) GZIP ARG: if applying gzip without -n argument, timestamps will be embedded in the header of the nal compressed le. (4) DATE CMD: capturing the current date with the date shell command. (5) PY DATE: obtaining date time in Python scripts. (6) PL LOCALTIME: obtaining date time in Perl scripts. (7) SYSTEM DATE: recording system time in the compiled binary. (8) DATE IN TEX: embedding date in TeX les, which in uences the built pdf les. (9) SORT IN PIPE: execute sort in pipeline without locale se ing. (10) GMTIME: obtaining current date time. (11) TAR GZIP PIPE: execute tar and gzip in pipeline.\nAlgorithm 1: RepLoc Input: binary package rst, binary package second, weight \u03b1 Output: candidate le list result 1 begin // Query Augmentation 2 log\u2190 diffoscope( rst, second) 3 query\u2190 parse log(log) 4 command les\u2190 parse build log(build log) 5 relevant command\u2190 retrieve relevant(query, command les) 6 augmented\u2190 concatenate(query, relevant commant)\n// Heuristic Filtering\n7 l ist \u2190 \u2205 8 for each source le s do 9 if s is matched by any rule in Table 2 then list\u2190 list \u222a {s }\n10 end // File Ranking 11 for each source le s do 12 if s \u2208 list then ws \u2190 1 13 else ws \u2190 0 14 scores \u2190 Calculate Sim\u2032 with respect to Equation 2 15 end 16 return sort(source les, score) 17 end\n(12) PL UNSORTED KEY: traversing unsorted hash keys in Perl script does not guarantee identical order. (13) LS WITHOUT LOCALE : capturing ls without locale se ing is similar with SORT IN PIPE. (14) UNSORTED WILDCARD: using wildcard in Make les without sorting, similar with PL UNSORTED KEY.\nBy applying the rules over the source les (e.g., with GNU grep -r -P), we obtain a subset of les that may lead to unreproducible builds. Note that these rules equally treat the source les as plain text, rather than consider the le types (e.g., based on le extension). e reason is that the unreproducible issues may reside in snippets or templates that do not follow le extension conventions, which are eventually embedded into unreproducible binaries. Based on such consideration, we do not sort the matched les in HF.\nRunning example: For dietlibc, there are in total ve problematic les, namely, /libpthread/Makefile, /libdl/Makefile, /debian/{rules, implicit}, and /Makefile. Among these les, /Makefile (see Figure 4(b)) can be captured by the UNSORTED - WILDCARD rule, in which sort does not appear before wildcard. However, we should note that there may be false alarms, e.g., for unexecuted commands or text in the comments. Consequently, HF may fail to place the matched problematic les at the top of the list."
        },
        {
            "heading": "3.3 File Ranking Component",
            "text": "e motivations behind the combination of HF and QA are twofold: (1) e heuristic rules in HF focus on the static aspect of the source les, i.e., treat all the source les in a uni ed way, and capture the suspicious les that match the de ned pa erns. Such mechanism can handle various le types. Unfortunately, there may be false alarms, especially for those les unused during the build process. (2) e build log based augmentation takes the dynamic aspect of the build process into consideration. With QA, we concentrate on the commands invoked during the build process. Hence, by combining the mechanisms, we can strengthen the visibility of the problematic les that lead to unreproducible builds.\nIn the FR component, these goals are realized as follows. First, with the augmented query, the relevant les are obtained with the\nsource le retrieval module. Similar as in Section 3.1, the VSM model is adopted to calculate the similarity values between the augmented query and each source le. Second, since we have acquired both the les retrieved by HF and the similarity values between source les and the augmented query, in the le ranking module, it is natural to combine these two types of information, to be er capture the problematic les. For example, we can modify Equation 1 and apply Sim\u2032 to rank the source les:\nSim\u2032(\u00ael , \u00aes) = (1 \u2212 \u03b1) \u00d7 Sim(\u00ael , \u00aes) + \u03b1 \u00d7ws , (2) where ws = 1 for those source les matched by the HF component, and ws = 0 otherwise. \u03b1 \u2208 [0, 1] is a weight parameter to balance the two terms, e.g., large \u03b1 values make RepLoc favor the HF component.\nWith Equation 2, the source les are ranked according to their modi ed similarity to the augmented query, and the top ranked les are returned as the nal results of RepLoc. We should note that, in this study, we adopt the le-level localization paradigm, in that the xing for many unreproducible packages is not unique. For instance, statements declaring missing environmental variables can appear anywhere in the le before it is needed. Hence, it is di cult to establish line-level ground-truth. In Algorithm 1, we present the pseudo-code of RepLoc, which combines QA (lines 2\u20136), HF (lines 7\u201310), and FR (lines 11-16) sequentially.\nRunning example: In Table 3, we present the top ve les retrieved by RepLoc and its individual components. From the table, we can observe that without augmenting the query, FR is able to retrieve two problematic les. However, the topmost ranked le is a changelog (/CHANGES), in that the le names in the di log appear in this le. In contrast, with the query augmented, FR (with QA) is able to rank the two problematic les at the top of the list. Meanwhile, although HF is able to capture /libpthread/Makefile, the le is not assigned top rank due to other false alarms, e.g., /t.c. Finally, by combining FR, QA, and HF, RepLoc is able to locate four problematic les."
        },
        {
            "heading": "4 EXPERIMENTAL RESULTS",
            "text": ""
        },
        {
            "heading": "4.1 Research estions",
            "text": "In this study, we intend to systematically analyze RepLoc, by investigating the following Research estions (RQs): \u2022 RQ1: Is RepLoc sensitive to the weighting parameter \u03b1? \u2022 RQ2: How e ective is RepLoc?\n\u2022 RQ3: How e cient is RepLoc? \u2022 RQ4: Is RepLoc helpful in localizing un xed packages?\nAmong these RQs, RQ1 concentrates on the impact of the weighting scheme between the components in RepLoc. RQ2 focuses on how well RepLoc performs in terms of di erent quality metrics. RQ3 examines whether RepLoc is time consuming, and RQ4 investigates the RepLoc\u2019s generalization."
        },
        {
            "heading": "4.2 Data Preparation",
            "text": "In this study, the dataset is constructed by mining Debian\u2019s BTS. To the best of our knowledge, Debian is the only repository providing both past-version packages and reproducibility-related patches, which are crucial for generating the corpus and the ground truth. Consequently, all the packages within the dataset are extracted from Debian\u2019 BTS, which are tagged as unreproducible by bug reporter via debtags, i.e., the command line interface for accessing the BTS. According to Debian\u2019s documentation, there are 14 categories of reproducible issues [16]. ere are also two special categories indicating the packages that fail to build from source, and the toolchain issues (non-deterministic issues introduced by other packages, see Section 5), which are not considered in this study.\nWe download all the 14 categories of 1716 bug reports, and download the packages, with their corresponding patches. en, we apply the validation tool kit,3 to obtain the corresponding di logs and build logs. In this study, we consider those categories with more than 30 packages. With such criterion, we obtain 671 packages in the dataset, which fall into the four largest categories. Figure 7(a) illustrates the statistics of the dataset. In the gure, we present the numbers of the open and closed bugs in Debian\u2019s BTS, as well as the number of packages in the dataset. Among the four categories of packages, the Timestamps category contains the most packages (462), followed by File-ordering (118), Randomness (50), and Locale (41). For all the four categories of 1491 packages that are labeled as \u201cdone\u201d, the packages in the dataset take a portion of 45.34%. Note that there are less packages in the dataset than closed bug reports, since packages may not be compilable due to the upgrade of their dependencies.\nIn Figure 7(b), we illustrate the statistics of the patches in the dataset. From the gure, we could observe that there are many types of les that might be involved in the unreproducible builds. For these les, the Debian rules les, which are the main build scripts, take the largest portion of the xed les (29.82%). Auxiliary les, such as the configure scripts and input les (*.in), takes the second largest portion (17.21%). A er that, there are the Make les (11.68%), scripts such as Python/Perl/PHP les (14.60%), C/C++ les (5.94%), XML les (4.80%), implicit build les (2.71%). Since we classify the les based on their le extensions heuristically, there are also 13.24% of the les that are not easy to classify, e.g, those without le extensions. is phenomenon conforms with the second barrier mentioned in Section 1, i.e., the causes to the unreproducible builds are diverse, which makes the localization task very challenging.\n3 e tool kit realizes steps 1\u20133 of Figure 2, available at h ps://anonscm.debian.org/ cgit/reproducible/misc.git"
        },
        {
            "heading": "4.3 Implementation and Metrics",
            "text": "RepLoc is implemented in Perl 5.24 and Java 1.8. All the experiments are conducted on an Intel Core i7 4.20 GHz CPU server with 16 GB memory, running GNU/Linux with kernel 4.9.0. For the comparative algorithms, we consider four variants of RepLoc, since there is no prior approach addressing this problem. e rst two variants implement two baseline algorithms, which only consider either the HF or the FR model (denoted as RepLoc(HF) and RepLoc(FR)). ese two variants are incorporated to examine the performance of its building-block components. Moreover, RepLoc(FR) could be considered the simulation of the manual localization, since in FR, the retrieval is realized by matching source les with di log contents. en, RepLoc(FR+QA) considers utilizing the QA component to enhance the basic queries extracted from the di logs. Finally, RepLoc indicates the version discussed in Section 3.\nTo evaluate the e ectiveness of RepLoc, metrics commonly used in the IR literatures are employed to evaluate the performance of RepLoc, including the accuracy rate, the precision, the recall, and the Mean Average Precision (MAP). e metrics are computed by examining the ranked list of source les returned by the framework in response to a query. e Top-N source les in the ranked list is called the retrieved set and is compared with the relevance list to compute the Precision and Recall metrics (denoted by P@N and R@N respectively). Given an unreproducible package with problematic les, a Top-N accuracy rate score, e.g. A@1, A@5, and A@10, of a localization tool is the portion of Top-N lists a tool provides that at least one problematic le contains in it [30, 48]. In this study, we also report P@1, P@5, P@10 and R@1, R@5, R@10 [28, 48]. P@N means the portion of problematic les successfully retrieved in a Top-N list, while R@N measures how many problematic les are retrieved in a Top-N list among all the problematic les:\nP@N = # of les that cause unreproducible builds N , (3)\nR@N = # retrieved problematic les in the Top-N list# of problematic les . (4)\nPrecision and Recall usually share an inverse relationship, in that, the Precision is higher than Recall for lower values of N and vice versa for higher values of N . An overall metric of retrieval accuracy is known as Mean Average Precision (MAP), which is the average of the Average Precision (AP) values over all the problematic les in unreproducible packages. For an unreproducible package with several problematic les, the AP is computed as\n\u2211M k=1 P@k\u00d7pos(k ) # of les related in the patch , where M is the size of a ranking list, pos(k) indicates whether the kth le in a ranking list is related to the unreproducible build, and P@k is the precision described in Equation 3. With AP de ned, MAP can be calculated by averaging all the AP scores across all the unreproducible packages."
        },
        {
            "heading": "4.4 Investigation of RQ1",
            "text": "In this RQ, we intend to investigate whether RepLoc is sensitive to the weighting parameter \u03b1 . As described in Section 3, in Equation 2, we propose the weighted similarity between queries and source les. Hence, in this RQ, we are interested in investigating RepLoc\u2019s behavior as we alter the weight of the two components. More speci cally, for each category of dataset, we randomly select half of the packages, and a grid search from 0.1 to 0.9 with a step of 0.1 is employed to analyze the impact of varying \u03b1 .\nConsidering the Timestamps and the Locale datasets, we visually present the trend of the A@10, P@10, R@10 and the MAP values\nagainst the \u03b1 value in Figure 8. From the gure, the following observations can be drawn. First, for the randomly selected packages, the performance of RepLoc exhibits similar trend, i.e., when \u03b1 is set within the range [0.2, 0.4], RepLoc obtains the best results. Second, we observe that RepLoc is not very sensitive to \u03b1 , unless \u03b1 is too large, which will make RepLoc prefer the HF component. Hence, for the subsequent experiments, \u03b1 is set with 0.3.\nAnswer to RQ1: Experimental results show that, RepLoc is not very sensitive to the parameter, which to some extent demonstrates the robustness of RepLoc."
        },
        {
            "heading": "4.5 Investigation of RQ2",
            "text": "In this RQ, we examine whether RepLoc locates the problematic les accurately. We present the experimental results, and discuss the phenomena observed. In Table 4, we rst give the results over the datasets. e table is organized as follows. e rst column indicates the four categories of datasets we built in this study (see Section 4.2). e second column represents the four variants of RepLoc. en, the rest of the table presents the metrics that evaluate the performance of each variant. Note that for the accuracy rate, the precision, and the recall, the metric values are averaged over all the packages. Besides, we also present the aggregate performance at the bo om of the table.\nTaking the Timestamps dataset as an example, several interesting phenomena can be observed. First, the performance of RepLoc(HF) is not satisfying. Even considering the Top-10 results, the corresponding accuracy rate is around 70%. To examine the representativeness of the heuristic rules, in Table 5 we present the results of RepLoc(HF) with single rule. We report the A@10, P@10, R@10, and MAP of the ve rules that perform the best. Among the rules, the GZIP ARG rule achieves the highest accuracy rate. However, the A@10 value is below 30%, which is signi cantly outperformed by RepLoc(HF) that considers all the rules. Similar observations could be drawn for other performance metrics, which to some extent con rms the diverse-cause barrier.\nSecond, by comparing the results of RepLoc(FR+QA) against RepLoc(FR) in Table 4, we can con rm the usefulness of QA. As\nmentioned, RepLoc(FR) could be loosely considered the simulation of manual localization, which tries to match the problematic les with the di log contents. Over the Timestamps dataset, A@10 of RepLoc(FR) is 71.21%. With the augmentation of the query, A@10 improves to 76.41%. Moreover, when we combine RepLoc(FR+QA) with HF, the performance is further improved, i.e., A@10 of RepLoc achieves 82.90%, which implies that for over 80% of the unreproducible packages in the Timestamps dataset, at least one problematic le is located in the Top-10 list. Besides, similar results are obtained over the other datasets, i.e., RepLoc(HF) and RepLoc(FR) perform the worst, RepLoc(FR+QA) outperforms RepLoc(FR) considering the A@10 value, and RepLoc performs the best.\nAssociated with Table 4, we also conduct statistical tests, to draw con dent conclusions whether one algorithm outperforms the other. For the statistical test, we employ the Wilcoxon\u2019s signed rank test, with a null hypothesis stating that there exists no difference between the results of the algorithms in comparison. We consider the 95% con dence level (i.e., p-values below 0.05 are considered statistically signi cant), and adopt the P@10 and R@10 as the performance metrics. We do not consider the accuracy rate and the MAP metrics, in that these are aggregate metrics. Over all the instances, when comparing RepLoc with any of the other three baseline variants, the null hypothesis is rejected (p-value < 0.05 for both P@10 and R@10), which implies that RepLoc outperforms their baseline variants in a statistically signi cant way.\nTo gain more insights into the behavior of RepLoc, we present the performance of the four variants against the number of retrieved results in Figure 9, over typical datasets. In the gure, the x-axis and the y-axis indicate the number of retrieved les, and the performance metrics. From the sub- gures, we con rm that over both the datasets, RepLoc outperforms the other variants signi cantly, i.e., the performance curves for RepLoc lie above those for other variants, which implies that for all the cases of the retrieved results, combining the two components is able to obtain be er results. is phenomenon conforms with our observations in Table 4.\nAnswer to RQ2: By comparing the variants of RepLoc over 671 real world packages, we con rm that by combining the heuristic\nrule-based lter and the query augmentation, RepLoc is able to outperform its variants."
        },
        {
            "heading": "4.6 Investigation of RQ3",
            "text": "In this RQ, we evaluate RepLoc from the e ciency perspectives. Since manually localizing the unreproducible issues is a time consuming task, automating such process is pro table only if the proposed approach is time e cient. Hence, we present the time statistics of the experiments. Figure 10 depicts the statistics of the source les as histograms, in which the x-axis indicates the number of source les ( leNum) and the words (wordNum), and the y-axis represents the associated frequency. In this study, the number of les ranges within [6, 19890], and the number of words for the majority of the packages ranges around 1 \u00d7 104, which implies that manually inspecting the les would be di cult.\nSince the scale of the packages in this study varies greatly, it is intuitive that the localization process over di erent packages will vary accordingly. To investigate this issue, we present the results related to time e ciency considering the three variants of RepLoc. In Figure 11, we illustrate the distributions of the dataset scalability and the execution time. In the sub- gures, the x-axis indicates the time in seconds, and the y-axis represents the frequency. From the results, we observe that, the indexing of the documents consumes the largest portion of time, compared with other components. In particular, the median of the execution time for RepLoc is 5.14 seconds.\nAnswer to RQ3: In this RQ, we investigate the e ciency perspectives of RepLoc. In this study, the indexing of the document consume the majority of the time."
        },
        {
            "heading": "4.7 Investigation of RQ4",
            "text": "For RQ1\u2013RQ3, to evaluate the performance of RepLoc properly, we employ the packages that have been xed, and adopt the patches from the BTS as the ground truth. However, in the real-world\nreproducible validation scenario, the patches are not available in advance. Hence, in this RQ, we intend to investigate RepLoc under such condition. More speci cally, we consider two scenarios, i.e., we apply RepLoc to the packages over (1) Debian packages that are previously un xed, and (2) the unreproducible packages from Guix.\nFirst, we are interested in whether RepLoc could be generalized to un xed packages, which are obtained from the continuous integration system of Debian. We also check the BTS, to ensure that the packages have not been xed. We apply RepLoc to localize the problematic les, and then manually check and x the unreproducible issues. rough localization and xing, 3 unreproducible packages belonging to the Timestamps category are xed, i.e., regina-rexx (3.6-2), fonts-uralic (0.0.20040829-5), and manpages-tr (1.0.5.1- 2). We submit the corresponding patches to the BTS [3\u20135], and the one for fonts-uralic has been accepted.\nFor these packages, the problematic les are ranked among the top of the retrieved list by RepLoc. For example, in Table 6, we present the results over the package manpages-tr. e table is organized similarly as Table. 3. From the table, we observe that RepLoc is able to localize problematic les e ectively, i.e., the problematic les are ranked the rst in the result. e package is unreproducible due to the invocation of gzip without \u201c-n\u201d, and the issue can be captured by the GZIP ARG rule in \u201c/source/manderle.sh\u201d. However, since the heuristic rules fail to capture the dynamic aspect of the build process, a le (\u201c/source/man1/gzip.1.xml\u201d) unused during compilation is also retrieved. In contrast, with FR and QA, we concentrate on the les involved by the build process. By combining both the static (HF) and the dynamic (HF and QA) perspectives, the problematic le is ranked the rst of the list with higher probability.\nSecond, we consider the packages from the Guix repository, to investigate whether the knowledge obtained from Debian could be generalized to other repositories. e reasons we choose Guix are that, (1) the repository is interested in the reproducible builds practice [23], and (2) its package manager provides the functionality of validating package reproducibility locally, which facilitates the experimental design. As a demonstration, we localize and manually x the problematic les of 3 packages, namely libjpeg-turbo (1.5.2), djvulibre (3.5.27), and skalibs (2.3.10.0). Similar with the previous case, the patches were submi ed to Guix\u2019s BTS [8\u201310]. Taking skalibs as an example, we present the results of the variants of RepLoc in Table 7. From the table, we could observe that the problematic le \u201c/Makefile\u201d is assigned the top rank. Contrarily, without RepLoc, over 900 source les have to be manually\ntraversed. Such observation to some extent demonstrates the usefulness of RepLoc in leveraging the knowledge from Debian to a di erent repository such as Guix. A er localizing the problematic le and manually xing, the submi ed patch has been accepted and pushed into the code base of Guix [10]. Similarly, the patches for djvulibre [8] and libjpeg-turbo [9] have also been accepted.\nAnswer to RQ4: We demonstrate that RepLoc is helpful in localizing un xed unreproducible packages from both Debian and Guix. In particular, unreproducible issues of 6 packages from both repositories are xed under the guidance of RepLoc, which have not been xed before this study."
        },
        {
            "heading": "5 THREATS TO VALIDITY",
            "text": "ere are several objections a critical reader might raise to the evaluation presented in this study, among which the following two threats deserve special a ention.\nFirst, in this study, the heuristic rules in HF are summarized from Debian\u2019s documentation. Also, we leverage the build log gathered from the build process. Hence, some may argue that the approach cannot be generalized to other so ware repositories because it relies too much on Debian\u2019s infrastructure. To mitigate this threat, in RepLoc, a ention is paid so that the components are not specialized for Debian. For example, despite knowing that the Debian rules les take the largest portion of the problematic les (see Figure 7(b)), no extra priority is given to these les during ranking. Also, in HF, we avoid using heuristic rules speci c to Debian, and intend to make the rules as general as possible. For instance, UNSORTED WILDCARD is applicable for Make le based build systems, and GZIP ARG is helpful if gzip-based compression is involved. As a result, the results of this study can be generalized to other repositories. As demonstrated in RQ4, we have successfully applied RepLoc to Guix. For other repositories, applying RepLoc should only require minor adaptation. For example, for the Fedora project, the build log can be gathered by parsing the verbose output of the mock build tool, and the di log could be generated by diffoscope as well.\nSecond, when constructing the datasets, the unreproducible packages caused by the tool-chain issues are not considered. For these packages, the unreproducible issues are introduced by the depended packages rather than the current package. Hence, identi cation of the tool-chain issues is another challenging task that requires further manual investigation [7]. Besides, we should note that xing the tool-chain issues may help make more packages reproducible.\nFor example, when reproducible-related patches were accepted by gcc from upstream, around 200 unreproducible packages that depended on gcc became reproducible automatically [18]. We plan to explore the tool-chain issues in the future."
        },
        {
            "heading": "6 RELATEDWORK",
            "text": ""
        },
        {
            "heading": "6.1 Bug Localization Related Work",
            "text": "First, this study is closely related to the fault localization studies, especially the IR-based approaches.\nFor example, Zhou et al. [49] proposed a specialized VSM based approach, and consider the similarities between bug reports to localize buggy les. Wang et al. [44] propose a compositional model that integrates multiple variants of VSM. In particular, they model the composition of di erent VSM variants as a optimization problem, and apply a genetic algorithm to search for the suitable composition pa ern between VSM variants. Wang et al. [42] investigate the usefulness of IR-based fault localization techniques, and discover that the quality of the bug reports are crucial to the performance of localization tasks.\nMeanwhile, domain knowledge is utilized to improve the performance of IR-based bug localization techniques. Ye et al. [48] nd bug- xing frequency and bug- xing recency of source code les are helpful for bug localization. Saha et al. [38] nd the structure of bug reports and source code les are also good knowledge for bug localization. ey consider bug reports or source code les as documents with structured elds, e.g., summary and description, or le name, class name, and method name, respectively. Stacktrace information in bug report is also analyzed [33, 46] to improve the performance of bug localization. Besides, version histories [39, 40, 43] and similar bug reports [24] are proved to be useful.\nBesides, with the development of IR techniques, other text mining methodologies are also incorporated to support locating buggy les. For example, due to its e ectiveness, Latent Dirichlet Allocation (LDA) has gained its popularity in the eld of bug localization. Lukins et al. [31] propose a static LDA-based technique for automatic bug localization. Lam et al. [29] propose a localization framework HyLoc that combines deep learning and IR-based model. ey integrate deep neural network and a VSM variant, to complement the two standalone components. Experimental results over real world projects demonstrate that their proposed model outperforms the individual models. Rao et al. [35] propose an incremental framework to update the model parameters of the Latent Semantic Analysis, which is then applied to localize buggy les. Experiments over so ware libraries with ten years of version history validate their framework.\nHowever, despite the closeness to these studies, we should note that the problem in this study has its unique features. For example, the counterpart of the bug reports in IR-based fault localization, i.e., the di logs, are not su ciently informative to guide the retrieval."
        },
        {
            "heading": "6.2 Reproducible Build Related Work",
            "text": "To the best of our knowledge, there have not been studies on localizing les that cause unreproducible builds. However, there have been studies that address the importance of reproducible builds. For example, Wheeler [45] describes a practical technique named diverse double compiling. By compiling the source les twice with\ndi erent compilers, and verifying the compiled binaries, certain types of malicious a acks can be detected and prevented. According to Debian\u2019s documentation, this work partially motivates the reproducible builds practice [15]. Holler et al. [26] investigate the diverse compilation under embedded system, and experimentally quantify the e ciency of diverse compiling for so ware fault tolerance. Carnavalet and Mannan [25] conduct an empirical study, focusing on the reproducible builds in the context of security-critical so ware. Based on the experiments on the encryption tool TrueCrypt, they summarize the challenges of reproducibility in practice. Ruiz et al. [36] address the reproducibility in cloud computing. ey adopt the term reconstructable so ware, and propose a prototype to simplify the creation of reliable distributed so ware.\nIn this study, we focus on the localization task for unreproducible builds, which has not been addressed in the existing studies."
        },
        {
            "heading": "7 CONCLUSIONS",
            "text": "In this study, we investigate the localization task for unreproducible builds. We present components that consider heuristic knowledge, similarity based information, as well as their integration as RepLoc. For empirical validation, we create four categories of publicly available datasets with 671 unreproducible packages from Debian. Extensive experiments reveal that RepLoc is able to e ectively localize the les that lead to unreproducible builds. Furthermore, with the help of RepLoc, we successfully identi ed and xed 6 new unreproducible packages from Debian and Guix.\nFor the future work, we are interested in the localization of problematic les for the tool-chain related issues. Also, inspired by the record-and-play techniques [34] from the crash reproduction based debugging research [27, 47], it would be interesting to leverage these techniques to detect more accurate correspondence between the build commands executed and the built binaries."
        },
        {
            "heading": "ACKNOWLEDGEMENTS",
            "text": "is work is supported in part by the National Natural Science Foundation of China under Grants 61772107, 61722202, 61502345, and 61403057, and in part by the Fundamental Research Funds for the Central Universities under Grant DUT16RC(4)62."
        }
    ],
    "title": "Automated Localization for Unreproducible Builds",
    "year": 2018
}