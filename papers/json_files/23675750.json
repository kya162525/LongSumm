{
    "abstractText": "Software development includes diverse tasks such as implementing new features, analyzing requirements, and fixing bugs. Being an expert in those tasks requires a certain set of skills, knowledge, and experience. Several studies investigated individual aspects of software development expertise, but what is missing is a comprehensive theory. We present a first conceptual theory of software development expertise that is grounded in data from a mixed-methods survey with 335 software developers and in literature on expertise and expert performance. Our theory currently focuses on programming, but already provides valuable insights for researchers, developers, and employers. The theory describes important properties of software development expertise and which factors foster or hinder its formation, including how developers\u2019 performance may decline over time. Moreover, our quantitative results show that developers\u2019 expertise self-assessments are context-dependent and that experience is not necessarily related to expertise.",
    "authors": [
        {
            "affiliations": [],
            "name": "Sebastian Baltes"
        },
        {
            "affiliations": [],
            "name": "Stephan Diehl"
        }
    ],
    "id": "SP:c6c67d56f9ba8ddd953d915863750e45921d2e96",
    "references": [
        {
            "authors": [
                "Phillip L. Ackerman",
                "Margaret E. Beier"
            ],
            "title": "Methods for Studying the Structure of Expertise: Psychometric Approaches",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "AdnanAziz",
                "Tsung-Hsien Lee",
                "Amit Prakash"
            ],
            "title": "Elements of Programming Interviews",
            "venue": "CreateSpace Independent Publishing Platform",
            "year": 2012
        },
        {
            "authors": [
                "Sebastian Baltes",
                "Stephan Diehl"
            ],
            "title": "Worse Than Spam: Issues In Sampling Software Developers",
            "venue": "In 10th International Symposium on Empirical Software Engineering and Measurement (ESEM",
            "year": 2016
        },
        {
            "authors": [
                "Sebastian Baltes",
                "Stephan Diehl"
            ],
            "title": "Towards a Theory of Software Development Expertise \u2014 Supplementary Material",
            "year": 2018
        },
        {
            "authors": [
                "Tanja Gabriele Baudson",
                "Franzis Preckel"
            ],
            "title": "mini-q: Intelligenzscreening in drei Minuten",
            "venue": "Diagnostica 62,",
            "year": 2016
        },
        {
            "authors": [
                "Sarah Beecham",
                "Nathan Baddoo",
                "Tracy Hall",
                "Hugh Robinson",
                "Helen Sharp"
            ],
            "title": "Motivation in Software Engineering: A systematic literature review",
            "venue": "Information and Software Technology 50,",
            "year": 2008
        },
        {
            "authors": [
                "Gunnar R. Bergersen",
                "Dag I.K. Sjoberg",
                "Tore Dyba"
            ],
            "title": "Construction and Validation of an Instrument for Measuring Programming Skill",
            "venue": "IEEE Transactions on Software Engineering 40,",
            "year": 2014
        },
        {
            "authors": [
                "Ricardo Britto",
                "Darja Smite",
                "Lars-Ola Damm"
            ],
            "title": "Experiences from Measuring Learning and Performance in Large-Scale Distributed Software Development",
            "venue": "In 10th International Symposium on Empirical Software Engineering and Measurement (ESEM",
            "year": 2016
        },
        {
            "authors": [
                "Pierre Carbonnelle"
            ],
            "title": "PYPL PopularitY of Programming Language: March 2016",
            "venue": "http://pypl.github.io/PYPL.html",
            "year": 2016
        },
        {
            "authors": [
                "Michelene T.H. Chi"
            ],
            "title": "Two Approaches to the Study of Expert\u2019s Characteristics",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "Earl Chrysler"
            ],
            "title": "Some Basic Determinants of Computer Programming Productivity",
            "venue": "Communications of the ACM 21,",
            "year": 1978
        },
        {
            "authors": [
                "K. Alec Chrystal",
                "Paul D. Mizen"
            ],
            "title": "Goodhart\u2019s law: Its origins, meaning and implications for monetary policy. Central banking, monetary theory and practice",
            "venue": "Essays in honour of Charles Goodhart",
            "year": 2003
        },
        {
            "authors": [
                "Norman Cliff"
            ],
            "title": "Dominance statistics: Ordinal analyses to answer ordinal questions",
            "venue": "Psychological bulletin 114,",
            "year": 1993
        },
        {
            "authors": [
                "D. Coleman",
                "D. Ash",
                "B. Lowther",
                "P. Oman"
            ],
            "title": "Using metrics to evaluate software system maintainability",
            "venue": "Computer 27,",
            "year": 1994
        },
        {
            "authors": [
                "Juliet Corbin",
                "Anselm Strauss"
            ],
            "title": "Basics of qualitative research (3rd ed.)",
            "venue": "SAGE Publications",
            "year": 2008
        },
        {
            "authors": [
                "Shirley Cruz",
                "Fabio Q.B. da Silva",
                "Luiz Fernando Capretz"
            ],
            "title": "Forty years of research on personality in software engineering: A mapping study",
            "venue": "Computers in Human Behavior",
            "year": 2015
        },
        {
            "authors": [
                "Bill Curtis"
            ],
            "title": "Fifteen years of psychology in software engineering: Individual differences and cognitive science",
            "venue": "In 7th International Conference on Software Engineering",
            "year": 1984
        },
        {
            "authors": [
                "Oscar Dieste",
                "Alejandrina M. Aranda",
                "Fernando Uyaguari",
                "Burak Turhan",
                "Ayse Tosun",
                "Davide Fucci",
                "Markku Oivo",
                "Natalia Juristo"
            ],
            "title": "Empirical evaluation of the effects of experience on code quality and programmer productivity: An exploratory study",
            "venue": "Empirical Software Engineering 22,",
            "year": 2017
        },
        {
            "authors": [
                "Stuart E. Dreyfus"
            ],
            "title": "The five-stage model of adult skill acquisition",
            "venue": "Bulletin of science, technology & society 24,",
            "year": 2004
        },
        {
            "authors": [
                "Stuart E. Dreyfus",
                "Hubert L. Dreyfus"
            ],
            "title": "A five-stage model of the mental activities involved in directed skill acquisition",
            "year": 1980
        },
        {
            "authors": [
                "Alastair Dunsmore",
                "Marc Roper"
            ],
            "title": "A comparative evaluation of program comprehension measures",
            "venue": "Department of Computer Science, University of Strathclyde",
            "year": 2000
        },
        {
            "authors": [
                "K. Anders Ericsson"
            ],
            "title": "An Introduction to Cambridge Handbook of Expertise and Expert Performance: Its Development, Organization, and Content",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "K. Anders Ericsson"
            ],
            "title": "The Influence of Experience and Deliberate Practice on the Development of Superior Expert Performance",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "K. Anders Ericsson",
                "Ralf T. Krampe",
                "Clemens Tesch-R\u00f6mer"
            ],
            "title": "The role of deliberate practice in the acquisition of expert performance",
            "venue": "Psychological review 100,",
            "year": 1993
        },
        {
            "authors": [
                "K. Anders Ericsson",
                "Michael J. Prietula",
                "Edward T. Cokely"
            ],
            "title": "The making of an expert. Harvard business review",
            "year": 2007
        },
        {
            "authors": [
                "K. Anders Ericsson",
                "Jacqui Smith"
            ],
            "title": "Prospects and limits of the empirical study of expertise: An introduction",
            "venue": "Prospects and limits",
            "year": 1991
        },
        {
            "authors": [
                "Paul J. Feltovich",
                "Michael J. Prietula",
                "K. Anders Ericsson"
            ],
            "title": "Studies of Expertise from Psychological Perspectives",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "Norman Fenton",
                "James Bieman"
            ],
            "title": "Software Metrics: A Rigorous and Practical Approach",
            "year": 2015
        },
        {
            "authors": [
                "Thomas Fritz",
                "Gail C. Murphy",
                "Emily Hill"
            ],
            "title": "Does a Programmer\u2019s Activity Indicate Knowledge of Code",
            "venue": "European Software Engineering Conference and ACM SIGSOFT International Symposium on Foundations of Software Engineering (ESEC/FSE",
            "year": 2007
        },
        {
            "authors": [
                "Ron Garland"
            ],
            "title": "The Mid-Point on a Rating Scale: Is it Desirable",
            "venue": "Marketing Bulletin 2, Research Note",
            "year": 1991
        },
        {
            "authors": [
                "Barney G. Glaser",
                "Anselm L. Strauss"
            ],
            "title": "The Discovery of Grounded Theory: Strategies for Qualitative Research",
            "venue": "Aldine Transaction",
            "year": 1967
        },
        {
            "authors": [
                "Lewis R. Goldberg"
            ],
            "title": "A broad-bandwidth, public domain, personality inventory measuring the lower-level facets of several five-factor models",
            "venue": "Personality psychology in Europe 7,",
            "year": 1999
        },
        {
            "authors": [
                "Charles A.E. Goodhart"
            ],
            "title": "Monetary Theory and Practice: The UK Experience",
            "year": 1984
        },
        {
            "authors": [
                "Georgios Gousios"
            ],
            "title": "The GHTorrent dataset and tool suite",
            "venue": "In 10th International Working Conference on Mining Software Repositories (MSR",
            "year": 2013
        },
        {
            "authors": [
                "Daniel Graziotin",
                "Xiaofeng Wang",
                "Pekka Abrahamsson"
            ],
            "title": "How do you feel, developer? An explanatory theory of the impact of affects on programming performance",
            "venue": "PeerJ Computer Science",
            "year": 2015
        },
        {
            "authors": [
                "Shirley Gregor"
            ],
            "title": "The nature of theory in information systems",
            "venue": "MIS quarterly 30,",
            "year": 2006
        },
        {
            "authors": [
                "Lucas Gren"
            ],
            "title": "The Links Between Agile Practices, Interpersonal Conflict, and Perceived Productivity",
            "venue": "In 21st International Conference on Evaluation and Assessment in Software Engineering",
            "year": 2017
        },
        {
            "authors": [
                "David Z. Hambrick",
                "Elizabeth J. Meinz"
            ],
            "title": "Limits on the Predictive Power of Domain-Specific Experience and Knowledge in Skilled Performance",
            "venue": "Current Directions in Psychological Science 20,",
            "year": 2011
        },
        {
            "authors": [
                "Jo E. Hannay",
                "Dag I.K. Sjoberg",
                "Tore Dyba"
            ],
            "title": "A systematic review of theory use in software engineering experiments",
            "venue": "IEEE Transactions on Software Engineering",
            "year": 2007
        },
        {
            "authors": [
                "James D. Herbsleb",
                "Audris Mockus"
            ],
            "title": "Formulation and preliminary test of an empirical theory of coordination in software engineering",
            "venue": "In 4th European Software Engineering Conference and ACM SIGSOFT International Symposium on Foundations of Software Engineering (ESEC/FSE",
            "year": 2003
        },
        {
            "authors": [
                "Dennis E. Hinkle",
                "WilliamWiersma",
                "Stephen G. Jurs"
            ],
            "title": "Applied statistics for the behavioral sciences",
            "venue": "Rand McNally College Publishing",
            "year": 1979
        },
        {
            "authors": [
                "Vera Hoorens"
            ],
            "title": "Self-enhancement and superiority biases in social comparison",
            "venue": "European review of social psychology 4,",
            "year": 1993
        },
        {
            "authors": [
                "Andy Hunt"
            ],
            "title": "Pragmatic Thinking and Learning: Refactor Your Wetware. Pragmatic bookshelf",
            "year": 2008
        },
        {
            "authors": [
                "Earl Hunt"
            ],
            "title": "Expertise, Talent, and Social Encouragement",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "R. Burke Johnson",
                "Anthony J. Onwuegbuzie",
                "Lisa A. Turner"
            ],
            "title": "Toward a definition of mixed methods research",
            "venue": "Journal of mixed methods research 1,",
            "year": 2007
        },
        {
            "authors": [
                "Capers Jones"
            ],
            "title": "Applied Software Measurement: Global Analysis of Productivity and Quality (3 ed.). McGraw-Hill Education",
            "year": 2008
        },
        {
            "authors": [
                "Huzefa H. Kagdi",
                "Maen Hammad",
                "Jonathan I. Maletic"
            ],
            "title": "Who can help me with this source code change",
            "venue": "In 24th IEEE International Conference on Software Maintenance (ICSM",
            "year": 2008
        },
        {
            "authors": [
                "Eirini Kalliamvakou",
                "Christian Bird",
                "Thomas Zimmermann",
                "Andrew Begel",
                "Robert DeLine",
                "Daniel M. German"
            ],
            "title": "What Makes a Great Manager of Software Engineers",
            "venue": "IEEE Transactions on Software Engineering Early Access Articles,",
            "year": 2017
        },
        {
            "authors": [
                "Barbara A. Kitchenham",
                "Shari Lawrence Pfleeger",
                "Lesley M. Pickard",
                "Peter W. Jones",
                "David C. Hoaglin",
                "Khaled El Emam",
                "Jarrett Rosenberg"
            ],
            "title": "Preliminary guidelines for empirical research in software engineering",
            "venue": "IEEE Transactions on Software Engineering 28,",
            "year": 2002
        },
        {
            "authors": [
                "Andrew J. Ko",
                "Bob Uttl"
            ],
            "title": "Individual differences in program comprehension strategies in unfamiliar programming systems",
            "venue": "In 11th International ESEC/FSE \u201918,",
            "year": 2003
        },
        {
            "authors": [
                "Ralf Th. Krampe andNeil Charness"
            ],
            "title": "Aging and Expertise",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "Philippe Kruchten",
                "Robert L. Nord",
                "Ipek Ozkaya"
            ],
            "title": "Technical debt: From metaphor to theory and practice",
            "venue": "IEEE Software",
            "year": 2012
        },
        {
            "authors": [
                "Justin Kruger",
                "David Dunning"
            ],
            "title": "Unskilled and unaware of it: How difficulties in recognizing one\u2019s own incompetence lead to inflated self-assessments",
            "venue": "Journal of Personality and Social Psychology 77,",
            "year": 1999
        },
        {
            "authors": [
                "Ann Langley"
            ],
            "title": "Strategies for theorizing from process data",
            "venue": "Academy of management review 24,",
            "year": 1999
        },
        {
            "authors": [
                "Thomas D. LaToza",
                "Gina Venolia",
                "Robert DeLine"
            ],
            "title": "Maintaining mental models: A study of developer work habits",
            "venue": "In 28th International Conference on Software Engineering",
            "year": 2006
        },
        {
            "authors": [
                "Paul Luo Li",
                "Andrew J. Ko",
                "Jiamin Zhu"
            ],
            "title": "What Makes A Great Software Engineer",
            "venue": "In 37th International Conference on Software Engineering",
            "year": 2015
        },
        {
            "authors": [
                "Wolfgang Lutz",
                "Warren Sanderson",
                "Sergei Scherbov"
            ],
            "title": "The coming acceleration of global population ageing",
            "venue": "Nature 451,",
            "year": 2008
        },
        {
            "authors": [
                "David Ma",
                "David Schuler",
                "Thomas Zimmermann",
                "Jonathan Sillito"
            ],
            "title": "Expert Recommendation with Usage Expertise",
            "venue": "In 25th IEEE International Conference on Software Maintenance (ICSM",
            "year": 2009
        },
        {
            "authors": [
                "M. Lynne Markus",
                "Daniel Robey"
            ],
            "title": "Information technology and organizational change: Causal structure in theory and research",
            "venue": "Management science 34,",
            "year": 1988
        },
        {
            "authors": [
                "Antoinette McCallin"
            ],
            "title": "Grappling with the literature in a grounded theory study",
            "venue": "Contemporary Nurse 15,",
            "year": 2003
        },
        {
            "authors": [
                "David C. McClelland"
            ],
            "title": "Human motivation",
            "year": 1987
        },
        {
            "authors": [
                "Robert R. McCrae",
                "Oliver P. John"
            ],
            "title": "An Introduction to the Five-Factor Model and Its Applications",
            "venue": "Journal of Personality 60,",
            "year": 1992
        },
        {
            "authors": [
                "David W. McDonald",
                "Mark S. Ackerman"
            ],
            "title": "Expertise recommender: A flexible recommendation system and architecture",
            "venue": "In Proceeding on the 2000 ACM Conference on Computer Supported Cooperative Work (CSCW",
            "year": 2000
        },
        {
            "authors": [
                "Gayle Laakmann McDowell"
            ],
            "title": "Cracking the Coding Interview (5th ed.)",
            "year": 2014
        },
        {
            "authors": [
                "Sharan B. Merriam",
                "Rosemary S. Caffarella",
                "Lisa M. Baumgartner"
            ],
            "title": "Learning in Adulthood: A Comprehensive Guide (3 ed.)",
            "year": 2007
        },
        {
            "authors": [
                "Andre N. Meyer",
                "Laura E. Barton",
                "Gail C. Murphy",
                "Thomas Zimmermann",
                "Thomas Fritz"
            ],
            "title": "The Work Life of Developers: Activities, Switches and Perceived Productivity",
            "venue": "IEEE Transactions on Software Engineering 43,",
            "year": 2017
        },
        {
            "authors": [
                "Andre N. Meyer",
                "Gail C. Murphy",
                "Thomas Zimmermann",
                "Thomas Fritz"
            ],
            "title": "Design Recommendations for Self-Monitoring in the Workplace: Studies in Software Development",
            "venue": "Proceedings of the ACM on Human-Computer Interaction",
            "year": 2017
        },
        {
            "authors": [
                "Harald A. Mieg"
            ],
            "title": "Social and Sociological Factors in the Development of Expertise",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "Audris Mockus",
                "James D. Herbsleb"
            ],
            "title": "Expertise browser: A quantitative approach to identifying expertise",
            "venue": "In 24th International Conference on Software Engineering",
            "year": 2002
        },
        {
            "authors": [
                "John Mongan",
                "Eric Gigure",
                "Noah Kindler"
            ],
            "title": "Programming interviews exposed (3rd ed.)",
            "year": 2013
        },
        {
            "authors": [
                "Patrick Morrison",
                "Emerson Murphy-Hill"
            ],
            "title": "Is programming knowledge related to age? An exploration of Stack Overflow",
            "venue": "In 10th International Working Conference on Mining Software Repositories (MSR",
            "year": 2013
        },
        {
            "authors": [
                "Janice M. Morse"
            ],
            "title": "Sampling in grounded theory",
            "venue": "In The SAGE Handbook of Grounded Theory",
            "year": 2007
        },
        {
            "authors": [
                "Stephan J. Motowidlo",
                "Walter C. Borman",
                "Mark J. Schmit"
            ],
            "title": "A Theory of Individual Differences in Task and Contextual Performance",
            "venue": "Human Performance 10,",
            "year": 1997
        },
        {
            "authors": [
                "Adolfo Pena"
            ],
            "title": "The Dreyfus model of clinical problem-solving skills acquisition: A critical perspective",
            "venue": "Medical Education Online",
            "year": 2010
        },
        {
            "authors": [
                "Paul Ralph"
            ],
            "title": "Toward Methodological Guidelines for Process Theories and Taxonomies in Software Engineering",
            "venue": "IEEE TSE Early Access",
            "year": 2018
        },
        {
            "authors": [
                "Romain Robbes",
                "David Rothlisberger"
            ],
            "title": "Using Developer Interaction Data to Compare Expertise Metrics",
            "venue": "In 10th International Working Conference on Mining Software Repositories (MSR",
            "year": 2013
        },
        {
            "authors": [
                "S. Ian Robertson"
            ],
            "title": "Problem Solving: Perspectives from Cognition and Neuroscience (2 ed.)",
            "year": 2016
        },
        {
            "authors": [
                "Pierre N. Robillard"
            ],
            "title": "The Role of Knowledge in Software Development",
            "venue": "Communications of the ACM 42,",
            "year": 1999
        },
        {
            "authors": [
                "D. Rodr\u00edguez",
                "M.A. Sicilia",
                "E. Garc\u00eda",
                "R. Harrison"
            ],
            "title": "Empirical findings on team size and productivity in software development",
            "venue": "Journal of Systems and Software 85,",
            "year": 2012
        },
        {
            "authors": [
                "Richard M. Ryan",
                "Edward L. Deci"
            ],
            "title": "Self-determination theory and the facilitation of intrinsic motivation, social development, and well-being",
            "venue": "American Psychologist 55,",
            "year": 2000
        },
        {
            "authors": [
                "Johnny Saldana"
            ],
            "title": "The coding manual for qualitative researchers",
            "year": 2015
        },
        {
            "authors": [
                "Felix D. Schonbrodt",
                "Friederike X.R. Gerstenberg"
            ],
            "title": "An IRT analysis of motive questionnaires: The unified motive scales",
            "venue": "Journal of Research in Personality 46,",
            "year": 2012
        },
        {
            "authors": [
                "Norbert Schwarz",
                "Daphna Oyserman"
            ],
            "title": "Asking questions about behavior: Cognition, communication, and questionnaire construction",
            "venue": "American Journal of Evaluation 22,",
            "year": 2001
        },
        {
            "authors": [
                "Ben Shneiderman",
                "Richard Mayer"
            ],
            "title": "Syntactic/Semantic Interactions in Programmer Behavior: A Model and Experimental Results",
            "venue": "International Journal of Computer and Information Sciences",
            "year": 1979
        },
        {
            "authors": [
                "Janet Siegmund",
                "Christian Kaestner",
                "Joerg Liebig",
                "Sven Apel",
                "Stefan Hanenberg"
            ],
            "title": "Measuring and modeling programming experience",
            "venue": "Empirical Software Engineering 19,",
            "year": 2014
        },
        {
            "authors": [
                "Janice Singer",
                "Timothy C. Lethbridge",
                "Norman G. Vinson",
                "Nicolas Anquetil"
            ],
            "title": "An examination of software engineeringwork practices",
            "venue": "Conference of the Centre for Advanced Studies on Collaborative Research (CASCON",
            "year": 1997
        },
        {
            "authors": [
                "Dag I.K. Sjoberg",
                "Tore Dyba",
                "Bente C.D. Anda",
                "Jo E. Hannay"
            ],
            "title": "Building theories in software engineering",
            "venue": "In Guide to Advanced Empirical Software Engineering",
            "year": 2008
        },
        {
            "authors": [
                "Sabine Sonnentag"
            ],
            "title": "Excellent software professionals: Experience, work activities, and perception by peers",
            "venue": "Behaviour & Information Technology 14,",
            "year": 1995
        },
        {
            "authors": [
                "Sabine Sonnentag"
            ],
            "title": "Expertise in professional software design: A process study",
            "venue": "Journal of Applied Psychology 83,",
            "year": 1998
        },
        {
            "authors": [
                "Sabine Sonnentag",
                "Cornelia Niessen",
                "Judith Volmer"
            ],
            "title": "Expertise in Software Design",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "Lauren A. Sosniak"
            ],
            "title": "Retrospective Interviews in the Study of Expertise and Expert Performance",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "Abbas Tashakkori",
                "Charles Teddlie"
            ],
            "title": "Mixed methodology: Combining qualitative and quantitative approaches",
            "year": 1998
        },
        {
            "authors": [
                "Robert Thornberg"
            ],
            "title": "Informed grounded theory",
            "venue": "Scandinavian Journal of Educational Research 56,",
            "year": 2012
        },
        {
            "authors": [
                "Dennis Tourish",
                "Owen Hargie"
            ],
            "title": "Motivating critical upward communication: A key challenge for management decision making",
            "venue": "In Key Issues in Organizational Communication",
            "year": 2003
        },
        {
            "authors": [
                "Christoph Treude",
                "Fernando Figueira Filho",
                "Uir\u00e1 Kulesza"
            ],
            "title": "Summarizing and measuring development activity",
            "venue": "European Software Engineering Conference and ACM SIGSOFT International Symposium on Foundations of Software Engineering (ESEC/FSE",
            "year": 2015
        },
        {
            "authors": [
                "Andrew H. van de Ven"
            ],
            "title": "Nothing is quite so practical as a good theory",
            "venue": "Academy of management review 14,",
            "year": 1989
        },
        {
            "authors": [
                "Andrew H. van de Ven",
                "Marshall Scott Poole"
            ],
            "title": "Explaining development and change in organizations",
            "venue": "Academy of management review 20,",
            "year": 1995
        },
        {
            "authors": [
                "Bogdan Vasilescu",
                "Vladimir Filkov",
                "Alexander Serebrenik"
            ],
            "title": "StackOverflow and GitHub: Associations between Software Development and Crowdsourced Knowledge",
            "venue": "In 2013 International Conference on Social Computing (SocialCom",
            "year": 2013
        },
        {
            "authors": [
                "Adriana Santarosa Vivacqua",
                "Henry Lieberman"
            ],
            "title": "Agents to assist in finding help",
            "year": 2000
        },
        {
            "authors": [
                "Karl E. Weick"
            ],
            "title": "Theory Construction as Disciplined Imagination",
            "venue": "Academy of management review 14,",
            "year": 1989
        },
        {
            "authors": [
                "Robert W. Weisberg"
            ],
            "title": "Modes of Expertise in Creative Thinking: Evidence from Case Studies",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        },
        {
            "authors": [
                "Lawrence G.Weiss",
                "Donald H. Saklofske",
                "Diane Coalson",
                "Susan Engi Raiford"
            ],
            "title": "WAIS-IV clinical use and interpretation: Scientist-practitioner perspectives",
            "year": 2010
        },
        {
            "authors": [
                "Minghui Zhou",
                "Audris Mockus"
            ],
            "title": "Developer Fluency: Achieving True Mastery in Software Projects",
            "venue": "In 18th ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE",
            "year": 2010
        },
        {
            "authors": [
                "Barry J. Zimmerman"
            ],
            "title": "Development and Adaption of Expertise: The Role of Self-Regulatory Processes and Beliefs",
            "venue": "In The Cambridge Handbook of Expertise and Expert Performance",
            "year": 2006
        }
    ],
    "sections": [
        {
            "text": "CCS CONCEPTS \u2022 Software and its engineering;\nKEYWORDS software engineering, expertise, theory, psychology ACM Reference Format: Sebastian Baltes and Stephan Diehl. 2018. Towards a Theory of Software Development Expertise. In Proceedings of the 26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE \u201918), November 4\u20139, 2018, Lake Buena Vista, FL, USA.ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/3236024.3236061"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "An expert is, according to Merriam-Webster, someone \u201chaving or showing special skill or knowledge because of what [s/he has] been taught or what [s/he has] experienced\u201d [74]. K. Anders Ericsson, a famous psychologist and expertise researcher, defines expertise as \u201cthe characteristics, skills, and knowledge that distinguish experts from novices and less experienced people\u201d [26]. For some areas, such as playing chess, there exist representative tasks and objective criteria for identifying experts [26]. In software development, however, it is more difficult to find objective measures for quantifying\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ESEC/FSE \u201918, November 4\u20139, 2018, Lake Buena Vista, FL, USA \u00a9 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5573-5/18/11. . . $15.00 https://doi.org/10.1145/3236024.3236061\nexpert performance [78]. Bergersen et al. proposed an instrument to measure programming skill [9], but their approach may suffer from learning effects because it is based on a fixed set of programming tasks. Furthermore, aside from programming, software development involves many other tasks such as requirements engineering, testing, and debugging [62, 96, 100], in which a software development expert is expected to be good at.\nIn the past, researchers investigated certain aspects of software development expertise (SDExp) such as the influence of programming experience [95], desired attributes of software engineers [63], or the time it takes for developers to become \u201cfluent\u201d in software projects [117]. However, there is currently no theory combining those individual aspects. Such a theory could help structuring existing knowledge about SDExp in a concise and precise way and hence facilitate its communication [44]. Despite many arguments in favor of developing and using theories [46, 56, 85, 109], theory-driven research is not very common in software engineering [97].\nWith this paper, we contribute a theory that describes central properties of SDExp and important factors influencing its formation. Our goal was to develop a process theory, that is a theory intended to explain and understand \u201chow an entity changes and develops\u201d over time [85]. In our theory, the entities are individual software developers working on different software development tasks, with the long-term goal of becoming experts in those tasks. This fits the definition of a teleological process theory, where an entity \u201cconstructs an envisioned end state, takes action to reach it and monitors the progress\u201d [110]. The theory is grounded in data from a mixedmethods survey with 335 participants and in literature on expertise and expert performance. Our expertise model is task-specific, but includes the notion of transferable knowledge and experience from related fields or tasks. On a conceptual level, the theory focuses on factors influencing the formation of SDExp over time. It is a first step towards our long-term goal to build a variance theory [61, 67] to be able explain and predict why and when a software developer reaches a certain level of expertise [41, 85].\nThe theory can help researchers, software developers as well as employers. Researchers can use it to design studies related to expertise and expert performance, and in particular to reflect on the complex relationship between experience and expertise (see Section 6), which is relevant for many self-report studies. Software developers can learn which properties are distinctive for experts in their field, which behaviors may lead to becoming a better software developer, and which contextual factors could affect expertise development. If they are already \u201csenior\u201d, they can learn what other developers expect from good mentors or which effects age-related performance decline may have on them. Finally, employers can learn what typical reasons for demotivation among their employees are, hindering developers to improve, and how they can build a work environment supporting expertise development of their staff.\nar X\niv :1\n80 7.\n06 08\n7v 4\n[ cs\n.S E\n] 4\nN ov\n2 01\n8"
        },
        {
            "heading": "2 RESEARCH DESIGN",
            "text": "To describe our research design, we follow Tashakkori and Teddlie\u2019s methodology [104]. We designed a sequential mixed model study (type VIII) with three phases (see Figure 1). We started with an open online survey, which we sent out to a random sample of GitHub developers (S1) to build a preliminary grounded theory of SDExp (see Section 3). In a second phase, we combined the preliminary grounded theory from the first phase with existing literature on expertise and expert performance. The result of this combination of inductive and deductive methods [41] was a preliminary conceptional theory of SDExp (see Section 4). In a third phase, we designed a focused questionnaire to collect data for building a revised conceptual theory that describes certain concepts of the preliminary theory in more detail. We sent the focused questionnaire to two additional samples of software developers (S2 and S3). Like in the first phase, we analyzed the qualitative data from open-ended questions, this time mapping the emerging codes and categories to the preliminary conceptual theory.\nTo complement our qualitative analysis, we conducted a quantitative analysis investigating developers\u2019 self-assessment of programming expertise and its relation to experience (see Section 6). Please note that we planned the general research design, in particular the transitions between inductive and deductive steps [61], before collecting the data. We provide all questionnaires, coding schemes, and all non-confidential survey responses as supplementary material [6]."
        },
        {
            "heading": "3 PHASE 1: GROUNDED THEORY",
            "text": "The goal of the first phase of our research was to build a grounded theory (GT) of SDExp. The GT methodology, introduced by Glaser and Strauss in 1967 [36], is an approach to generate theory from qualitative data. Since its introduction, different approaches evolved: Glaser\u2019s school emphasized the inductive nature of GT,while Strauss and Corbin focused on systematic strategies and verification [13, 19]. The third and most recent school of GT, called constructivist GT, tried to find a middle ground between the two diverging schools by building upon the flexibility of Glaser and Strauss\u2019s original approach, combining it with constructivist epistemology [13].\nAll three schools rely on the process of coding that assigns \u201csummative, salient, essence-capturing\u201d words or phrases to portions of the unstructured data [91]. Those codes are iteratively and continuously compared, aggregated, and structured into higher levels of abstractions, the categories and concepts. This iterative process is called constant comparison. We followed Charmaz\u2019s constructivist approach, dividing the analysis process into three main phases: (1) initial coding, (2) focused coding and categorizing, and (3) theory building. The last step tries to draw connections between the abstract concepts that emerged from the data during the first two phases, generating a unifying theory. An important aspect of GT is that the abstractions can always be traced back to the raw data (grounding). In the first step, the initial coding, it is important to remain open and to stick closely to the data [13]. Glaser even suggests not to do a literature review before conducting GT research [68], which is a rather extreme and debatable position [105]. We decided to limited our literature review in the first phase to software engineering literature and postponed the integration of results from\npsychology literature to the second phase of our research. The main research questions guiding this phase were:\nRQ1: Which characteristics do developers assign to novices and which to experts? RQ2: Which challenges do developers face in their daily work?\nOur main area of interest were the characteristics developers assign to novices and experts (RQ1). However, as software development experts are expected to master complex tasks efficiently [117], we included a question about challenges developers face in their daily work (RQ2) to identify such tasks."
        },
        {
            "heading": "3.1 Survey Design and Sampling",
            "text": "To answer our research questions, we designed an online questionnaire, which we sent to a random sample of software developers. Our goal was to start open-minded, thus we primarily relied on open-ended questions for data collection. The questionnaire contained seven open-ended and four closed-ended questions related to SDExp plus seven demographic questions. To prevent too broad and general answers, we focused on expertise in one particular programming language. We chose Java, because at the time we designed the survey (October 2015) it was, according to various rankings, the most popular programming language [12, 106]. We analyzed all open-ended questions separately using Charmaz\u2019s grounded theory approach, performing all three constructivist GT phases (see above) on the survey answers. After deductively revising the resulting GT (see Section 4), we used theoretical sampling to collect more data on certain concepts and again performed those three GT phases, constantly comparing the new data to the data from the first iteration (see Section 5). We used the closed-ended questions to describe the samples and to analyze the relation between experience and (self-assessed) expertise (see Section 6).\nQualitative researchers often rely on convenience sampling for selecting their participants [5, 82]. However, we wanted to reach a diverse sample of novices and experts, which is hard to achieve with this sampling approach. Therefore, we drew our first sample randomly from all users who were active on both Stack Overflow (SO) and GitHub (GH) between January 1, 2014 and October 1, 2015. Both platforms are very popular among software developers and for both of them, demographic information about users is publicly available [111]. Another motivation for this sampling strategy was to be later able to correlate the self-assessments of developers with their activity on GH and SO.\nWe derived our sampling frame from the data dumps provided by Stack Exchange (August 18, 2015) [102] and GHTorrent (September 25, 2015) [39]. To match users on both platforms, we followed the approach of Vasilescu et al. [111], utilizing the MD5 hash value of users\u2019 email addresses. For the SO users, we retrieved the email\nhashes from an old data dump released September 10, 2013 where this information was directly available for all users. Further, for users who set a Gravatar URL in their profile, we extracted the email hash from there. In the end, we were able to retrieve the email hashes for 3.8 million SO users (75% of all users in the 2015 dataset). In the GHTorrent data dump, the email address was available for 6.6 million GH users (69% of all users in the dataset). To identify active users, we checked if they contributed to a question (asked, answered, or commented) on SO and committed to a project on GH since January 1, 2014. This resulted in a sampling frame with 71,400 unique users from which we drew a random sample of 1,000 users. In the following, S1 denotes this sample.\nThe first iteration of the questionnaire was online from October 13, 2015 until November 11, 2015. Of the 1,000 contacted users, 122 responded (12.2% response rate). Of the 122 respondents, 115 identified themselves as male, one as female and six did not provide their gender. The majority of respondents (67.2%) reported their main software development role to be software developer, the secondlargest group were software architects (13.9%). Most participants answered from Europe (49.2%) and North America (37.7%). Further demographic information can be found in Table 1."
        },
        {
            "heading": "3.2 Terminology",
            "text": "According to Sj\u00f8berg et al., the building blocks of theories are its core entities, the constructs, the relationships between these constructs, and the scope conditions that delineate a theory\u2019s application area [97]. To have a consistent terminology across the paper, we use the term concepts instead of constructs for the central elements of the presented theories.\nThe scope of all theories we built, including the GT, was to describe what constitutes SDExp and which factors influence its formation, focusing on individual developers. In the second phase (see Section 4), we added a task-specific notion of expertise and then revised the resulting preliminary theory in a second inductive step (see Section 5) to focus on programming-related tasks."
        },
        {
            "heading": "3.3 Concepts",
            "text": "Figure 2 shows the high-level concepts and relationships of the grounded theory that resulted from our qualitative analysis of all open-ended questions. Most answers regarding characteristics of experts and novices (RQ1) were either related to having a certain degree of knowledge in different areas or a certain amount or quality of experience. We marked those concepts that constitute SDExp in gray color. The factors contributing to the formation of SDExp, and the results of having a certain degree of SDExp, have a white background. Participants described typical behaviors, character traits, and skills of experts. Many answers mentioned properties that distinguish source code written by experts from source code written by novices. In our notion, the quality of source code is the result of having a certain level of knowledge and experience\nand thus a measure of expert performance. When asked about challenges (RQ2), participants often named time-pressure and unrealistic demands by managers or customers. Generally, most answers related to challenges were not technical, but referred to human factors. In the GT, we summarized these factors as work context.\nIn the following, we present the most frequent sub-categories of the concepts mentioned above. The concepts are in bold font, the (sub-)categories are in small capitals. We provide a full list of all categories and subcategories as supplementary material [6].\nExperience: Most statements that we assigned to this concept referred to the qantity of software development experience (e.g., in terms of years), but some also described itsqality. Examples for the latter include having built \u201ceverything from small projects to enterprise projects\u201d or \u201c[experience] with many codebases\u201d. In particular, participants considered professional experience, e.g., having \u201cshipped a significant amount of code to production or to a customer\u201d and working on shared code to be important factors.\nKnowledge: Since we specifically asked for Java, many answers were language-specific or referred to certain Java frameworks. Experts were described as having an \u201cintimate knowledge of the design and philosophy of the language\u201d (depth of knowledge), which includes knowing \u201cthe shortcomings of the language [...] or the implementation [...].\u201d Answers also indicated the importance of having a broad knowledge about algorithms, data structures, or different programming paradigms to bring \u201cthe wisdom of [...] other philosophies into Java\u201d.\nQuality of source code: Regarding the quality of source code, participants named several properties that source code of experts should possess: It should be well-structured and readable, contain \u201ccomments when necessary\u201d, be \u201coptimized\u201d in terms of performance and sustainable in terms of maintainability. One participant summarized the code that experts write as follows: \u201cEvery one can write Java code which a machine can read and process but the key lies in writing concise and understandable code which [...] people who have never used that piece of code before [can read].\u201d\nBehavior, character traits, and skills: For this concept, the most common categorywas communication skills. Experts should be willing to \u201cshare [their] knowledge with other developers\u201d, but they should also know when to \u201cask for help\u201d. Some participants\nmentioned the role of experts as teachers, e.g. to train \u201cyounger developers\u201d. Another category was (self-)reflection, meaning reflecting on problems (\u201cthinks before coding\u201d) as well as on own behavior (being \u201caware [of] what kind of mistakes he can make\u201d). Further, participants named problem-solving skills and attributes that we summarized in a category named being fast.\nWork context: Many participants mentioned problems related to people affecting their work. One participant put it this way: \u201cComputers are easy. People are hard.\u201d Salient were the comments about constant time pressure, often caused by customers or the management. Respondents found it challenging to maintain \u201cquality despite pressure to just make it work\u201d. One participant remarked that \u201csometimes non-software managers think of software like manufacturing: If 1 person works 400 parts in a day 10 should work 4000. But in software development, that analogy breaks down.\u201d There were also comments about team issues like \u201cgetting a big team of developers adopt common standards of coding, designing and unit testing.\u201d Participants also complained about the lack of well-defined reqirements and the importance of good communication: \u201c[...] User\u2019s cannot communicate what they want. [...] Project managers who talk to the users don\u2019t understand the implications by the requirements and mostly don\u2019t know enough of the business process the user lives every day. Hence, he cannot communicate the problem to the development team.\u201d"
        },
        {
            "heading": "3.4 Relationships",
            "text": "After structuring participants\u2019 answers into concepts, categories, and sub-categories, we looked at the answers again, trying to find meaningful relationships. The result of this process is depicted in Figure 2. In our notion, certain forms of behavior, and an individual developer\u2019s character traits and general skills make it more likely to gain the level of knowledge and experience to be considered an expert in software development, which then manifests itself in the quality of source code the developer creates. However, gained knowledge and experience also affect an individual\u2019s behavior and shapes other skills. Moreover, the work context, meaning, for example, the office, colleagues, customers, or the application domain of a project, influence the behavior and thus the formation of knowledge and experience.\nPhase 1: The grounded theory describes SDExp as a combination of a certain quantity and quality of knowledge and experience, both general and for a particular programming language. The work context, behavior, character traits, and skills influence the formation of expertise, which can be observed when experts write well-structured, readable, and maintainable source code."
        },
        {
            "heading": "4 PHASE 2: PRELIMINARY CONCEPTUAL THEORY",
            "text": "As described in our research design, the next step after inductively deriving a preliminary GT from the responses of the participants in our first sample was to deductively embed this GT in existing literature on expertise and expert performance. To this end, we reviewed psychology literature. Our main source was The Cambridge Handbook of Expertise and Expert Performance [28] including the\nreferenced literature. This handbook is the first [28], and to the best of our knowledge most comprehensive, book summarizing scientific knowledge on expertise and expert performance. The result of this deductive step was a task-specific conceptual theory of expertise development that is compatible with the grounded theory from the first phase. Figure 3 shows our preliminary conceptual theory, which we are going to present in this section.\nGenerally, process theories focus on events and try to find patterns among them, leading to a certain outcome\u2014variance theories describe a certain outcome as a relationship between dependent and independent variables [61]. The process that we describe with our conceptual theory is the formation of SDExp, that is the path of an individual software development novice towards becoming an expert. This path consists of gradual improvements with many corrections and repetitions [27], therefore we do not describe discrete steps like, for example, the 5-stage Dreyfus model of skill acquisition (see Section 6.2). Instead, we focus on the repetition of individual tasks. In phase 3, we extended our conceptual theory with a focus on programming-related tasks (see Section 5), but the general structure is flexible enough to be extended towards other software development tasks as well [62, 96, 100]. Even with a focus on programming expertise, the distinction between tasks is important. For example, an excellent Java programmer is not automatically an excellent Haskell programmer. Moreover, programming itself includes diverse tasks, such as implementing new features or fixing bugs, with a varying centrality and difficulty [117]."
        },
        {
            "heading": "4.1 Concepts",
            "text": "In the following, we will describe the concepts we deductively integrated into our grounded theory using literature on expertise and expert performance.\nIndividual differences and behavior: We split the GT concept behavior, character traits, and skills into individual differences and behavior. We modeled behavior as being relative to a certain task and as being influenced by individual differences [83] such as mental abilities, personality, and motivation, which have long been considered essential for general [11, 31, 43] and programming performance [21]. Even if the general intelligence is not a valid predictor for attaining expert performance in a domain [26], improvements are constrained by an individual\u2019s cognitive capacities [27]. Especially at the early stages of skill acquisition, general intelligence is in fact an important factor [58]. It is also known that mental abilities start to decline at a certain age [58]\nAcquiring expertise is not exclusively a cognitive matter\u201d [50]\u2014 developers\u2019 personality and motivation influence behaviors that may or may not lead to improvements of expertise [50, 101]. Generally, the term skill is defined as \u201can ability or proficiency acquired through training and practice\u201d [2]. Thus, according to that definition, being a good software developer is also a skill. However, in the scope of our theory, we limit the term skill to fundamental skills such as communication and social skills [2].\nTask context: In the GT, we described how the work context, including team members, managers, and customers, can influence developers\u2019 behavior. In the conceptual theory, we considered this context to be task-specific (e.g., communication with customers is more likely to happen during requirements analysis and communication with colleagues when refactoring an existing module). The task context captures all organizational, social [77], and technical constraints that are relevant for the task at hand.\nKnowledge and experience: Knowledge can be defined as a \u201cpermanent structure of information stored in memory\u201d [88]. Some researchers consider a developer\u2019s knowledge base as the most important aspect affecting their performance [21]. Studies with software developers suggest that \u201cthe knowledge base of experts is highly language dependent\u201d, but experts also have \u201cabstract, transferable knowledge and skills\u201d [100]. We modeled this aspect in our theory by dividing the central concepts knowledge and experience from the GT into a task-specific and a general part. This is a simplification of our model, because the relevance of knowledge and experience is rather a continuum than dichotomous states [114]. However, Shneiderman and Mayer, who developed a behavioral model of software development, used a similar differentiation between general (\u201csemantic\u201d) and specific (\u201csyntactical\u201d) knowledge [94]. General knowledge and experience does not only refer to technical aspects (e.g., low-level computer architecture) or general concepts (e.g., design patterns), but also to knowledge about and experience with successful strategies [57, 98, 99].\nPerformance, education, and monitoring: As mentioned in the introduction, it may be difficult to find objective measures for quantifying expert performance in software development. However, there exist manymetrics and measures that can be evaluated regarding their validity and reliability for measuring expert performance. Respondents from the first sample mentioned different characteristics of experts\u2019 source code, but also the time it takes to develop a solution. This is related to the area of program comprehension where task correctness and response time are two important measures [25]. At this point, our goal is not to treat performance as a dependent variable that we try to explain for individual tasks, we rather consider different performance monitoring approaches to be a means for feedback and self-reflection. For our long-term goal to build a variance theory for explaining and predicting the development of expertise, it will be more important to be able to accurately measure developers\u2019 performance.\nEducation and mentoring help building knowledge and thus contribute to the development of expertise [30]. Having a teacher or mentor is particularly important for deliberate practice [29, 30], which is a central aspect of our theory (see below)."
        },
        {
            "heading": "4.2 Relationships",
            "text": "The relationships in our theory are intentionally labeled with rather generic terms such as \u201caffects\u201d or \u201cgenerates\u201d, because more research is needed to investigate them. Nevertheless, we want to point out two central groups of relationships: deliberate practice and the influence of monitoring, feedback, and self-reflection.\nDeliberate practice: Having more experience with a task does not automatically lead to better performance [29]. Research has shown that once an acceptable level of performance has been attained, additional \u201ccommon\u201d experience has only a negligible effect, in many domains the performance even decreases over time [32]. The length of experience has been found to be only a weak correlate of job performance after the first two years [27]\u2014what matters is the quality of the experience. According to Ericsson et al., expert performance can be explained with \u201cprolonged efforts to improve performance while negotiating motivational and external constraints\u201d [29]. For them, deliberate practice, meaning activities and experiences that are targeted at improving the own performance, are needed to become an expert. For software development, Zhou and Mockus found that developers can improve their performance over time by continuously increasing the difficulty and centrality of development tasks [117], which is in line with the concept of deliberate practice. Traditionally, research on deliberate practice concentrated on acquired knowledge and experience to explain expert performance [11, 31, 43]. However, later studies have shown that deliberate practice is necessary, but not sufficient, to achieve high levels of expert performance [11]\u2014individual differences play an important role [43] (see above).\nMonitoring, feedback, and self-reflection: A central aspect of deliberate practice is monitoring one\u2019s own performance, and getting feedback, for example from a teacher or coach [27]. Generally, such feedback helps individuals to monitor their progress towards goal achievement [64]. Moreover, as Tourish and Hargie note, \u201c[t]he more channels of accurate and helpful feedback we have access to, the better we are likely to perform.\u201d [107]. In areas like chess or physics, studies have shown that experts have more accurate self-monitoring skills than novices [14]. In our model, the feedback relation is connected to the concept task context as we assumed that feedback for a software developer most likely comes from co-workers or supervisors. To close the cycle, monitoring and self-reflection influence a developer\u2019s motivation and consequently his/her behavior. In the revised conceptual theory (see Section 5), we also included mentors in this feedback cycle.\nPhase 2: The preliminary conceptual theory builds upon the grounded theory. Among other changes, the theory introduces a task-specific view on expertise, separates individual differences and behavior, and embeds the concept of deliberate practice, including the relationships monitoring, feedback, and selfreflection. Moreover, instead of focusing on source code, it introduces the general concept of performance as a result of having a certain level of expertise."
        },
        {
            "heading": "5 PHASE 3: REVISED CONCEPTUAL THEORY",
            "text": "The goal of the third and last phase was to validate the general design of our theory and to collect more data about certain concepts, in particular the ones related to deliberate practice. Our focus was on programming-related tasks, but the theory can as well be extended and operationalized for other software development tasks in future work."
        },
        {
            "heading": "5.1 Survey Design",
            "text": "We revised the open questionnaire from phase 1 to focus on specific concepts, in fact most questions of the resulting focused questionnaire were directly related to individual concepts of the preliminary theory. We then conducted theoretical sampling to \u201celaborate and refine the categories constituting [our] theory\u201d [13], surveying two additional samples of software developers. We tried to reach active Java developers (S2) and very experienced developers (S3). We targeted Java developers, because we wanted to compare participants\u2019 general experience and expertise with their experience and expertise in one particular programming language (see Section 6). We further targeted experienced developers, because in the first phase especially this group of participants provided well-elaborated and insightful answers. Please note that the goal of theoretical sampling is \u201cconceptual and theoretical development\u201d, not \u201cincreasing the [...] generalizability\u201d of results [13].\nWe revised and extended our two initial research questions to adjust them to our preliminary conceptual theory. Beside asking for typical character traits of experts (RQ1.1), we now asked in particular for traits that are supportive for becoming an expert (RQ1.2) to collect more data on factors influencing the formation of SDExp. Due to the importance of mental abilities in expert development and the fact that they start to decline at a certain age [58], we asked about situations where developers\u2019 performance declined over time (RQ1.3). Since our theory is task-specific, we also asked for tasks that an expert should be good at (RQ1.4). When we asked participants in S1 for challenges in their daily work (RQ2), they often\nreferred to their work context and in particular to people-related issues. The work context may also influence developers\u2019 motivation, which plays an important role in expertise development (see Section 4.1). Thus, we changed RQ2 to focus more on those two aspects. Since we deductively included the concept of deliberate practice in our theory, we added questions aboutmonitoring (RQ3.1) and mentoring (RQ3.2), which are important aspects of deliberate practice. We provide the research questions and the corresponding survey questions as supplementary material [6].\nDuring the analysis of samples S2 and S3, we build upon our conceptual theory, mapping the emerging codes and categories to the existing theory. This procedure is similar to what Salda\u00f1a calls elaborative coding [91]. Figure 4 depicts the high-level concepts and categories of our revised conceptual theory. Some categories are not shown in the figure, but are described in this section. We provide a full list of all (sub-)categories as supplementary material [6]."
        },
        {
            "heading": "5.2 Sampling",
            "text": "As mentioned in the previous section, our preliminary conceptual theory guided the sampling (theoretical sampling [13, 82]). Our goal was to reach active Java developers (S2) as well as very experienced developers (S3). We retrieved the sampling frame for those samples from the Stack Exchange Data Dump [103] released January 1, 2016 and the GHTorrent data dump [39] released February 16, 2016.\nFor the Java sample (S2), we started by identifying active GH projects.We first filtered out the projects that were not deleted, not a fork, had at least two contributing users, and had at least 10 commits. Then, to select non-trivial Java projects, we only considered projects with at least 300 kB of Java source code (sum of file sizes of all Java files in the project). From the resulting 22,787 Java GH projects, we created a sampling framewith all users who contributed (committed or merged a pull request) to one of the selected projects and who pushed at least 10 commits between January 1, 2015 and December 31, 2015. From the 44,138 users who satisfied the above criteria, we contacted the ones with a public email address on their profile page (n = 1, 573).\nWith the third sample (S3), we wanted to reach very experienced users. Therefore, we again combined data from SO and GH.We used the age of a developer as a proxy variable for their experience. For GH users, the age was not available, but 11% of the users in the SO dump provided their age. To select experienced users, we filtered all SO users with age \u2265 55 years and \u2264 80 years and matched them with a GH account using the hash value of their email address. This resulted in a sample of 877 experienced users.\nThe focused questionnaire we used in the third phase contained nine open-ended and nine closed-ended questions, three of them only visible depending on previous answers, plus seven demographic questions. The full questionnaire is available as supplementary material [6]. This iteration of the questionnaire was online from February 18, 2016 until March 3, 2016 (S2) and from February 19, 2016 until March 4, 2016 (S3). Of the 1,573 contacted users in S2, 30 had an invalid email address and could not be reached. In the end, 127 participants filled out the questionnaire (response rate 8.2%). Of the 877 users in S3, 18 had an invalid email address and 91 participants completed the questionnaire (response rate 10.6%). We removed five participants from S3 because their answers either indicated that the age information from SO was not correct or that they were not active software developers. This lead to 86 responses available for analysis. Overall, combining S2 and S3, we had 213 valid responses in phase 3.\nIn S2, 119 respondents identified themselves as male, three as female and five did not provide their gender (S3: 84/1/1). The majority of respondents (S2: 64.6%, S3: 61.6%) reported their main software development role to be software developer, the second-largest group were software architects (S2: 13.4%, S3: 17.5%). In S2, most participants answered from Europe (47.2%) and North America (32.3%), in S3 the order was reversed (North America (67.4%), Europe (23.3%)). Further demographic information can be found in Table 1.\nComparing the demographics of the first two samples, we can see that S1 and S2 are quite similar, except for the fact that participants in S2 had more experience with Java (Mdn 3.5 vs. 6 years) and rated their Java expertise to be higher (Mdn 4 vs. 5). This indicates that our sampling approach was successful in reaching active Java developers. In S3, the values for the amount of professional work time dedicated to software development are quite similar to the other two samples. However, the developers in this sample are much older (M 59.9 vs. 30.4/31.6) and have much more general programming experience (Mdn 35 vs. 10/10). This indicates that our sampling approach for S3 was successful in reaching developers with a long general programming experience. However, many developers in S3 have little Java experience (Mdn 1.5 years) and also rated their\nJava expertise relatively low (Mdn 2). One reason for this could be that one quarter of the participants had a programming experience of 40 years or more (Q3 = 40) and compared to this time frame, Java is a relatively young programming language (introduced 1995). The boxplots in Figure 5 visualize the differences in general/Java experience and expertise between the three samples."
        },
        {
            "heading": "5.3 Concepts",
            "text": "Figure 4 shows the revised conceptual theory resulting from our analysis of the closed- and open-ended answers of samples S2 and S3. In the following, we describe the most frequent (sub-)categories for the high-level concepts of our theory that emerged during the analysis and combine those qualitative results with quantitative evaluations where possible. For each concept, we indicate when there were notable differences between the answers in S2 and S3. Like before, we write the concepts in bold font and the (sub-)categories in small capitals. We also provide the number of answers we assigned to each concept or category (in brackets). We only present the most frequent categories and provide the complete coding schema as supplementary material [6].\nTasks: Since our SDExp model is task-specific, we asked our participants to name the three most important tasks that a software development expert should be good at. The three most frequently mentioned tasks were designing software architecture (95), writing source code (91), and analyzing and understanding reqirements (52). Many participants not only mentioned the tasks, but also certain quality attributes associated with them, for example \u201carchitecting the software in a way that allows flexibility in project requirements and future applications of the components\u201d and \u201cwriting clean, correct, and understandable code\u201d. Other mentioned tasks include testing (48), communicating (44), staying up-to-date (28), and debugging (28). Our theory currently focuses on tasks directly related to programming (see Figure 4), but the responses show that it is important to broaden this view in the future to include, for example, tasks related to requirements engineering (analyzing and understanding reqirements) or the adaption of new technologies (staying up-to-date).\nExperience, knowledge, and performance: Like in the first phase, we asked participants about general attributes of software development experts. Aspects like having experience (26), a broad general knowledge (35) about \u201cparadigms [...], data structures, algorithms, computational complexity, and design patterns\u201d, and an \u201cintimate\u201d knowledge about a certain programming language (taskspecific knowledge (30)) were important. In particular, knowledge\nabout software architecture, including \u201cmodularization\u201d and \u201cdecomposition\u201d, was frequently named (22). Interestingly, 20 of the 22 answers mentioning software architecture came from the sample of active Java developers. Also similar to the first phase, participants described properties of experts\u2019 source code such as maintainability (22), clear structure (12), or performance (9). The answers from S2 and S3 supported the general structure of our theory, which we derived inductively in phase 1 and deductively in phase 2. Thus, we will focus on new aspects and in particular on factors influencing the formation of SDExp in the following.\nIndividual differences:We asked for specific characteristics of experts and in particular for character traits that support expertise development. Regarding the personality of experts, participants often described three properties that are also present in the popular five factor personality model (FFM) [70]: According to our participants, experts should be open-minded (42) and curious (35) (FFM: openness), be team players (37) (FFM: agreeableness), and be thorough and pay attention to detail (FFM: conscientiousness). Two other important traits were being patient (26) and being self-reflected (20). The latter is an important connection to the concept of deliberate practice that we introduced in the previous phase and includes understanding one\u2019s \u201cweaknesses and strengths\u201d and \u201cthe ability to learn from prior mistakes\u201d.\nRegarding skills that an expert should possess, problem-solving (84) was most frequently named. Sub-categories of problem solving are abstraction/decomposition (30), analytical thinking (20), and logical thinking (17). An expert can \u201cbreak a giant problem into the little pieces that can be solved to add back up to the whole\u201d. Examples where an analytical approach is needed include bug fixing or \u201cmapping the problem domain into the solution space\u201d. A second important skill was having the \u201cdrive to keep learning\u201d, which some participants described as continuous learning (55). Moreover, like in the first phase, communication skills (42) were frequently named. In the answers of this iteration, those skills were often mentioned together with the task of understanding and implementing reqirements (32): An expert should be \u201ca good listener during requirement gathering\u201d, understand \u201ca customer\u2019s desires\u201d, \u201cwork out what is really needed when the client can only say what they think they want\u201d, and should be able to \u201cexplain what he is doing to non developers\u201d. According to our participants, another important skill is being able to assess trade-offs (19) when comparing alternative solutions. Trade-offs can exist between \u201cdesign, maintainability, [and] performance\u201d. Experts should be \u201cable to discern the differences between early optimization and important design decisions for the long term goal\u201d, which is closely related to the concept of technical debt in software projects [59].\nMentoring: More than half the the participants in S2 and S3 (54.3%) had a (former) colleague or teacher whom they would describe as their mentor in becoming a better software developer. We asked those participants to describe their mentor(s). Six categories emerged during the initial and focused coding of participants\u2019 answers. One category, having time, was only present in the answers from S3: Eight experienced developers named aspects such as taking time to explain things or honoring solutions that take more time in the beginning, but save time on the long run.\nRegarding the mentor\u2019s role, senior developer (15), professor or teacher (13) and peer (12) were the most common answers. Two participants noted that their mentor was actually a junior developer younger than themselves. What is important are a mentor\u2019s character (29), skills (19), his/her experience (16), and his/her role as a source for feedback (20) and as a motivator (19). The most common characteristics of mentors were being guiding (10), patient (8), and open-minded (7). The most important aspect of a mentor\u2019s feedback were comments about code qality (7). What participants motivated most was when mentors posed challenging tasks. In summary, we can conclude that the description of good mentors resembles the description of software development experts in general.\nMonitoring and self-reflection:We asked participants if they regularly monitor their software development activities. Combining the answers from S2 and S3, 38.7% of the 204 participants who answered that question said that they regularly monitor their activity. We asked those participants how they usually monitor their development activity.\nIn both samples, the most important monitoring activity was peer review (16), where participants mentioned asking co-workers for feedback, doing code-review, or doing pair-programming. One participant mentioned that he tries to \u201ctake note of how often [he] win[s] technical arguments with [his] peers\u201d. Participants also mentioned time tracking (14) tools like WakaTime or RescueTime, issue tracking (11) systems like Jira or GitHub issues, and project management (14) tools like Redmine and Scrum story points as sources for feedback, comparing expected to actual results (e.g., time goals or number of features to implement). Three developers reported writing a development diary.\nRegarding employed metrics, participants reported using simple metrics such as the commit freqency, lines of code added / deleted, or number of issues resolved. Further, they reported to use static analysis (18) tools such as SonarQube, FindBugs, and Checkstyle, or to use GitHub\u2019s activity overview (10). In this point, there was a difference between the answers in S2 and S3: GitHub\u2019s activity overview was mentioned almost exclusively by the active Java developers (9). Three developers were doubtful regarding the usefulness of metrics. One participant noted: \u201cI do not think that measuring commits [or] LOC [...] automatically is a good idea to rate performance. It will raise competition, yes\u2014but not the one an employer would like. It will just get people to optimize whatever is measured.\u201d The described phenomenon is also known as Goodhart\u2019s law [16, 38].\nMotivation: To assess developers\u2019 motivation, we asked our participants what the most rewarding part of being a software developer is for them. Many participants were intrinsically motivated, stating that problem solving (46) is their main motivation\u2014one participant wrote that solving problems \u201cmakes [him] feel clever, and powerful.\u201d Another participant compared problem solving to climbing a mountain: \u201cI would equate that feeling [of getting a feature to work correctly after hours and hours of effort] to the feeling a mountain climber gets once they reach the summit of Everest.\u201d Many developers enjoy seeing the result (53) of their work. They are particularly satisfied to see a solution which they consider to be of highqality (22). Four participants mentioned refactoring\nas a rewarding task. One answered: \u201cThe initial design is fun, but what really is more rewarding is refactoring.\u201d Others stressed the importance of creating something new (19) and helping others (37). Interestingly, money was only mentioned by six participants as a motivation for their work.\nWork context: To investigate the influence of the work context on expertise development, we asked what employers should do in order to facilitate a continuous development of their employees\u2019 software development skills. We grouped the responses into four main categories: 1. encourage learning (70), 2. encourage experimentation (61), 3. improve information exchange (53), and 4. grant freedom (42). To encourage learning, employers may offer in-house or pay for external training courses (34), pay employees to visit conferences (15), provide a good analog and/or digital library (9), and offer monetary incentives for self-improvement (7). The most frequently named means to encourage experimentation were motivating employees to pursue side projects (29) and building a work environment that is open for new ideas and technologies (23). To improve information exchange between development teams, between different departments, or even between different companies, participants proposed to facilitate meetings (16) such as agile retrospectives, \u201cSelf-improvement Fridays\u201d, \u201clunch-and-learn sessions\u201d, or \u201cTechnical Thursday\u201d meetings. Such meetings could explicitly target information exchange or skill development. Beside dedicated meetings, the idea of developers rotating (15) between teams, projects, departments, or even companies is considered to foster expertise development. To improve the information flow between developers, practices such as mentoring (9) or code reviews (8) were mentioned. Finally, granting freedom, primarily in form of less time-pressure (18), would allow developers to invest in learning new technologies or skills.\nPerformance decline: We asked participants if they ever observed a significant decline of their own programming performance or the performance of co-workers over time. Combining the answers from S2 and S3, 41.5% of the 205 participants who answered that question actually observed such a performance decline over time. We asked those participants to describe how the decline manifested itself and to suggest possible reasons. The main categories we assigned to those answers were: 1. different reasons for demotivation (34), 2. changes in the work environment (32), 3. age-related decline (13), 4. changes in attitude (10), and 5. shifting towards other tasks (7). The most common reason for an increased demotivation was non-challenging work (8), often caused by tasks becoming routine over time. One participant described this effect as follows: \u201cI perceived an increasing procrastination in me and in my colleagues, by working on the same tasks over a relatively long time (let\u2019s say, 6 months or more) without innovation and environment changes.\u201d Other reasons included not seeing a clear vision or direction in which the project is or should be going (7) and missing reward for high-quality work (6). Regarding the work environment, participants named stress (6) due to tight deadlines or economic pressure (\u201cthe company\u2019s economic condition deteriorated\u201d). Moreover, bad management (8) or team structure (5) were named. An example for bad management would be \u201c[h]aving a supervisor/architect who is very\npoor at communicating his design goals and ideas, and refuses to accept that this is the case, even when forcibly reminded.\u201d. Changes in attitude may happen due to personal issues (e.g., getting divorced) or due to shifting priorities (e.g., friends and family getting more important). When developers are being promoted to team leader or manager, they shift towards other tasks, resulting in a declining programming performance.\nAge-related decline was described in both samples, but the more elaborate answers came from the experienced developers. We consider the investigation of age-related performance decline in software development, together with the consequences for individual developers and the organization, to be an important area for future research. To illustrate the effects that age-related decline may have, we provide four verbatim quotes by experienced developers:\n\u201cIn my experience (I started programming in 1962), new languages, systems, hardware became more complex and more diverse, programming became more complex. In my 50s I found it difficult to keep up with new paradigms and languages. So I turned to technical writing and eventually stopped programming.\u201d (software developer, age 72)\n\u201cFor myself, it\u2019s mostly the effects of aging on the brain. At age 66, I can\u2019t hold as much information short-term memory, for example. In general, I am more forgetful. I can compensate for a lot of that by writing simpler functions with clean interfaces. The results are still good, but my productivity is much slower than when I was younger.\u201d (software architect, age 66)\n\u201cProgramming ability is based on desire to achieve. In the early years, it is a sort of competition. As you age, you begin to realize that outdoing your peers isn\u2019t all that rewarding. [...] I found that I lost a significant amount of my focus as I became 40, and started using drugs such as ritalin to enhance my abilities. This is pretty common among older programmers.\u201d (software developer, age 60)\n\u201cI\u2019ve been in the software industry for 36 years. [...] It seems as if for the first half or two thirds of that time I was fortunate to be involved in areas at the forefront of the technology wave [...]. For the last 10-15 years though, I have increasingly had the feeling that waves of technology were passing me by [...]. Once I do start to get involved [...] there is a huge learning curve to overcome and I labour to deliver stories as rapidly as younger colleagues who have been immersed in the relevant technology for longer.\u201d (software developer, age 57)"
        },
        {
            "heading": "5.4 Relationships",
            "text": "The only relationships we added are related to the concept of mentoring. As mentioned above, participants described mentors as an important source for feedback and as motivators. Thus, we connected mentoring to the corresponding concepts motivation and feedback in the revised conceptual theory.\nPhase 3: To refine and elaborate certain concepts of our preliminary conceptual theory, we conducted a second inductive step, collecting data from two additional samples of software developers. We added details about individual differences and task contexts that foster the formation of SDExp, and further investigated concepts such as monitoring, mentoring and selfreflection, which are related to deliberate practice. We also asked about performance decline over time and identified age-related decline as a problem for older software developers."
        },
        {
            "heading": "6 EXPERIENCE AND EXPERTISE",
            "text": "Since software developers\u2019 expertise is difficult to measure [78], researchers often rely on proxies for this abstract concept [95]. We investigated the relationship and validity of the two proxies length of experience and self-assessed expertise to provide guidance for researchers."
        },
        {
            "heading": "6.1 Programming Experience vs. Expertise",
            "text": "As mentioned above, we asked participants for their general and Java programming experience (years) and for a self-assessment of their general and Java expertise (semantic differential from 1=novice to 6=expert), see Table 1 and Figure 5. To explore how experience, self-assessed expertise, and other variables are related, we employed the nonparametric Spearman\u2019s rank correlation coefficient (\u03c1). Our interpretation of \u03c1 is based on Hinkle et al.\u2019s scheme [47]: low (0.3 \u2264 |\u03c1 | < 0.5), moderate (0.5 \u2264 |\u03c1 | < 0.7), high (0.7 \u2264 |\u03c1 | < 0.9), and very high correlation (0.9 \u2264 |\u03c1 | \u2264 1). We chose this nonparametric test because not all variables we tested had interval scaling and not all of them were normally distributed.\nWe highlight important correlations in the following and provide the complete correlation table as supplementary material [6]. For samples S1 and S2, the general experience in years (GE) correlates at least moderately with the self-assessed general expertise rating (GRsem) and the participants\u2019 age in years. Interestingly, this correlation cannot be observed for the experienced developers (S3). For the active Java developers (S2), the general experience (GE) and the Java experience (JE) have a high correlation. The Java experience (JE) has a high correlation with the self-assessed Java expertise rating (JRsem) for all three samples, and a moderate correlation with the age for the active Java developers (S2).\nFrom the observed correlations, we cannot draw consistent conclusions that are valid for all three samples and for both types of experience (general and Java). Our interpretation of these results is that, depending on the background of the participants, experience in years can or cannot be a valid proxy for (self-assessed) programming expertise. Generally, despite the fact that most researchers would probably agree with the definition of expertise as achieving \u201coutstanding performance\u201d [31], in many empirical studies programming expertise has been operationalized as years (or months) of programming experience [95, 100]. Our results, which suggest that this operationalization may not be valid, is in line with studies showing that excellent software professionals have broader but not necessarily longer experience [22, 98\u2013100]."
        },
        {
            "heading": "6.2 Validity of Expertise Self-assessments",
            "text": "In the previous subsection, we motivated that experience may not always be a valid proxy for expertise. We were also interested in the validity of self-assessed expertise, which is, like other self-reports, context-dependent [93]. The validity of self-assessed expertise is related to the concept of self-reflection in our conceptual theory, but has also methodological implications for software engineering research in general, because self-assessed programming expertise is often used in studies with software developers to differentiate between novices and experts [95]. To analyze the influence of question context on expertise self-assessments, we asked the participants in\nsamples S2 and S3 for a second self-assessment of their Java expertise at the end of the online survey. At that point, we did not only provide a semantic differential scale like in the beginning of the survey (JRsem, see Table 1), but also a description of the rating scale stages based on the 5-stage Dreyfus model of skill acquisition [24] (JRdre), ranging from novice (1) to expert (5). This model has been applied in various contexts, but researchers also discussed its limitations [84]. We based our description of the Dreyfus model on a later description by Stuart Dreyfus [23] and an adapted version by Andy Hunt [49]. We provide the description of the five stages, which we used in the focused questionnaire, as supplementary material [6]. The goal of this setup was to investigate if providing additional context has a significant influence on developers\u2019 self-assessment compared to a semantic differential scale without context.\nWhen designing the initial questionnaire, we chose a 6-point scale for the expertise rating such that participants have to decide whether they consider themselves to be either on the novice (1-3) or expert (4-6) side of the scale, without the option to select a middle value [35, 80]. To be able to compare the ratings, we had to adjust JRsem to be in range [1, 5] using the following function: adj(x) = 1 5 + 4 5x . To test for significant differences between the two ratings, we applied the non-parametric two-sided Wilcoxon signed rank test [116] and report the corresponding p-value (pw ). To measure the effect size, we used Cliff\u2019s delta (\u03b4 ) [17]. Our interpretation of \u03b4 is based on the guidelines by Kitchenham et al. [55]. Moreover, we report the confidence interval of \u03b4 at a 95% confidence level (CI\u03b4 ).\nThe Wilcoxon signed rank test indicated that JRdre is significantly higher than JRsem for the experienced developers in S3 (pw = 0.0009), but the difference is not significant for the active Java developers in S2 (pw = 0.47). Cliff\u2019s \u03b4 shows only a negligible effect for S2 (\u03b4 = 0.08, CI\u03b4 = [\u22120.20, 0.04]), but a small positive effect for S3 (\u03b4 = 0.17, CI\u03b4 = [0.004, 0.33]), i.e., experienced developers tended to adjust their self-assessments to a higher rating after we provided context. A possible interpretation of this result could be found in the Dunning-Kruger effect [60], which is one form of the illusory superiority bias [48] where individuals tend to overestimate their abilities. One result of Kruger and Dunning is that participants with a high skill-level underestimate their ability and performance relative to their peers [60]. This may have happened in the sample with experienced developers (S3) when they assessed their Java expertise using the semantic differential scale. When we provided context in form of the Dreyfus model, they adjusted their ratings to a more adequate rating, whereas the less experienced developers (S2) stuck to their, possibly overestimated, ratings. We cannot conclude that the Dreyfus model in fact leads to more adequate ratings for experienced developers, because we do not have the data to assess the validity of their ratings. However, we can conclude that the way we asked developers to assess their Java programming expertise was influenced by the context we provided.\nExperience and expertise: Neither developers\u2019 experience measured in years nor the self-assessed programming expertise ratings yielded consistent results across all settings. One direction for future work is to investigate and compare different expertise rating scales to provide guidance for researchers designing studies with expertise self-assessments."
        },
        {
            "heading": "7 LIMITATIONS AND THREATS TO VALIDITY",
            "text": "Since we conducted mixed-methods research, we assess the limitations and threats to validity of our study in terms of the typical quantitative categories internal and external validity [51], but we will also apply the qualitative evaluation criteria credibility, originality, resonance, and usefulness [13].\nInternal validity: In our analysis of expertise self-assessments (see Section 6.2), we cannot rule out that a confounding factor lead to the higher self-assessments of experienced developers (S3). However, although we used the same questionnaire for S2 and S3, the effect was only significant and non-negligible for S3. Our goal was not to be able to quantify the effect of context on developers\u2019 selfassessment, but to show that it exists to motivate future research on this aspect.\nExternal validity: The main limitation affecting external validity is our focus on Java and on open source software development, in particular on GH and SO users. Moreover, as one of three samples targeted experienced developers and only five participants identified themselves as female, our results may be biased towards experienced male developers. Nevertheless, we are confident that our theory is also valid for other developer populations, because of the abstract nature of its core concepts and their grounding in related work. Moreover, although we contacted open source developers, many of them reported on their experiences working in companies (see, e.g., the concepts work/task context).\nQualitative evaluation criteria: To support credibility of our findings, we not only inductively built our theory from surveys with 335 software developers, but also deductively included results from related work on expertise and expert performance. We constantly compared the answers between all three samples and mapped them to overarching concepts and categories. For the core concepts general/task-specific knowledge and experience, and the connection of individual differences, work context, behavior, and performance, we observed theoretical saturation in the way that those concepts were frequently named and the descriptions did not contradict the relationships we modeled. However, as we only collected data from three samples of developers, the concepts, and in particular the categories we added in phase 3, have to be validated using more data to achieve a higher level of theoretical saturation. In terms of originality, we not only contribute a first conceptual theory of SDExp, but also a research design for theory building that other software engineering researchers can adapt and apply. Regarding the resonance of our theory, the feedback, in particular from samples S2 and S3 with focused questions directly related to theory concepts, was generally positive. Participants described their participation as a \u201cvery informative experience\u201d and a \u201cnice opportunity to reflect\u201d. However, there was some negative feedback regarding the Java focus, especially in sample S3. Participants were mainly asking why we concentrated on Java, not questioning the general decision to focus on one particular programming language for some questions. To motivate the usefulness of our theory, we refer to Section 9, which contains short summaries of our findings targeting researchers, software developers, and their employers.\nOther limitations: The qualitative analysis and theory-building was mainly conducted by the first author and was then discussed\nwith the second author. We tried to mitigate possible biases introduced by us as authors of the theory by embedding our initial GT in related work on expertise and expert performance (see Section 4) and then again collecting data to further refine the resulting conceptual theory (see Section 5). However, when theorizing, there will always be an \u201cuncodifiable step\u201d that relies on the imagination of the researcher [61, 113]."
        },
        {
            "heading": "8 RELATEDWORK",
            "text": "Expertise research in software engineering mainly focused on expert recommendation, utilizing information such as change history [53, 71, 78], usage history [66, 112], bug reports [3], or interaction data [34, 86]. Investigated aspects of software development expertise (SDExp) include programming experience [95], age [81], developer fluency [117], and desired attributes of software engineers [63] and managers [54]. Moreover, similar to our study, Graziotin et al. observed that vision and goal-setting are related to developers\u2019 performance [40]. However, as mentioned above, up to now there was no theory combining those individual aspects.\nBeside the references mentioned in the description of our theory, the psychological constructs personality, motivation, and mental ability provide many links to theories and instruments from the field of psychology. To assess developers\u2019 personality, e.g., one could employ the International Personality Item Pool (IPIP) [37], measuring the big five personality traits. There have been many studies investigating the personality of software developers [20]. Cruz et al. conclude in their systematic mapping study that the evidence from analyzed papers is conflicting, especially for the area of individual performance. Thus, more research is needed to investigate the connection between personality and expert performance. Our theory can help to identify confounding factors affecting performance, in particular the interplay between an individual\u2019s mental abilities, personality, motivation, and his/her general and task-specific knowledge and experience. The connection between mental abilities, personality, and domain knowledge in expertise development has, for example, been described by Ackerman and Beier\u2019s [1].\nThe concepts of communication and problem-solving skills have been thoroughly described in psychology literature [45, 64, 87]. Researchers can use this knowledge when designing studies about the influence of such skills on the formation of SDExp. The other two general skills we included in our theory, continuous learning and assessing trade-offs, have also been described by Li et al. [63], who identified continuously improving and effective decision-making as critical attributes of great software engineers.\nVery closely related to the concept of deliberate practice [29], which we included in our theory, is the concept of self-directed learning [73] that connects our work to educational research. Similar to our theory, motivation and self-monitoring are considered to be important aspects of self-directed learning [73]. To capture the motivation of developers one could adapt ideas from selfdetermination theory [90] or McClelland\u2019s theory of the big three motives [69]. There also exist instruments like the Unified Motive Scales (UMS) [92] to assess human motivation, which can be utilized in studies. Beecham et al. [8] conducted a systematic literature review of motivation in software engineering. While many studies reported that software developers\u2019 motivation differs from other\ngroups, the existing models diverge and \u201cthere is no clear understanding of [...] what motivates Software Engineers.\u201d Nevertheless, the authors name \u201cproblem solving, working to benefit others and technical challenge\u201d as important job aspects that motivate developers. This is very similar to our categories work as challenge and helping others, which we assigned to the conceptmotivation in our theory. An area related to motivation is the (perceived) productivity of individual developers [15, 75] or software development teams [42, 89]. The results from existing studies in this area can be adapted to assess the performance of developers for monitoring, feedback, and self-reflection [76, 108]. Beside their connection to existing software engineering research, those concepts also connect our theory to two additional areas of psychology: metacognition (\u201cknowledge about one\u2019s own knowledge [... and] performance\u201d) [32] and self-regulation [118].\nTo measuremental abilities, test like theWAIS-IV [115] or the graphical mini-q test [7] can be employed. As motivated above, the connection between aging and expertise [58], and in particular how a (perceived) age-related performance decline influences individuals and how they compensate this decline, are important directions for future research. Considering the phenomenon of global population aging [65], the number of old software developers is likely to increase in the next decades. With their experience and knowledge, those developers are a valuable part of software development teams. However, as our qualitative data suggests, they may become unsatisfied with their jobs and may even drop out of software development.\nTo assess theperformance of individual software developers, researchers can choose from various existing softwaremetrics [33, 52]. Especially maintainability metrics [18] are of interest, because in our study, maintainability was the most frequently named source code property of experts. Tests about general programming knowledge could be derived from literature about typical programming interview questions [4, 72, 79]. To assess task-specific Java knowledge, one could rely on commercially available tests like the exams for Oracle\u2019s Java certification. Britto et al.[10] report on their experience measuring learning results and the associated effect on performance in a large-scale software project. Their results can help measuring the concepts education and performance."
        },
        {
            "heading": "9 SUMMARY AND FUTUREWORK",
            "text": "In this paper, we presented a conceptual theory of software development expertise (SDExp). The theory is grounded in the answers of an online survey with 355 software developers and in existing literature on expertise and expert performance. Our theory describes various properties of SDExp and factors fostering or hindering its development. We classified our theory as a teleological process theory that views \u201cdevelopment as a repetitive sequence of goal formulation, implementation, evaluation, and modification of goals based on what was learned\u201d [110]. Our task-specific view of SDExp, together with the concept of deliberate practice and the related feedback cycle, fits this framing, assuming that developers\u2019 goal is to become experts in certain software development tasks.\nWe reached a diverse set of experienced and less experienced developers. However, due to the focus on Java and open source software, future work must investigate the applicability of our\nresults to other developer populations. We plan to add more results from existing studies in software engineering and psychology to our theory and to conduct own studies based on our theory. In particular, we want to broaden the scope to include more tasks not directly related to programming. Nevertheless, the theory is already useful for researchers, software developers, and their employers. In the following, we will briefly summarize our findings with a focus on those target audiences.\nResearchers: Researchers can use our methodological findings about (self-assessed) expertise and experience (see Section 6) when designing studies involving self-assessments. If researchers have a clear understanding what distinguishes novices and experts in their study setting, they should provide this context [93] when asking for self-assessed expertise and later report it together with their results. We motivated why we did not describe expertise development in discrete steps (see Section 4), but a direction for future work could be to at least develop a standardized description of novice and expert for certain tasks, which could then be used in semantic differential scales. To design concrete experiments measuring certain aspects of SDExp, one needs to operationalize the conceptual theory [44]. We already linked certain concepts to measurement instruments such as UMS (motivation), WAIS-IV (mental abilities), or IPIP (personality). We also mentioned static analysis tools to measure code quality and simple productivity measures such as commit frequency and number of issues closed. This enables researchers to design experiments, but also to re-evaluate results from previous experiments. There are, e.g., no coherent results about the connection of individual differences and programming performance yet. One could review studies on developers\u2019 motivation [8] and personality [20] in the context of our theory, to derive a research design for analyzing the interplay of individual differences and SDExp.\nDevelopers: Software developers can use our results to see which properties are distinctive for experts in their field, and which behaviors may lead to becoming a better software developer. For example, the concept of deliberate practice, and in particular having challenging goals, a supportive work environment, and getting feedback from peers are important factors. For \u201csenior\u201d developers, our results provide suggestions for being a good mentor. Mentors should know that they are considered to be an important source for feedback and motivation, and that being patient and being openminded are desired characteristics. We also provide first results on the consequences of age-related performance decline, which is an important direction for future work.\nEmployers: Employers can learn what typical reasons for demotivation among their employees are, and how they can build a work environment supporting the self-improvement of their staff. Beside obvious strategies such as offering training sessions or paying for conference visits, our results suggest that employers should think carefully about how information is shared between their developers and also between the development team and other departments of the company. Facilitating meetings that explicitly target information exchange and learning new skills should be a priority of every company that cares about the development of their employees. Finally, employers should make sure to have a good mix of continuity and change in their software development process, because nonchallenging work, often caused by tasks becoming routine, is an important demotivating factor for software developers."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "We thank the survey participants, Bernhard Baltes-G\u00f6tz, Daniel Graziotin, and the anonymous reviewers for their valuable feedback."
        }
    ],
    "title": "Towards a Theory of Software Development Expertise",
    "year": 2018
}