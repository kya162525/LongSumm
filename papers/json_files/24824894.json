{
    "abstractText": "We investigate how Simpson\u2019s paradox a\u0082ects analysis of trends in social data. According to the paradox, the trends observed in data that has been aggregated over an entire population may be di\u0082erent from, and even opposite to, those of the underlying subgroups. Failure to take this e\u0082ect into account can lead analysis to wrong conclusions. We present a statistical method to automatically identify Simpson\u2019s paradox in data by comparing statistical trends in the aggregate data to those in the disaggregated subgroups. We apply the approach to data from Stack Exchange, a popular question-answering platform, to analyze factors a\u0082ecting answerer performance, speci\u0080cally, the likelihood that an answer wri\u008aen by a user will be accepted by the asker as the best answer to his or her question. Our analysis con\u0080rms a known Simpson\u2019s paradox and identi\u0080es several new instances. \u008cese paradoxes provide novel insights into user behavior on Stack Exchange.",
    "authors": [
        {
            "affiliations": [],
            "name": "Nazanin Alipourfard"
        },
        {
            "affiliations": [],
            "name": "Marina Del Rey"
        },
        {
            "affiliations": [],
            "name": "Peter G. Fennell"
        },
        {
            "affiliations": [],
            "name": "Kristina Lerman"
        }
    ],
    "id": "SP:a812e1cd1e71ee2be697e507d795f640738cb0f4",
    "references": [
        {
            "authors": [
                "Tushar Agarwal",
                "Keith Burghardt",
                "Kristina Lerman"
            ],
            "title": "On \u008bi\u008aing: Performance and Practice in Online Game Play",
            "venue": "In Proceedings of 11th AAAI International Conference on Web and Social Media. AAAI",
            "year": 2017
        },
        {
            "authors": [
                "Samuel Barbosa",
                "Dan Cosley",
                "Amit Sharma",
                "Roberto M. Cesar-Jr."
            ],
            "title": "Averaging Gone Wrong: Using Time-Aware Analyses to Be\u008aer Understand Behavior",
            "year": 2016
        },
        {
            "authors": [
                "Elias Bareinboim",
                "Judea Pearl"
            ],
            "title": "Causal inference and the data-fusion problem",
            "venue": "PNAS 113,",
            "year": 2016
        },
        {
            "authors": [
                "P.J. Bickel",
                "E.A. Hammel",
                "O\u2019connell J.W"
            ],
            "title": "Sex bias in graduate admissions: Data from Berkeley",
            "venue": "Science 187,",
            "year": 1975
        },
        {
            "authors": [
                "Keith Burghardt",
                "Emanuel F. Alsina",
                "Michelle Girvan",
                "William Rand",
                "Kristina Lerman"
            ],
            "title": "\u008ce myopia of crowds: Cognitive load and collective evaluation of answers on Stack Exchange",
            "venue": "PLOS ONE 12,",
            "year": 2017
        },
        {
            "authors": [
                "William K. Estes"
            ],
            "title": "\u008ce problem of inference from curves based on group data",
            "venue": "Psychological bulletin 53,",
            "year": 1956
        },
        {
            "authors": [
                "Carem C Fabris",
                "Alex A Freitas"
            ],
            "title": "Discovering surprising pa\u008aerns by detecting occurrences of Simpson\u0080s paradox",
            "venue": "In Research and Development in Intelligent Systems",
            "year": 2000
        },
        {
            "authors": [
                "Emilio Ferrara",
                "Nazanin Alipoufard",
                "Keith Burghardt",
                "Chiranth Gopal",
                "Kristina Lerman"
            ],
            "title": "Dynamics of Content\u008bality in Collaborative Knowledge Production",
            "venue": "In ICWSM. AAAI",
            "year": 2017
        },
        {
            "authors": [
                "Greg Ver Steeg",
                "Rumi Ghosh",
                "Kristina Lerman"
            ],
            "title": "What stops social epidemics",
            "venue": "In ICWSM",
            "year": 2011
        },
        {
            "authors": [
                "Miguel A. Hernan",
                "David Clayton",
                "Niels Keiding"
            ],
            "title": "Simpson\u2019s paradox unraveled",
            "venue": "Int J Epidemiology 40,",
            "year": 2011
        },
        {
            "authors": [
                "Nathan O. Hodas",
                "Kristina Lerman"
            ],
            "title": "How Limited Visibility and Divided A\u008aention Constrain Social Contagion",
            "venue": "SocialCom",
            "year": 2012
        },
        {
            "authors": [
                "Nathan O. Hodas",
                "Kristina Lerman"
            ],
            "title": "\u008ce Simple Rules of Social Contagion",
            "venue": "Scienti\u0080c Reports",
            "year": 2014
        },
        {
            "authors": [
                "J.P. Kincaid",
                "Jr R.P. Fishburnea",
                "R.L. Rogers",
                "B.S. Chissom"
            ],
            "title": "Derivation of new readability formulas (automated readability index, fog count and \u0083esch reading ease formula) for navy enlisted personnel",
            "venue": "Technical Report. U.S. Navy",
            "year": 1975
        },
        {
            "authors": [
                "Farshad Kooti",
                "Karthik Subbian",
                "Winter Mason",
                "Lada Adamic",
                "Kristina Lerman"
            ],
            "title": "Understanding Short-term Changes in Online Activity Sessions",
            "venue": "In Companion WWW2017",
            "year": 2017
        },
        {
            "authors": [
                "Kristina Lerman"
            ],
            "title": "Information Is Not a Virus, and Other Consequences of Human Cognitive Limits",
            "venue": "Future Internet 8,",
            "year": 2016
        },
        {
            "authors": [
                "H. James Norton",
                "George Divine"
            ],
            "title": "Simpson\u2019s paradox \u0080 and how to avoid it",
            "venue": "Signi\u0080cance 12,",
            "year": 2015
        },
        {
            "authors": [
                "Daniel M. Romero",
                "Brendan Meeder",
                "Jon Kleinberg"
            ],
            "title": "Di\u0082erences in the Mechanics of Information Di\u0082usion Across Topics: Idioms, Political Hashtags, and Complex Contagion on Twi\u008aer. InWWW",
            "year": 2011
        },
        {
            "authors": [
                "Philipp Singer",
                "Emilio Ferrara",
                "Farshad Kooti",
                "Markus Strohmaier",
                "Kristina Lerman"
            ],
            "title": "Evidence of Online Performance Deterioration in User Sessions on Reddit",
            "venue": "PLoS ONE 11,",
            "year": 2016
        },
        {
            "authors": [
                "J.W. Vaupel",
                "A.I. Yashin"
            ],
            "title": "Heterogeneity\u2019s ruses: some surprising e\u0082ects of selection on population dynamics",
            "venue": "Am. Stat. 39,",
            "year": 1985
        },
        {
            "authors": [
                "Yu Xie"
            ],
            "title": "Population heterogeneity and causal inference",
            "venue": "PNAS 110,",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "CCS CONCEPTS \u2022Mathematics of computing\u2192 Statistical paradigms; Exploratory data analysis; Regression analysis; \u2022Information systems \u2192 Data mining; Collaborative and social computing systems and tools; Clustering;\nKEYWORDS Simpson\u2019s Paradox, Trend Analysis ACM Reference format: Nazanin Alipourfard, Peter G. Fennell, and Kristina Lerman. 2018. Can you Trust the Trend? Discovering Simpson\u2019s Paradoxes in Social Data. In Proceedings of WSDM 2018: e Eleventh ACM International Conference on Web Search and Data Mining , Marina Del Rey, CA, USA, February 5\u20139, 2018 (WSDM 2018), 9 pages. DOI: 10.1145/3159652.3159684"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Digital traces of human activity have exposed social behavior to web and data mining algorithms. Researchers have analyzed the \u2217N. Alipourfard and P. Fennell contributed equally to this work.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. WSDM 2018, Marina Del Rey, CA, USA \u00a9 2018 ACM. 978-1-4503-5581-0/18/02. . .$15.00 DOI: 10.1145/3159652.3159684\ngrowing social data to understand, among other things, how information spreads in social networks [18], and the factors a ecting user engagement [2] and performance [19] in online platforms. Yet social data analysis presents multi-faceted challenges that existing data mining approaches are not well-equipped to handle. Real-world data is noisy and sparse. To uncover hidden pa erns, scientists aggregate data over the population, which tends to improve statistics and signal-to-noise ratio. However, real-world data is also heterogeneous, i.e., composed of subgroups that vary widely in size and behavior. is heterogeneity can severely bias analysis of social data.\nOne example of such bias is Simpson\u2019s paradox. According to the paradox, an association observed in data that has been aggregated over an entire population may be quite di erent from, and even opposite to, those of the underlying subgroups. Failure to take this e ect into account can distort conclusions drawn from data. One of the be er known examples of Simpson\u2019s paradox comes from a study of gender bias in graduate admissions [4]. In the aggregate admissions data there appears to be a statistically signi cant bias against women: a smaller fraction of female applicants is admi ed for graduate studies. However, when admissions data is disaggregated by department, women have parity and even a slight advantage over men in some departments. e paradox arises because departments preferred by female applicants have lower admissions rates for both genders.\nSimpson\u2019s paradox also a ects analysis of trends. When measuring how an outcome changes as a function of an independent variable, the characteristics of the population over which the trend is measured may change as a function of the independent variable due to survivor bias. As a result, the data may appear to exhibit a trend, which disappears or reverses when the data is disaggregated. For example, it may appear that repeated exposures to information or hashtags on social media make an individual less likely to share it with his or her followers [18]. In fact, the opposite is true: the more people are exposed to information, the more likely they are to share it with followers [16]. However, those who follow many others (and are likely to be exposed to a meme or a hashtag multiple times) are less responsive overall, due to the high volume of information they receive [12]. eir reduced susceptibility to exposures biases the aggregate response, leading to wrong conclusions about behavior. Once disaggregated based on the volume of information received, a clearer pa ern of exposure response emerges, one that is more predictive of the actual response [13]. However, despite accumulating evidence that Simpson\u2019s paradox a ects inference of trends in social and behavioral data [1, 2, 15, 19], researchers do not routinely test for it in their studies. ar X iv :1\n80 1.\n04 38\n5v 1\n[ cs\n.C Y\n] 1\n3 Ja\nn 20\n18\nWe describe a method to identify Simpson\u2019s paradoxes in the analysis of trends in social data. Our statistical approach nds pairs of variables\u2014that we call Simpson\u2019s pairs\u2014such that a trend in some outcome as a function of the rst independent variable observed in the aggregate data disappears or reverses itself when the data is disaggregated into distinct subgroups on the second conditioning variable. We perform mathematical analysis, which identi es two necessary conditions for the paradox to occur: (1) the independent and conditioning variables are correlated and (2) the value of the outcome variable di ers within conditioning subgroups.\nWe apply the proposed approach to data collected from Stack Exchange, a popular question-answering platform. Speci cally, we analyze factors a ecting answerer performance, measured as the likelihood the answer provided by the answerer will be accepted by the asker as the best answer to his or her question. We construct a variety of features to describe answers and answerers, and study how the outcome\u2014in this case answer acceptance\u2014depends on these features. We compare results of statistical trends found in aggregated and disaggregated data to identify Simpsons\u2019s pairs. Our analysis discovers several cases of Simpson\u2019s paradox in Stack Exchange data. In addition to a known e ect that describes deterioration of answerer performance over the course of a session, our method identi es several new cases of Simpson\u2019s paradox. ese paradoxes yield new insights into answerer performance on Stack Exchange. For example, creating a new feature to describe answerers, which combines variables of a Simpson\u2019s pair, leads to a more robust proxy of answerer performance.\nPresence of a Simpson\u2019s paradox in social data can indicate interesting pa erns [8], including important behavioral di erences. e paradox suggests that subgroups within the population under study systematically di er in their behavior, and these di erences are large enough to a ect aggregate trends. In such cases the trends discovered in disaggregated data are more likely to describe\u2014and predict\u2014individual behavior than the trends found in aggregated data. us, to build more robust models of behavior, data scientists need to identify the subgroups within their data or risk drawing wrong conclusions. e method presented in this paper provides a simple framework for identifying such interesting subgroups by systematically searching for Simpson\u2019s paradox in trend data.\ne rest of the paper is organized as follows. First, we present background, including multiple observations of Simpson\u2019s paradox in a variety of disciplies (Sec. 2). en we describe our methodology for detecting Simpson\u2019s paradox by identifying covariates in data, and analyze the paradox mathematically to gain more insight into its origins (Sec. 3). Finally, we apply our method to real-world data from the question-answering site Stack Exchange, and demonstrate its ability to automatically identify novel cases of Simpson\u2019s paradox (Sec. 4). We conclude with the discussion of implications."
        },
        {
            "heading": "2 BACKGROUND AND RELATEDWORK",
            "text": "e goal of data analysis is to identify important associations between features, or variables, in data. However, hidden correlations between variables can lead analysis to wrong conclusions. One important manifestation of this e ect is Simpson\u2019s paradox, according to which an association that appears in di erent subgroups of data may disappear, and even reverse itself, when data is aggregated\nacross subgroups. Instances of the paradox have been documented across a variety of disciplines, including demographics, economics, political science, and clinical research, and it has been argued that the presence of Simpson\u2019s paradox implies that interesting pa erns exist in data [8]. A notorious example of Simpson\u2019s paradox arose during a gender bias lawsuit against UC Berkeley. Analysis of graduate school admissions data revealed a statistically signi cant bias against women. However, the pa ern of discrimination observed in this aggregate data disappeared when admissions data was disaggregated by department. Bickel et al. [4] a ributed this e ect to Simpson\u2019s paradox. ey argued that the subtle correlations between the popularity of departments among the genders and their selectivity resulted in women applying to departments that were hardest to get into, which skewed analysis.\nSimpson\u2019s paradox must also be considered in the analysis of trends. Vaupel and Yashin [20] give a compelling illustration of how survivor bias can shi the composition of data, distorting the conclusions drawn from it. Analysis of recidivism among convicts released from prison shows that the rate at which they return to prison declines over time. From this, policy makers may conclude that age has a pacifying e ect on crime: older convicts are less likely to commit crimes. In reality, this conclusion is false. Instead, we can think of the population of ex-convicts as composed of two subgroups with constant, but very di erent recidivism rates. e rst subgroup, let\u2019s call them \u201creformed,\u201d will never commit a crime once released from prison. e other subgroup, the \u201cincorrigibles,\u201d will always commit a crime. Over time, as \u201cincorrigibles\u201d commit o enses and return to prison, there are fewer of them le in the population. e survivor bias changes the composition of the population under study, creating an illusion of an overall decline in recidivism rates. As Vaupel and Yashin warn, \u201cunsuspecting researchers who are not wary of heterogeneity\u2019s ruses may fallaciously assume that observed pa erns for the population as a whole also hold on the sub-population or individual level.\u201d eir paper gives numerous other examples of such ecological fallacies.\nSimilar illusions crop up in many studies of social behavior. For example, when examining how social media users respond to information from their friends (other users that they follow), it may appear that if more of a user\u2019s friends use a hashtag then the user will be less likely to use it himself or herself [18]. Similarly, the more friends share some information, the less likely the user is to share it with his or her followers [10]. From this, one may conclude the additional exposures to information in a sense \u201cinnoculate\u201d the user and act to suppress the sharing of information. In fact, this is not the case, and instead, additional exposures monotonically increase the user\u2019s likelihood to share information with followers [16]. However, those users who follow many others, and are likely to be exposed to information or a hashtag multiple times, are less responsive overall, because they are overloaded with information they receive from all the friends they follow [12]. Calculating response as a function of the number of exposures in the aggregate data falls prey to survivor bias: the more responsive users (with fewer friends) quickly drop out of the average (since they are generally exposed fewer times), leaving the highly connected, but less responsive, users behind. e reduced susceptibility of these highly connected users biases aggregate response, leading to wrong conclusions about individual\nbehavior. Once data is disaggregated based on the volume of information individuals receive, a clearer pa ern of response emerges, one that is more predictive of behavior [13]. Multiple examples of Simpson\u2019s paradox have been identi ed in empirical studies of online behavior. A study [2] of Reddit found that while it may appear that average comment length on decreases over any xed period of time, when data is disaggregated into groups based on the year user joined Reddit, comment length within each group increases during the same time period. It is only because users who joined early tend to write longer comments that the Simpson\u2019s paradox appears.\nData heterogeneity also impacts statistical analysis of data [7] and causal inference [21]. However, no general framework to recognize and mitigate Simpson\u2019s paradox exist. Current methods require that the structure of data be explicitly speci ed [3] or at best be guided by subject ma er knowledge [11].\nDespite accumulating evidence that Simpson\u2019s paradox a ects inference from data [7, 21], scientists do not routinely test for the presence of this paradox in heterogeneous data. Our work addresses this knowledge gap by proposing a statistical method to systematically uncover instances of Simpson\u2019s paradox in data."
        },
        {
            "heading": "3 METHODS",
            "text": "We propose a method to systematically uncover Simpson\u2019s paradox for trends in data. We denote asY the dependent variable in the data set, i.e., an outcome being measured, and as X = {X1,X2, . . . ,Xm } the set of m independent variables or features. e goal of the method is to identify pairs of variables (Xp ,Xc )\u2014Simpson\u2019s pairs\u2014 such that a trend in Y as a function of Xp disappears or reverses when the data is disaggregated by conditioning on Xc . More specifically, our method searches for pairs of variables (Xp ,Xc ) such that\nd\ndxp E[Y |Xp = xp ] > 0 \u2200xp , (1)\nd\ndxp E[Y |Xp = xp ,Xc = xc ] \u2264 0 \u2200xp ,xc . (2)\nand vice versa (i.e., dE[Y |Xp = xp ]/dxp < 0, dE[Y |Xp = xp ,Xc = xc ]/dxp \u2265 0). Equations (1) and (2) hold if the expected value of Y is a monotonically increasing (or decreasing) function of Xp alone, but conditioned on Xc is a monotonically decreasing (resp. increasing) function of Xp , or is constant."
        },
        {
            "heading": "3.1 Finding Simpson\u2019s Pairs",
            "text": "With this goal in mind, we employ linear models to quantify the relationship between Y , an independent variable Xp , and a conditioning variable Xc upon which the data is disaggregated. Firstly, on the aggregate level, we model the relationship between Y and Xp as a linear model of the form\nE[Y |Xp = xp ] = fp (\u03b1 + \u03b2xp ), (3)\nwhere fp (\u03b1 + \u03b2xp ) is a monotonically increasing function of its argument \u03b1 + \u03b2xp . e parameter \u03b1 in Eq. (3) is the intercept of the regression function, while the trend parameter \u03b2 quanti es the e ect of Xp on Y . Secondly, for the disaggregation, we t linear models of the form of Eq. (3) but with di erent values of the\nparameters \u03b1 and \u03b2 depending on the value of Xc : E[Y |Xp = xp ,Xc = xc ] = fp,c (\u03b1(xc ) + \u03b2(xc )xp ), (4)\nWhen ing linear models f (\u03b1 + \u03b2X ) we have not only a ed trend parameter \u03b2 but also a p-value which gives the probability of nding an intercept \u03b2 at least as extreme as the ed value under the null hypothesis H0 : \u03b2 = 0. From this, we have three possibilities:\n\u2022 \u03b2 is not statistically di erent from zero (sgn(\u03b2) = 0), \u2022 \u03b2 is statistically di erent from zero and positive (sgn(\u03b2) =\n1), \u2022 \u03b2 is statistically di erent from zero and negative (sgn(\u03b2) = -1).\nis mechanism allows us to test for Simpson\u2019s paradox by comparing the sign of \u03b2 from the aggregated t (Eq. (3)) with the signs of the \u03b2 \u2019s from the disaggregated ts (Eq. (4)). Although Eqs. (3) and (4) state that the signs from the disaggregated curves should all be di erent from the aggregated curve, in practice this is too strict, especially as human behavioral data is noisy. us, we compare the sign of the t to aggregated data to the simple average of the signs of ts to disaggregated data\u2014 if the signs are di erent then we have uncovered an instance of Simpson\u2019s paradox. e summary of the algorithm is the following:\nTrend Simpson\u2019s Paradox Algorithm 1 def trend_simpsons_pair(X, Y): 2 paradox_pairs = [] 3 for paradox_var in vars: 4 beta , pvalue =\ntrend_analysis(X[paradox_var], Y) 5 agg = sgn(beta , pvalue) 6 for condition_var in vars: 7 if paradox_var != condition_var: 8 dagg = [] 9 for con_gr in bins_of(condition_var): 10 beta , pvalue =\ntrend_analysis(X[paradox_var | con_gr], Y)\n11 dagg.append(sgn(beta , pvalue)) 12 if agg != sgn(mean(dagg)): 13 paradox_pairs.append ([ paradox_var ,\ncondition_var ]) 14 return paradox_pairs 15 16 def sgn(beta , pvalue = 0.0): 17 return (0 if (beta == 0 or pvalue > 0.05)\nelse (1 if beta > 0 else -1))\nData Disaggregation. A critical step in our method is disaggregating data by conditioning on variable Xc . e idea behind disaggregation is to segment data into more homogeneous subgroups of similar elements. For multinomial variablesXc , disaggregation step simply involves grouping data by unique values of Xc . However, for continuous Xc or discrete variables with large range, this step is more complex. We can bin the elements according to their values of Xc , but the decision has to be made how large each bin is, whether bin sizes scale linearly or logarithmically, etc. If the bin is too small,\nit may not contain enough samples for a statistically signi cant measurement, but if it is too large, the samples may be too heterogeneous for a robust trend. In our experiments described below, bins of xed size successfully identify Simpson\u2019s pairs, though we realize that more sophisticated binning techniques can allow us to isolate more pairs or reduce the number of false positives."
        },
        {
            "heading": "3.2 Mathematical Analysis of the Paradox",
            "text": "We have presented a mathematical formulation of Simpson\u2019s paradox in terms of the derivatives of conditional expectations as given by Eqs. (1) and (2), and we now examine these equations to get a be er insight into the origins and causes of this paradox.\ne expectation in Eq. (1) can be related to that of Eq. (2) as\nE[Y |Xp = xp ] = (5)\u222b Xc E[Y |Xp = xp ,Xc = xc ] Pr(Xc = xc |Xp = xp )dxc ,\nand di erentiating this expectation w.r.t. xp allows us to compare the trends of Eqs. (1) and (2). e derivative of the right hand side of Eq. (5) with respect to xp is\u222b\nXc\n( d\ndxp E[Y |Xp = xp ,Xc = xc ] ) Pr(Xc = xc |Xp = xp )dxc+\u222b\nXc E[Y |Xp = xp ,Xc = xc ]\n( d\ndxp Pr(Xc = xc |Xp = xp )\n) dxc . (6)\nIf E[Y |Xp = xp ,Xc = xc ] is a non-increasing function of xp\u2014as in Eq. (2)\u2014then the rst integral in Eq. (6) will be non-positive. us for E[Y |Xp = xp ] to be an increasing function of xp , i.e., for Eq. (6) to be positive, the second integral must be positive.\nis inequality condition leads to two necessary conditions for the occurrence of Simpson\u2019s paradox. e rst condition is that\nd\ndxp Pr(Xc = xc |Xp = xp ) , 0, (7)\ni.e., the distribution of the conditioning variable Xc is not independent of Xp and so the two variables are correlated. As Xp changes, the distribution of the values of Xc must also change. In the case that the distribution of Xc is independent of Xp , then d Pr(Xc = xc |Xp = xp )/dx = 0 and so the second integral of Eq. (6) will be zero resulting in no Simpson\u2019s paradox.\ne second necessary condition for the occurrence of Simpson\u2019s paradox is that the expectation of Y , conditioned on Xp , must not be independent of Xc , i.e.,\nE[Y |Xp = xp ,Xc = xc ] , E[Y |Xp = xp ]. (8)\nFor any given value of Xp , the expectation of Y must vary as a function of Xc . If the condition of Eq. (8) is not met then the second integral in Eq. (6) becomes\u222b\nXc E[Y |Xp = xp ]\n( d\ndxp Pr(Xc = xc |Xp = xp )\n) dxc (9)\n= E[Y |Xp = xp ] d\ndxp (\u222b Xc Pr(Xc = xc |Xp = xp )dxc ) = 0,\nand so Simpson\u2019s paradox will not occur.\nus, this mathematical analysis has given us an insight into causes for Simpson\u2019s paradox in data \u2014correlations between independent variables and the fact that the distribution of the conditioning variable Xc changes at a faster rate with respect to the independent paradox variable Xp than does the expectation of Y . is point will be covered in greater detail in the next section."
        },
        {
            "heading": "4 RESULTS",
            "text": "We explore our approach using data from the question-answering platform called Stack Exchange. is platform, launched in 2008 to provide a forum for people to ask computer programming questions, grew over the years as a forum asking questions on a variety of technical and non-technical topics. e premise behind Stack Exchange is simple: any user can ask a question, which others may answer. Users can also vote for answers they nd helpful, and the asker can accept one of the answers as the best answer to the question. In this way, the Stack Exchange community collectively curates knowledge."
        },
        {
            "heading": "4.1 Stack Exchange Data",
            "text": "We used anonymized data representing all questions and answers from August 2008 until September 2014.1 e data includes 9.6M questions, of which approximately half had an accepted answer. Only the questions that received two or more answers were included [5]. Previous studies of Stack Exchange [9] and other online platforms [1, 19], identi ed user sessions as an important variable in understanding performance. User actions, i.e., answering questions, can be segmented into sessions\u2014periods of activity without a prolonged break. Following [9] we use 100 minutes as minimum break length to de ne sessions. A time interval longer than 100 minutes between two answers constitutes the end of one session and the start of a new one. Note that the exact value of this threshold does not change results, but simply merge a small fraction of sessions into longer sessions.\nTo understand factors a ecting user performance on Stack Exchange, we study the relationship between user a ributes and the probability that the answer the user produces is accepted by the asker as best answer to his or her question. To this end, for each answer in the data set, we create a list of features describing the answer, as well as features of describing the user writing the answer:\nReputation: Answerer\u2019s reputation at the time he or she posted the answer. is score summarizes the user\u2019s cumulative contributions to Stack Exchange. Number of answers: Cumulative number of answers written by the user at the time the current answer was posted. Tenure: Age of the user\u2019s account (in seconds) at the time the user posted the answer. Percentile: User\u2019s percentile rank based on tenure. Time since previous answer: Time interval (in seconds) since\nuser\u2019s previous answer. Session length: e length of the session (in number of an-\nswers posted) during which the answer was posted. Answer position: Index of the answer within a session. Words: Number of words in the answer. Lines of codes: Number of lines of codes in the answer.\n1h ps://archive.org/details/stackexchange"
        },
        {
            "heading": "Xp : Independent Variable Xc : Conditioning Variable",
            "text": "URLs: Number of hyperlinks in the answer. Readability: Answer\u2019s Flesch Reading Ease [14] score."
        },
        {
            "heading": "4.2 Simpson\u2019s Paradoxes on Stack Exchange",
            "text": "We apply the method described above to Stack Exchange data. Here, our dependent variable Y is binary, denoting whether or not a speci c answer to a question was accepted as the best answer. In this case of binary outcomes we use the logistic regression linear model of the form\nf (\u03b1 + \u03b2x) = 1 1 + e\u2212(\u03b1+\u03b2x ) . (10)\ne parameters \u03b1 and \u03b2 are ed using Maximum likelihood, while test of the null hypothesis H0 : \u03b2 = 0 is performed using the Likelihood Ratio Test [6].\ne eleven variables in Stack Exchange data, result in 110 possible Simpson\u2019s pairs. Among these, our method identi es seven as instance of paradox. ese are listed in Table 1.\nOur approach reveals that the previously reported nding that acceptance probability decreases with answer position [9] is an instance of Simpson\u2019s paradox and would not have been observed had the data not been disaggregated by session length. More interestingly, our approach also identi es previously unknown instances of Simpson\u2019s paradox. We explore these in greater detail below, illustrating how it can lead to deeper insights into online behavior.\n4.2.1 Answer Position & Session Length. We measure session length by the number of answers a user posts before taking an extended break. Session length was shown to be an important confounding variable in online activity. Analysis of the quality of comments posted on a social news platform Reddit showed that, once disaggregated by the length of session, the quality of comments declines over the course of a session, with each successive comment wri en by a user becoming shorter, less textually complex, receiving fewer responses and a lower score from others [19]. Similarly, each successive answer posted during a session by a user on Stack Exchange is shorter, less well documented with external links and code, and less likely to be accepted by the asker as the best answer [9].\nOur approach automatically identi es this example as Simpson\u2019s paradox, as illustrated in Fig. 1. e gure shows average acceptance probability for an answer as a function of its position (or\nindex) within a session. According to Fig. 1a, which reports aggregate acceptance probability, answers wri en later in a session are more likely to be accepted than earlier answers. However, once the same data is disaggregated by session length, the trend reverses (Fig. 1b): each successive answer within the same session is less likely to be accepted than the previous answer. For example, for sessions during which ve answers were wri en, the rst answer is more likely to be accepted than the second answer, which is more likely to be accepted than the third answer, etc., which is more likely to be accepted than the h answer. e lines in Fig. 1 represent ts to data using logistic regression.\nis example highlights the necessity to properly disaggregate data to identify the subgroups for analysis. Unless data is disaggregated, wrong conclusions may be drawn, in this case, for example, that user performance improves during a session.\n4.2.2 Number of Answers & Reputation. Experience plays an important role in the quality of answers wri en by users. Stack Exchange veterans, i.e., users who have been active on Stack Exchange for more than six months, post longer, be er documented answers, that are also more likely to be accepted as best answers by askers [9]. ere are several ways to measure experience on Stack Exchange. Reputation, according to Stack Exchange, gauges how much the community trusts a user to post good questions and provide useful answers. While reputation can be gained or lost with di erent actions, a more straightforward measure of experience is user tenure, which measures time since the user became active on Stack Exchange, or Percentile, normalized rank of a user\u2019s tenure. Alternately, experience can be measured by the Number of Answers a user posted during his or her tenure before writing the current answer.\nOur method uncovers a novel Simpson\u2019s paradox for user experience variables Reputation and Number of Answers. In the aggregate data, acceptance probability increases as a function of the Number of Answers (Fig. 2a). is is consistent with our expectations that the more experienced users\u2014who have wri en more answers over their tenure on Stack Exchange\u2014produce higher quality answers. However, when data is conditioned on Reputation, the trend reverses (Fig. 2b). In other words, focusing on groups of users with the same reputation, those who have wri en more answers over their tenure are less likely to have a new answer accepted than the less active answerers."
        },
        {
            "heading": "4.3 e Origins of Simpson\u2019s paradox",
            "text": "To understand why Simpson\u2019s paradox occurs in Stack Exchange data, we illustrate the mathematical explanation of Section 3.2 with examples from our study. Consider the paradox for Answer Position\u2013Session Length Simpson\u2019s pair, illustrated in Fig. 1a. In the disaggregated data, trend lines of acceptance probability for sessions of di erent length are stacked (Fig. 1b): answers produced during longer sessions are more likely to be accepted than answers\nproduced during shorter sessions. In addition, there are many more shorter sessions than longer ones. Table 2 reports the number of sessions of di erent length. By far, the most common session has length one: users write only one answer during these sessions. Each longer session is about half as common as a session that is one answer shorter.\nWhat happens to the trend in the aggregated data? When calculating acceptance probability as a function of answer position, all sessions contribute to acceptance probability for the rst answer of a session. Sessions of length one dominate the average. When calculating acceptance probability for answers in the second position, sessions of length one do not contribute, and acceptance probability\nis dominated by data from sessions of length two. Similarly, acceptance probability of answers in the third position is dominated by sessions of length three. Survivor bias excludes data from shorter sessions, which also have lower acceptance probability, creating an upward trend in acceptance probability.\nWe back up this intuitive explanation withmathematical analysis of Section 3.2. Although acceptance probability is decreasing as a function of Answer Position for each value of Session Length (Fig. 1b), the probability mass of Session Length is constantly moving towards larger values as Answer Position increases. Notice that as Answer Position increments from a to a + 1, sessions of length a are no longer included (as the minimum session length is now a+ 1). us, while Session Length has probability mass Pr(Xc = a |Xp = a) when Xp = a, it has probability Pr(Xc = a |Xp = a + 1) = 0 at Xp = a + 1:\nd\ndxp Pr(Xc = a |Xp = xp )\u2016xp=a = \u2212 Pr(Xc = a |Xp = a). (11)\nMeanwhile, for all other values of Xc greater than a, the probability mass at Xp = a + 1 is the same as that at Xp = a (as the number of data points is constant along sessions of same length) but normalized to account for the sessions of length a, i.e.,\nPr(Xc = xc |Xp = a + 1) = Pr(Xc = xc |Xp = a)\n1 \u2212 Pr(Xc = a |Xp = a) . (12)\ne rate of change of these probability masses with respect to Xp is\nd\ndxp Pr(Xc = xc |Xp = xp )\u2016xp=a =(\n1 1 \u2212 Pr(Xc = a |Xp = a)\n\u2212 1 ) Pr(Xc = xc |Xp = a). (13)\ne probability mass function Pr(Xc = xc |Xp = a) decreases for Xc = a corresponding to the smallest value of acceptance probability, while increasing for all other values Xc > a. Moreover, the rate of increase of this probability mass is greater than the rate at\nwhich the acceptance probability decreases, resulting in an upward trend when the data is aggregated.\nA similar e ect plays out in the Number of Answers\u2013Reputation Simpson\u2019s pair. Figure 3a shows the heatmap of acceptance probability for di erent values of the Number of Answers wri en over a user\u2019s tenure and user Reputation, while Fig. 3b shows the correlated joint distribution of the two variables. e gures illustrate the rst condition of Simpson\u2019s paradox (Eq. (7)): as Xp changes, the distribution of the values of Xc must also change. is dependency can be clearly seen in Fig. 3b\u2014as Xp = Number o f Answers increases then the distribution ofXc = Reputation shi s to increasing values, which produces the paradox.\nIn the real world this means that users, who have wri en more answers are not more likely to have a new answer they write accepted. In fact, among users with same Reputation, those who earned this reputation with fewer answers are more likely to have a new answer they write accepted as best answer. is suggests that such users are simply be er at answering questions, and that this can be detected early in their tenure on Stack Exchange (while they still have low reputation). Note, however, that an exception to the trend reversal occurs for users with very high reputation. In Stack Exchange, users can gain reputation by \u201cAnswer is marked accepted\u201d, \u201cAnswer is voted up\u201d, \u201c estion is voted up\u201d, etc. It seems that, high reputation users and low reputation users are di erent: for high reputation users, experience (number of wri en answers) is important, while for low reputation users the quality of answers, which may lead to votes, is more important. Analysis of this behavior is beyond the scope of this paper."
        },
        {
            "heading": "4.4 Discussion and Implications",
            "text": "Presence of a Simpson\u2019s paradox in data can indicate interesting or surprising pa erns [8], and for trends in social data, important behavioral di erences within a population. Since social data is o en generated by a mixture of subgroups, existence of Simpson\u2019s\nparadox suggests that these subgroups di er systematically and signi cantly in their behavior. By isolating important subgroups in social data, our method can yield insights into their behaviors.\nFor example, our method identi es Session Length as a conditioning variable for disaggregating data when studying trends in acceptance probability as a function of answer\u2019s position within a session. In fact, prior work has identi ed session length as an important parameter in studies of online performance [1, 9, 15, 19]. Unless activity data is disaggregated into individual sessions\u2014sequences of activity without an extended break\u2014important pa erns are obscured. A pervasive pa ern in online platforms is user performance deterioration, whereby the quality of a user\u2019s contribution decreases over the course of a single session. is deterioration was observed for the quality of answers wri en on Stack Exchange [9], comments posted on Reddit [19], and the time spent reading posts on Facebook [15]. Our method automatically identi es position of an action within a session and session length as an important pair of variables describing Stack Exchange.\nWe examine in detail one novel paradox discovered by our method for the Reputation\u2013Number of Answers variables. e trends in Fig. 2b suggest that both variables jointly a ect acceptance probability. Inspired by this observation, we construct a new variable\u2014 Reputation / Number of Answers\u2014i.e., Reputation Rate. Figure 4 shows how acceptance probability changes with respect to Reputation Rate for di erent groups of users. ere is an strong upward trend, suggesting that answers provided by users with higher Reputation Rate are more likely to be accepted. Moreover, while the lines span reputations of an extremely broad range\u2014from one to 100,000\u2014 they collapse onto a single curve. is suggests that Reputation Rate is a good proxy of user performance. e remaining paradoxes uncovered by our method could yield similarly interesting insights into user behavior on Stack Exchange.\nWe also illustrate the di erence between our method and linear models that model the outcome variable as a function of both Xp andXc . For such multivariate linear models [17], we can t a model fp,c (\u03b1 + \u03b2Xp + \u03b2cXc ) to the disaggregated data, and compare the sign of the coe cient \u03b2 to the sign of the linear coe cient of the \u201caggregated\u201d model fp (\u03b1 + \u03b2Xp ). In our method, we bin the values ofXc and t separate linear models of the form of Eq. (4) in each bin of Xc , aggregating by averaging the linear coe cient signs of each model. We claim that our approach has bene ts over multivariate linear models which allow it to nd Simpson\u2019s pairs where multivariate linear models can not. First, in multivariate linear models, all subgroups have the same coe cient \u03b2 , and intercepts \u03b1 + \u03b2cXc , which vary linearly with Xc . In our method, however, each group can have di erent intercept and coe cient, which makes nding paradox pairs in heterogeneous data more exible. Indeed this exibility is necessary \u2014 from our results (Figs. 1b and 2b) it is clear that the trend parameters \u03b2(xc ) of the ed lines vary signi cantly depending on xc .\nSecondly, our method of aggregating by simple averaging of the linear coe cient signs of the subgroups means that trends within each subgroup are weighted equally regardless of how many datapoints are in that subgroup. is is contrary to multivariate linear models, which t the model parameters based on each datapoint (and so weigh heavily towards values of Xc with many datapoints). To illustrate, we show that our algorithm nds Time Since Previous Answer - Answer Position as a Simpson\u2019s pair, which a multivariate logistic regression does not. e variable Answer Position is the index of the answer a user has completed without an extended (\u00bf100 minute) break, and so Answer Position = 1 if Time Since Previous Answer \u2265 100 minutes and Answer Position > 1 if Time Since Previous Answer < 100 minutes. Fig. (5a) shows that, for Answer Position = 1, the acceptance probability decreases as a function of Time Since Previous Answer, possibly because be er users take shorter breaks. On the other hand, for other Answer Positions the trend is reversed, and acceptance probability increases with Time Since Previous Answer, suggesting that in short term, users who take more time to answer questions or take short breaks between questions write answers of higher quality.\nClearly, Time Since Previous Answer - Answer Position is an important Simpson\u2019s pair, illustrating that time has a bene cial e ect on answer quality ar short time scales. even though it is detrimental on the aggregate level. Multivariate logistic regression does not capture this behaviour, as 65% of the probability mass of Time Since Previous Answer is for values larger than 100 minutes, so when ing fp,c (\u03b1 + \u03b2Xp + \u03b2cXc ) to the data, it tries to t a hyperplane, which describes the majority of the data as best as possible, in this case the decreasing trend corresponding to Answer Position = 1."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "We presented a method for systematically uncovering instances of Simpson\u2019s paradox in data. e method identi es pairs of variables, such that a trend in an outcome as a function of one variable disappears or reverses itself when the same data is disaggregated by conditioning it on the second variable. e disaggregated data corresponds to subgroups within the population generating the data. Our mathematical analysis suggests that Simspon\u2019s paradox\nis caused by both correlations between independent variables in data (Figs. 3b and 5b), as well as di ering behaviour of the outcome variable within subgroups, illustrated here by the stacked curves of Figs. 1b and 2b. Failure to account for this e ect can lead analysis to wrong conclusions about typical behavior of individuals.\nWe applied our method to real-world data from the questionanswering site Stack Exchange. We were speci cally interested in uncovering features a ecting the probability that an answer wri en by a user will be accepted by the asker as the best answer to his or her question. We identi ed eleven relevant features of answers and users. Not only did the method con rm an existing paradox, but it also uncovered new instances of Simpson\u2019s paradox.\nOur work opens several directions for future work. e proposed algorithm could bene t from a more principled method to bin continuous data and more sophisticated techniques for re-aggregating the intercepts of the curves ed to disaggregated data. Also, while it appears that conditioning onXc disaggregates the population into more homogeneous subgroups, we have not used formal methods, such as goodness of t, to test for be er t of regression models to data. Goodness of t may also be used to guide data disaggregation strategies. In addition, our method applies to explicitly declared variables, and not to latent variables that may a ect data. While these and similar questions remain, our proposed method o ers a promising tool for the analysis of heterogeneous social data."
        },
        {
            "heading": "Acknowledgments",
            "text": "We acknowledge funding support from the James S. McDonnell Foundation, Air Force O ce of Scienti c Research (FA9550-17-10327), and by the Army Research O ce (W911NF-15-1-0142)."
        }
    ],
    "title": "Can you Trust the Trend? Discovering Simpson\u2019s Paradoxes in Social Data",
    "year": 2018
}