{
    "abstractText": "We consider the paradigm of a black box AI system that makes life-critical decisions. We propose an \u201carguing machines\u201d framework that pairs the primary AI system with a secondary one that is independently trained to perform the same task. We show that disagreement between the two systems, without any knowledge of underlying system design or operation, is su cient to arbitrarily improve the accuracy of the overall decision pipeline given human supervision over disagreements. We demonstrate this system in two applications: (1) an illustrative example of image classi cation and (2) on large-scale real-world semi-autonomous driving data. For the rst application, we apply this framework to image classi cation achieving a reduction from 8.0% to 2.8% top-5 error on ImageNet. For the second application, we apply this framework to Tesla Autopilot and demonstrate the ability to predict 90.4% of system disengagements that were labeled by human annotators as challenging and needing human supervision.",
    "authors": [
        {
            "affiliations": [],
            "name": "Lex Fridman"
        },
        {
            "affiliations": [],
            "name": "Li Ding"
        },
        {
            "affiliations": [],
            "name": "Benedikt Jenik"
        },
        {
            "affiliations": [],
            "name": "Bryan Reimer"
        }
    ],
    "id": "SP:1e7e4741fb92580bd305d881a850fd26c304f02d",
    "references": [
        {
            "authors": [
                "Mariusz Bojarski",
                "Davide Del Testa",
                "Daniel Dworakowski",
                "Bernhard Firner",
                "Beat Flepp",
                "Prasoon Goyal",
                "Lawrence D Jackel",
                "Mathew Monfort",
                "Urs Muller",
                "Jiakai Zhang"
            ],
            "title": "End to end learning for self-driving cars",
            "year": 2016
        },
        {
            "authors": [
                "Gary Bradski"
            ],
            "title": "The OpenCV Library",
            "venue": "Dr. Dobb\u2019s Journal: Software Tools for the Professional Programmer 25,",
            "year": 2000
        },
        {
            "authors": [
                "Jia Deng",
                "Wei Dong",
                "Richard Socher",
                "Li-Jia Li",
                "Kai Li",
                "Li Fei-Fei"
            ],
            "title": "Imagenet: A large-scale hierarchical image database",
            "venue": "In Computer Vision and Pattern Recognition,",
            "year": 2009
        },
        {
            "authors": [
                "Bradley Efron"
            ],
            "title": "Bootstrap methods: another look at the jackknife",
            "venue": "In Breakthroughs in statistics",
            "year": 1992
        },
        {
            "authors": [
                "Andre Esteva",
                "Brett Kuprel",
                "Roberto A Novoa",
                "Justin Ko",
                "Susan M Swetter",
                "Helen M Blau",
                "Sebastian Thrun"
            ],
            "title": "Dermatologistlevel classi cation of skin cancer",
            "year": 2017
        },
        {
            "authors": [
                "Mark Everingham",
                "SM Ali Eslami",
                "Luc Van Gool",
                "Christopher KI Williams",
                "John Winn",
                "Andrew Zisserman"
            ],
            "title": "The pascal visual object classes challenge: A retrospective",
            "venue": "International journal of computer vision 111,",
            "year": 2015
        },
        {
            "authors": [
                "Lex Fridman"
            ],
            "title": "2018. Tesla Vehicle Deliveries and Autopilot Mileage Statistics",
            "year": 2018
        },
        {
            "authors": [
                "Lex Fridman",
                "Daniel E. Brown",
                "Michael Glazer",
                "William Angell",
                "Spencer Dodd",
                "Benedikt Jenik",
                "Jack Terwilliger",
                "Julia Kindelsberger",
                "Li Ding",
                "Sean Seaman",
                "Hillary Abraham",
                "Alea Mehler",
                "Andrew Sipperley",
                "Anthony Pettinato",
                "Linda Angell",
                "Bruce Mehler",
                "Bryan Reimer"
            ],
            "title": "2017. MIT Autonomous Vehicle Technology Study: Large- Scale Deep Learning Based Analysis of Driver Behavior and Interaction with Automation",
            "year": 2017
        },
        {
            "authors": [
                "Ian Goodfellow",
                "Jean Pouget-Abadie",
                "Mehdi Mirza",
                "Bing Xu",
                "David Warde-Farley",
                "Sherjil Ozair",
                "Aaron Courville",
                "Yoshua Bengio"
            ],
            "title": "Generative Adversarial Nets",
            "venue": "In Advances in Neural Information Processing Systems 27,",
            "year": 2014
        },
        {
            "authors": [
                "Varun Gulshan",
                "Lily Peng",
                "Marc Coram",
                "Martin C Stumpe",
                "Derek Wu",
                "Arunachalam Narayanaswamy",
                "Subhashini Venugopalan",
                "Kasumi Widner",
                "Tom Madams",
                "Jorge Cuadros"
            ],
            "title": "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs",
            "venue": "Jama 316,",
            "year": 2016
        },
        {
            "authors": [
                "David Gunning"
            ],
            "title": "Explainable arti cial intelligence (xai). Defense Advanced Research Projects Agency (DARPA), nd Web (2017)",
            "year": 2017
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "In Proceedings of the IEEE 10 conference on computer vision and pattern recognition",
            "year": 2016
        },
        {
            "authors": [
                "Robert C Hilborn"
            ],
            "title": "Sea gulls, butter ies, and grasshoppers: A brief history of the butter y e ect in nonlinear dynamics",
            "venue": "American Journal of Physics 72,",
            "year": 2004
        },
        {
            "authors": [
                "Geo rey Hinton",
                "NiRsh Srivastava",
                "Kevin Swersky"
            ],
            "title": "Neural Networks for Machine Learning Lecture 6a Overview of mini\u2013batch gradient descent",
            "year": 2012
        },
        {
            "authors": [
                "Brody Huval",
                "Tao Wang",
                "Sameep Tandon",
                "Je Kiske",
                "Will Song",
                "Joel Pazhayampallil",
                "Mykhaylo Andriluka",
                "Pranav Rajpurkar",
                "Toki Migimatsu",
                "Royce Cheng-Yue"
            ],
            "title": "An empirical evaluation of deep learning on highway driving",
            "year": 2015
        },
        {
            "authors": [
                "G Kendrey",
                "B Szende",
                "K Lapis",
                "T Marton",
                "B Hargitai",
                "FJ Roe",
                "PN Lee"
            ],
            "title": "Misdiagnosis of lung cancer in a 2000 consecutive autopsy study in Budapest. General & diagnostic pathology",
            "year": 1996
        },
        {
            "authors": [
                "Jinkyu Kim",
                "John Canny"
            ],
            "title": "Interpretable Learning for Self- Driving Cars by Visualizing Causal Attention",
            "venue": "In The IEEE International Conference on Computer Vision (ICCV)",
            "year": 2017
        },
        {
            "authors": [
                "John C Knight"
            ],
            "title": "Safety critical systems: challenges and directions",
            "venue": "In Software Engineering,",
            "year": 2002
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Geo rey E Hinton"
            ],
            "title": "ImageNet Classi cation with Deep Convolutional Neural Networks",
            "venue": "In Advances in Neural Information Processing Systems 25,",
            "year": 2012
        },
        {
            "authors": [
                "Anders Krogh",
                "Jesper Vedelsby"
            ],
            "title": "Neural network ensembles, cross validation, and active learning. Advances in neural information processing systems",
            "year": 1995
        },
        {
            "authors": [
                "Alex Kue er",
                "Jeremy Morton",
                "Tim Wheeler",
                "Mykel Kochenderfer"
            ],
            "title": "Imitating driver behavior with generative adversarial networks",
            "venue": "In IEEE Intelligent Vehicles Symposium",
            "year": 2017
        },
        {
            "authors": [
                "Volodymyr Mnih",
                "Adria Puigdomenech Badia",
                "Mehdi Mirza",
                "Alex Graves",
                "Timothy Lillicrap",
                "Tim Harley",
                "David Silver",
                "Koray Kavukcuoglu"
            ],
            "title": "Asynchronous methods for deep reinforcement learning",
            "venue": "In International Conference on Machine Learning",
            "year": 2016
        },
        {
            "authors": [
                "Vinod Nair",
                "Geo rey E Hinton"
            ],
            "title": "Recti ed linear units improve restricted boltzmann machines",
            "venue": "In Proceedings of the 27th international conference on machine learning",
            "year": 2010
        },
        {
            "authors": [
                "Usman Pirzada"
            ],
            "title": "Tesla AutoPilot - An In-Depth Look At The Technology Behind the Engineering Marvel. (Dec 2015). http:// wccftech.com/tesla-autopilot-story-in-depth-technology/ [Online; posted 3-Dec-2015",
            "year": 2015
        },
        {
            "authors": [
                "Dean A. Pomerleau"
            ],
            "title": "ALVINN: An Autonomous Land Vehicle in a Neural Network",
            "venue": "In Advances in Neural Information Processing Systems 1,",
            "year": 1989
        },
        {
            "authors": [
                "St\u00e9phane Ross",
                "Geo rey J Gordon",
                "Drew Bagnell"
            ],
            "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning",
            "venue": "In AISTATS,",
            "year": 2011
        },
        {
            "authors": [
                "Olga Russakovsky",
                "Jia Deng",
                "Hao Su",
                "Jonathan Krause",
                "Sanjeev Satheesh",
                "Sean Ma",
                "Zhiheng Huang",
                "Andrej Karpathy",
                "Aditya Khosla",
                "Michael Bernstein"
            ],
            "title": "Imagenet large scale visual recognition challenge",
            "venue": "International Journal of Computer Vision 115,",
            "year": 2015
        },
        {
            "authors": [
                "Karen Simonyan",
                "Andrew Zisserman"
            ],
            "title": "Very deep convolutional networks for large-scale image recognition",
            "venue": "arXiv preprint arXiv:1409.1556",
            "year": 2014
        },
        {
            "authors": [
                "Nitish Srivastava",
                "Geo rey Hinton",
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Ruslan Salakhutdinov"
            ],
            "title": "Dropout: A simple way to prevent neural networks from over tting",
            "venue": "The Journal of Machine Learning Research 15,",
            "year": 2014
        },
        {
            "authors": [
                "Christian Szegedy",
                "Wei Liu",
                "Yangqing Jia",
                "Pierre Sermanet",
                "Scott Reed",
                "Dragomir Anguelov",
                "Dumitru Erhan",
                "Vincent Vanhoucke",
                "Andrew Rabinovich"
            ],
            "title": "Going Deeper with Convolutions",
            "venue": "In Computer Vision and Pattern Recognition (CVPR)",
            "year": 2015
        },
        {
            "authors": [
                "David H Wolpert"
            ],
            "title": "Stacked generalization",
            "venue": "Neural networks 5,",
            "year": 1992
        },
        {
            "authors": [
                "Huazhe Xu",
                "Yang Gao",
                "Fisher Yu",
                "Trevor Darrell"
            ],
            "title": "End-To- End Learning of Driving Models From Large-Scale Video Datasets",
            "venue": "In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "year": 2017
        },
        {
            "authors": [
                "Jiakai Zhang",
                "Kyunghyun Cho"
            ],
            "title": "Query-E cient Imitation Learning for End-to-End Simulated Driving",
            "venue": "In Proceedings of the Thirty-First AAAI Conference on Arti cial Intelligence, February",
            "year": 2017
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Successful operation of intelligent automated systems in realworld applications where errors are assigned extremely high\ncosts, such as when the systems are tasked with making life-critical decisions, is one of the grand challenges facing the AI community. The di culty is not within the task itself, but rather in the small margin of allowable error given the human life at stake and the large number of edge cases that have to be accounted for in real-world operation. This challenge has two categories of approaches: (1) improve the accuracy of the system such that it reaches the acceptable level of performance, or (2) integrate the system with a human supervisor that aids its operation such that the combined system of human and machine reach the acceptable level of performance. The former set of approaches has been the focus of the machine learning community. The latter is the focus of this paper.\nWe consider the real-world operating paradigm of a black box AI system (termed \u201cprimary system\u201d) that is tasked with making life-critical decisions. The proposed method integrates the human being into the critical role of resolving uncertainty and disagreement in decisions whose errors are associated with high negative utility values. We demonstrate this system in two applications: (1) an illustrative example of image classi cation and (2) on large-scale real-world semiautonomous driving data. For the rst application, we show\n* Corresponding author. Email: fridman@mit.edu.\nar X\niv :1\n71 0.\n04 45\nthis framework applied to image classi cation achieving an improvement from 8.0% to 2.8% top-5 error on ImageNet over ResNet-50 network (treated as a black box). For the second application, we apply the arguing machines framework to monocular-vision-based automated steering systems. The rst is a proprietary Tesla Autopilot system equipped in the rst generation of Autopilot-capable vehicles. The second is an end-to-end neural network trained on a largescale naturalistic dataset of 420 hours or 45 million frames of autonomous driving in Tesla vehicles. We demonstrate the ability of the overall arguing machines to predict 90.4% of system disengagements that were deemed as \u201ctricky\u201d by human annotators and thus likely to be associated with highprobability of driver injury if not handled by the driver.\nThis paper demonstrates the surprising and impactful nding that the disagreement between two systems, without any knowledge of the design of either system, may have su - cient information to signi cantly improve the performance of the overall framework when combined with human supervision. This result has serious implications for the design of e ective and safe human-computer interaction experiences."
        },
        {
            "heading": "Arguing Machines Concept",
            "text": "The \u201cblack box\u201d nature of AI systems is the property of some machine learning approaches that make it di cult to \u201csee inside\u201d the model inference process that makes a particular decision. This is both due to the inherent di cult of engineering explainable AI systems [13] and the natural reluctance by companies that provide the AI system to visualize the inner workings of the system and to reveal uncertainty of predictions and system errors. The motivation for this work is that there are applications in which such errors can lead to loss of human life. Errors are inherently part of supervised machine\nlearning systems that seek to generalize from patterns of the past to pattern of the present. It is very di cult to engineer such errors out completely. We propose to instead manage them by integrating the human being as a supervisor. This is important for both creating a safe interaction with an AI system, but also a more e ective human-computer interaction experience that develops an appropriate amount of trust and understanding.\nFig. 1 shows the arguing machines framework. Consider that there is a primary AI system trained to perform a speci c task. A task is de ned as making a decision based on a well-de ned input. For image classi cation (see \u00a73), the task is to take an image as input and make a prediction of likelihood that the image is one of a number of categories. For autonomous steering (see \u00a74), the task is to take a sequence of video frames of the forward roadway and make a steering decision. The output of this system is a decision, discrete in the former case and continuous in the latter case. The arguing machines framework introduces a secondary system trained to perform the same task without any interaction with the primary system. The disagreement between the two systems is measured by the arbitrator and passed to a human supervisor if the disagreement exceeds a constant prede ned threshold. This threshold controls the tradeo between the relative amount of human supervision and overall system error as illustrated in Fig. 1."
        },
        {
            "heading": "Real-World Application: Autonomous Driving",
            "text": "We use image classi cation in \u00a73 as an illustrative case study to demonstrate the concept of arguing machines. However, in this work, the central case study of applying the arguing machines framework in the real world is semi-autonomous driving (detailed in \u00a74). We chose this application because\nit is a domain where AI systems are already making hundreds of thousands of life-critical decisions every day in Tesla vehicles equipped with Autopilot [9] and many other cars equipped with various degrees of automation [10]. These perception-control systems are black box AI systems that provide very limited communication of system limits, uncertainty, and errors to the driver. Therefore, we believe applying the arguing machines framework in this context may help integrate the human driver in a way that may help save their life.\nAs shown in Fig. 2, for the semi-autonomous driving case study, the role of the primary machine is served by the rst generation of Tesla Autopilot software with the perception and steering predictions performed by the integrated Mobileye system [27]. The role of the secondary machine in this paper is served by an end-to-end convolutional neural network similar to that described and evaluated in [1] except that our model considers the temporal dynamics of the driving scene by taking as input some aspects of the visual change in the forward-facing video for up to 1 second back in time (see \u00a74). The output of both systems is a steering angle. The di erences in those outputs is what constitutes the argument based on which disengagement suggestions and edge case proposals are made. The network model is trained on a balanced dataset constructed through sampling from 420 hours of real-world on-road automated driving by a eet of 16 Tesla vehicles [10] (see \u00a74).\nThe central idea proposed in this work is that robustness of the arti cial intelligence system behind the perception and planning necessary for automated driving can be achieved by supplementing the training dataset with edge cases automatically discovered through monitoring the disagreement between multiple machine learning models.\nWe implement and deploy the system described in this work to show its capabilities and performance in real-world conditions. Its successful operation is exhibited in an extensive, on-road video demonstration that is made publicly available at https://hcai.mit.edu/arguing-machines. As Fig. 8 shows, we instrumented a Tesla Model S vehicle with an NVIDIA Jetson TX2 running the neural network based perceptioncontrol system and disagreement function in real-time. The input to the system is a forward-facing monocular camera and the output are steering commands. The large display shows steering commands both from the primary system (Tesla) and secondary system (neural network), and noti es the driver when a disagreement is detected.\nThe case studies presented in this paper have associated data, source code, and demonstration videos that are made available on https://hcai.mit.edu/arguing-machines."
        },
        {
            "heading": "2 RELATEDWORK",
            "text": "Life-critical and safety-critical systems are those whose failure may result in loss of human life [20]. Naturally, many domains of real-world human-machine interaction involve risk of injury and loss of life through a long sequence of cause and e ect that is far removed from the initial decisions made by the machine. In this work, we are focusing on applications where a single erroneous decision by an AI system has a high-likelihood of causing direct harm to a human being in a way that does not separate the initial decision from the nal negative result via a chaos of unintended consequences. This latter paradigm is less amenable to analysis [15].\nThe real-world application data analyzed in this work is from the domain of autonomous vehicle perception-control systems. Other application domains where AI systems make life-critical decision include medicine, nuclear engineering, aviation, and autonomous weapon systems. Medical diagnosis is the process in medicine that is clearly amenable to assistance by AI systems, assuming the speci c diagnosis task can be formalized and digitally grounded in human measurement data. In many cases, this process is life-critical in that a misdiagnosis (incorrect diagnosis) can lead to bodily harm and loss of life [18]. Such a diagnosis task can be directly formed into an exam classi cation problem, allowing for supervised deep learning methods to be e ectively applied. In exam classi cation, one or multiple images (an exam sample) as input is matched with a single diagnostic variable as output (e.g., disease present or not). [12] applies deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs. [7] demonstrates classi cation of skin lesions using a single CNN, trained end-to-end from images directly to predict disease labels."
        },
        {
            "heading": "Ensemble of Neural Networks",
            "text": "The idea of multiple networks collaborating or competing against each other to optimize an objective have been implemented in various contexts. For example, multiple networks have been combined together in order to improve accuracy [22] as have traditionally been explored in machine learning as ensembles of classi ers. For deep neural networks, [32] propose a technique that provides a way of approximately combining exponentially many di erent network architectures. Recent work [14] combine six models of di erent depth to form an ensemble. [34] independently trained seven versions of the same network with same initialization, which only di er in sampling methodologies and the randomized input image order. In these approaches, decision-level fusion is performed across many classi ers in order to increase accuracy and robustness of the overall system.\nBesides, ensemble can also be done on the dataset-level. Early statistical sampling methods such as [6] can be used to improve the performance and get the con dence interval of a model. [8, 30] use the method to test whether the performance of di erent networks is statistically signi cantly di erent, and obtain the con dence interval of error rate. Moreover for computer vision speci cally, various ensemble methods can be done on input-level, such as averaging prediction of ve di erent crops and their horizontal re ections [21], multi-scale multi-crop prediction [14, 31, 34], are commonly used to increase accuracy and robustness of the whole system during testing. However, [34] also note that such terminology may not be necessary in real-world applications, as the bene t of which becomes marginal after a reasonable number.\nAlternatively, generative adversarial networks (GANs) [11] have two di erent networks working against each other for representation learning and subsequent generation of samples from those learned representations, including generation of steering commands [23]. Neural networks have also been used in di erent environments at the same time [24] to learn from them in parallel, or, as in our work, to look at what the disagreement to other systems reveals about the underlying state of the world the networks operate in. Although not directly referred in our work, the above research share the similar idea of using the disagreement between different systems, and indicates that there is much information contained in such disagreement."
        },
        {
            "heading": "End-to-End Approaches to Driving",
            "text": "In contrast to modular engineering approaches to self-driving systems, where deep learning only plays a role for the initial scene interpretation step [17], it is also possible to approach driving as a more holistic task that can possibly be solved in a data-driven way by a single learner: an end-to-end neural network. First attempts were made almost 30 years ago [28], long before the recent GPU-enabled performance breakthroughs in deep learning [21].\nA similar, but more modern approach using deeper, convolutional nets has been deployed in an experimental vehicle by NVIDIA [1], and further improvements to that were made using various forms of data augmentation [29] and adapted to the driving context by [37]. A more advanced approach [36] formulates autonomous driving as a vehicle egomotion prediction problem, and uses an end-to-end sequence model built upon a scene perception model. They also show that by training scene perception alone as a side task further improves the whole system. Recently, [19] studies the visual explanations and network\u2019s behavior in end-to-end driving, by using a visual attention model to train a convolutional network from images to steering angle."
        },
        {
            "heading": "3 ARGUING MACHINES FOR IMAGE CLASSIFICATION ON IMAGENET",
            "text": "The ImageNet Dataset [5] and Challenge [30] has become the standard benchmark for large-scale object recognition, allowing signi cant algorithmic advances in large-scale image recognition and retrieval. Most of the state-of-the-art approaches [14, 21, 31] are variants of deep convolutional neural network architectures. However, although signi - cant strides toward solving the image classi cation problem have been taken, the systems are still far from perfection. We chose image classi cation as the illustrative case study because it is one of the best studied problems in arti cial intelligence, and yet even in this well-studied problem space, we can demonstrate improvement by integrating human supervision via the arguing machines framework.\nIf we consider the general process of decision making, aggregating ideas from multiple sources strengthens the generalizability of the decision. A single source is likely to be biased due to factors of data selection or underlying model speci cs. This concept is widely used in machine learning algorithms to improve performance. Despite the fact that deep neural networks models themselves are ensembles of linear functions with non-linear activations, unsupervised ensemble methods such as bootstrap [6], bagging [3], dropout [32] and supervised ones such as stacking [4, 35] can be utilized to improve the generalization accuracy of the overall system.\nIn this paper we consider the idea that in collaborative decision making, disagreement may contain as much if not more critical information than agreement, especially when the individual decision makers are very good at the task in question. We explore this kind of disagreement in a machine learning scenario, and seek to leverage the information behind such disagreement in order to improve the overall performance of the system..\nIn this section, we illustrate the idea of arguing machines with a toy experiment on ImageNet Dataset. The arguing machines framework is proposed as follows. Suppose, there exists a state-of-the-art black-box AI system (primary system) whose accuracy is great but not perfect. In order to safely use or test the system, we propose to have a secondary system that can argue with the primary system. When disagreement arises between two systems, we regard it as a di cult case and mark it as needing human supervision. The purpose of arguing machines is to improve the system performance with minimal human e ort, especially when the primary system is a black-box and gives no other information except the nal output.\nThe experiment in this section is a common image classi - cation task. We take two popular image recognition models, VGG [31] and ResNet [14]. Speci cally, we treat a single ResNet-50 model as the black-box and a VGG-16 model as\nan end-to-end deep learning model. The models are pretrained and we obtain the prediction results from single center-cropped images in the ImageNet validation set.\nThe arguing machines arbitrator detects the disagreement when the top predictions of two systems di er. In this experiment, ResNet and VGG disagree on 11645 images, which is 23.3% of the whole validation set. For the results of arguing machines, we assume with human taking look at the disagreement cases, the classi cation is always correct. We also propose a baseline method that with the same amount of images send to human veri cation (always correct), but randomly selected. We evaluate both the top-1 error and the top-5 error. The results are shown in Table 1.\nThe results show that with the arguing machines framework, the performance of a state-of-the-art image recognition system can be signi cantly improved, even when we treat it as a black-box system.\nTable 2 shows the analysis of arguing machines in this context. With less than a quarter of images veri ed by a human supervisor, the arguing machines framework is able to detect more than half of the failure cases in both top-1 and top-5 tasks, even given the fact that both systems already have very strong performance. Such results also indicate that although two deep convolutional neural networks are trained on the same dataset, with similar architectures featuring a combination of convolutional layers, fully connected layers, dropout layers, etc., the behavior of the two trained systems is quite di erent, as they do not fail the same way during testing. This is a surprising and fascinating result that reveals the predictive power of disagreement between arti cial intelligence systems.\nThe precision of top-5 classi cation is much lower than top-1, because the two systems can be both correct even if they disagree on the top prediction. However the recall for both top-1 and top-5 tasks are consistently high, indicating that even with the simpler classi cation task, where systems fail less often, the arguing machines framework can still detect many of the failure cases with disagreements and in so doing signi cantly reduce the error.\nExamples of disagreements between the primary and secondary systems on the image classi cation task are shown in Fig. 3. More examples, including disagreement over object detection and classi cation in video, are available online at https://hcai.mit.edu/arguing-machines."
        },
        {
            "heading": "4 ARGUING MACHINES FOR SEMI-AUTONOMOUS DRIVING",
            "text": "Software is taking on greater operational control in modern vehicles and in so doing is opening the door to machine learning. These approaches are fundamentally hungry for data, based on which, they aim to take on the higher level perception and planning tasks. As an example, over 15 million vehicles worldwide are equipped with Mobileye computer vision technology [33], including the rst generation Autopilot system that serves as the \u201cprimary machine\u201d in this work.\nGiven the requirement of extremely low error rates and need to generalize over countless edge cases, large-scale annotated data is essential to making these approaches work in real-world conditions. In fact, for driving, training data representative of all driving situations may be more important than incremental improvements in perception, control, and planning algorithms. Tesla, as an example, is acknowledging this need by asking its owners to share data with the company for the explicit purpose of training the underlying machine learning models. Our work does precisely this, applying end-to-end neural network approaches to training on large-scale, semi-autonomous, real-world driving data. The resulting model serves as an observer and critic of the primary system with the goals of (1) discovering edge cases in the o ine context and (2) bringing the human back into the loop when needed in the online context.\nWe perform two evaluations in our application of arguing machines to semi-autonomous driving. First, we evaluate the ability of the end-to-end network to predict steering angles commensurate with real-world steering angles that were used to keep the car in its lane. For this, we use distinct periods of automated lane-keeping during Autopilot engagement as the training and evaluation datasets. Second, we evaluate the ability of an argument arbitrator (termed \u201cdisagreement function\u201d) to estimate, based on a short time window, the likelihood that a transfer of control is initiated, whether by the human driver (termed \u201chuman-initiated\u201d) or\nthe Autopilot system itself (termed \u201cmachine-initiated\u201d). We have 6,500 total disengagements in our dataset. All disengagements (whether human-initiated or machine-initiated) are considered to be representative of cases where the visual characteristics of the scene (e.g., poor lane markings, complex lane mergers, light variations) were better handled by a human operator. Therefore, we chose to evaluate the disagreement function by its ability to predict these disengagements, which it is able to do with 90.4% accuracy (see Fig. 6)."
        },
        {
            "heading": "Naturalistic Driving Dataset",
            "text": "The dataset used for the training and evaluation of the end-toend steering network model comprising the \u201csecondary machine\u201d is taken from a large-scale naturalistic driving study of semi-autonomous vehicle technology [10]. Speci cally, we used 420 hours of driving data where a Tesla Autopilot system was controlling both the longitudinal and lateral movement of the vehicle.\nThis subset of the full naturalistic driving dataset served as ground truth for automated lane keeping. In other words, given the operational characteristics of Autopilot, we know that the vehicle only leaves the lane in two situations: (1) during automated lane changes and (2) as part of a \u201cdisengagement\u201d where the driver elects or is forced to take back control of the vehicle. We have the full enumeration of both scenarios. The latter is of particular interest to the task of arguing machines, as one indication of a valuable disagreement is one that is associated with a human driver feeling su ciently uncomfortable to elect to take back control of the vehicle. There are 6,500 such instances of disengagement that are used for evaluating the ability of the disagreement function to discover edge cases and challenging driving scenarios as discussed in \u00a74."
        },
        {
            "heading": "End-to-End Learning of the Steering Task",
            "text": "Our model, which is inspired by [1] uses 5 convolutional layers, the rst 3 with a stride of 2 \u00d7 2 and 5 \u00d7 5 kernels and the remaining 2 keeping the same stride, while switching to smaller 3 \u00d7 3 kernels. On top of that, we add 4 fully connected layers going down to output sizes of 100, 50, 10, and 1, respectively. Throughout the net ReLU activations [25] are used on the layers. In addition, we use Dropout [21] as regularization technique on the fully connected layers. The net is trained using an RMSprop [16] optimizer minimizing the mean squared error between predicted and actual steering angle.\nSince a large part of driving - and therefore also our dataset - consists of going straight, we had to speci cally select input images to remove that imbalance, and resulting bias towards lower steering angle values the net would learn otherwise.\nTo accomplish this dataset balancing task, we calculate a threshold using the minimum number of available frames in steering angle ranges of one degree. This threshold is then used within the range of interest of [\u221210\u25e6, 10\u25e6] steering angle to allow at max threshold frames get selected to achieve a balance. This results in about 100,000 training and 50,000 validation frames.\nFor the input to the neural network we considered 5 different preprocessing methods (see Fig. 4) - referenced as M1 - M5 in the following sections - each producing a 256 \u00d7 144 image with 3 channels. M5 uses the method proposed in [1] as a comparison, consisting of the RGB channels of a single frame. M4 uses the same single frame, but precomputes edges on each color channel.\nTo improve the accuracy beyond that, for input methods M1 to M3 we use a temporal component, meaning multiple frames, to improve situation awareness. M3, in addition to the current frame, also looks 10 and 20 frames back and provides the grayscale version of them as the input image channels. M2 goes beyond that and, in addition to using multiple frames as input, also subtracts them from each other, which helps with an implicit input normalization, as well as automatically highlighting the important moving parts like lane markings. The exact mathematical formulation of the input is:\nIt = {(Ft \u2212 Ft\u221210), (Ft \u2212 Ft\u22125), (Ft \u2212 Ft\u22121)} (1)\nwhere It and Ft are the input to the neural network and the video frame at time t . The unit of time is 1 video frame or 33.3 milliseconds given the 30 fps video used in this work.\nIn (1), each channel is based on the current frame, but also incorporates a \u201c ashback\u201d to another frame further back.\nM1 does not use \u201c ashbacks\u201d, but instead looks at the changes that happened over a series of time segments - each 10 frames long, as follows:\nIt = {(Fi\u221220 \u2212 Fi\u221230), (Ft\u221210 \u2212 Ft\u221220), (Ft \u2212 Ft\u221210)} (2)\nTo evaluate the network using the di erent preprocessing methods, we compute the mean absolute steering angle error over the validation set. The results are shown in Fig. 5. Precomputing edges (M4) already leads to improved performance over just supplying the RGB image (M5), and providing temporal context (M1-M3) does even better, with \u201c ashbacks\u201d (M2) performing better than just providing multiple frames (M3), and comparing time segments (M1) performing best. For the evaluation of the disagreement function in \u00a74, we use M1."
        },
        {
            "heading": "Disagreement Function and Edge Case Discovery",
            "text": "The goal for the disagreement function is to compare the steering angle suggested by the \u201cprimary machine\u201d (Autopilot) and the \u201csecondary machine\u201d (neural network) and based on this comparison to make a binary classi cation of whether\nthe current situation is a challenging driving situation or not. The disagreement function can take many forms including modeling the underlying entropy of the disagreement, but the function computed and evaluated in this work purposefully took on a simple form through the following process:\n(1) Normalize the steering angle for both the primary and secondary machines to be in [\u22121, 1] normalized by the range [\u221210, 10] and all angles exceeding the range are set to the range limits. (2) Compute the di erence between the normalized steering suggestions and sum them over a window of 1 second (or 30 samples). (3) Make the binary classi cation decision based on a disagreement threshold \u03b4 .\nThe metrics used for evaluating the performance of the disagreement system are false accept rate (FAR) and false reject rate (FRR). Where the detection event of interest is the Autopilot disengagement. In other words, an \u201caccept\u201d\nis a prediction that this moment in time is likely to be associated with a disengagement and can thus be considered an edge case for the machine learning system. A \u201creject\u201d is a prediction that this moment in time is not likely to be associated with a disengagement. In order to compute FAR and FRR measure for a given value of \u03b4 , we use classi cation windows evenly sampled from disengagement periods and non-disengagement periods. A disengagement period is de ned as the 5 seconds leading up to a disengagement and 1 second following it.\nThe illustrative example in Fig. 7 shows the temporal dynamics of the two steering suggestions, the resulting disagreement, and the role of \u03b4 in marking that moment leading up to the disengagement as an edge case. The ROC curve in Fig. 6 shows, by varying \u03b4 , that the optimal mean error rate is 0.096, and is achieved when \u03b4 = 10. This means that given any 1 second period of Autopilot driving in our test dataset, the di erence function can predict whether a disengagement will happen in the next 5 seconds with 90.4% accuracy. This\nis a promising result that motivates further evaluation of the predictive power of the disagreement function both on a larger dataset of Autopilot driving and in real-world on-road testing."
        },
        {
            "heading": "On-Road Deployment",
            "text": "As part of exploring and validating the concept of arguing machines we also built a version that runs real time inside a car. This system consists of a NVIDIA Jetson TX2 to run the model, a 23 inch high resolution screen for the human interface attached over the center stack of a Tesla Model S with Autopilot version 1, a custom interface to connect to the vehicle CAN bus to get its current steering angle and a dashboard-mounted Logitech C920 camera capturing the forward roadway scene at 720p resolution at 30fps.\nThe system uses OpenCV\u2019s camera capture module [2] to get a live, real-time video stream of the road scene from the C920 camera. The captured image is stored in a shortterm, dynamic, temporally-sorted bu er structure and uses that bu er structure to assemble the right combination of frames. In this case, we used our best network model (M1), where frames that are 10, 20 and 30 frames back in time are combined with the current frame to compute the input for the neural network. The in-car neural network uses the same network layout as described above, running an optimized PyTorch [26] implementation on the Jetson TX2\u2019s Tegra Parker SoC with a Pascal GPU compute chip. The steering angle computed by the neural network and the one captured from Tesla\u2019s autopilot system are then fed into the actual disagreement measurement routine and additionally displayed on the center stack mounted screen. In addition, in case of a severe disagreement, the system also displays a \u201cdisagreement detected\u201d warning on the same screen.\nEven though this system is a proof of concept, it achieves a latency from camera input to screen GUI update of less than 200 milliseconds, while performing neural network inference in real time. During an on-road demonstration during evening rush hour it appears to work reliably and help to warn the driver of oncoming di cult situations in multiple instances. The video of the demonstration is available online at https://hcai.mit.edu/arguing-machines."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "This work proposes a framework for integrating a human supervisor into the decision making process of a black box AI system that is tasked with making life critical decision. We demonstrate this framework in two applications: (1) an illustrative example of image classi cation and (2) on largescale real-world semi-autonomous driving data. For the rst application, we apply this framework to image classi cation\nachieving a reduction from 8.0% to 2.8% top-5 error on ImageNet. For the second application, we apply this framework to Tesla Autopilot and demonstrate the ability to predict 90.4% of system disengagements that were labeled by human annotators as challenging and needing human supervision. Finally, we implement, deploy, and demonstrate our system in a Tesla Model S vehicle operating in real-world conditions."
        }
    ],
    "title": "Arguing Machines: Human Supervision of Black Box AI Systems That Make Life-Critical Decisions",
    "year": 2018
}