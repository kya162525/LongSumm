{
    "abstractText": "Many systems for the parallel processing of big data are available today. Yet, few users can tell by intuition which system, or combination of systems, is \u201cbest\u201d for a given workflow. Porting workflows between systems is tedious. Hence, users become \u201clocked in\u201d, despite faster or more efficient systems being available. This is a direct consequence of the tight coupling between user-facing front-ends that express workflows (e.g., Hive, SparkSQL, Lindi, GraphLINQ) and the back-end execution engines that run them (e.g., MapReduce, Spark, PowerGraph, Naiad). We argue that the ways that workflows are defined should be decoupled from the manner in which they are executed. To explore this idea, we have built Musketeer, a workflow manager which can dynamically map front-end workflow descriptions to a broad range of back-end execution engines. Our prototype maps workflows expressed in four highlevel query languages to seven different popular data processing systems. Musketeer speeds up realistic workflows by up to 9\u00d7 by targeting different execution engines, without requiring any manual effort. Its automatically generated back-end code comes within 5%\u201330% of the performance of hand-optimized implementations.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ionel Gog"
        },
        {
            "affiliations": [],
            "name": "Malte Schwarzkopf"
        },
        {
            "affiliations": [],
            "name": "Natacha Crooks"
        },
        {
            "affiliations": [],
            "name": "Matthew P. Grosvenor"
        },
        {
            "affiliations": [],
            "name": "Allen Clement"
        },
        {
            "affiliations": [],
            "name": "Steven Hand"
        }
    ],
    "id": "SP:ce7b1bcb3608dfe7cab1648bc18ca2e3f1f6a998",
    "references": [
        {
            "authors": [
                "R.M. BELL",
                "Y. KOREN",
                "C. VOLINSKY"
            ],
            "title": "The BellKor solution to the Netflix prize",
            "venue": "Tech. rep., AT&T Bell Labs,",
            "year": 2008
        },
        {
            "authors": [
                "Y. BU",
                "V. BORKAR",
                "J. JIA",
                "M.J. CAREY",
                "C. TYSON"
            ],
            "title": "Pregelix: Big(ger) Graph Analytics on A Dataflow Engine",
            "venue": "Proceedings of the VLDB Endowment 8,",
            "year": 2015
        },
        {
            "authors": [
                "R. CHAIKEN",
                "B. JENKINS",
                "P. LARSON",
                "B. RAMSEY",
                "D. SHAKIB",
                "S. WEAVER",
                "J. ZHOU"
            ],
            "title": "SCOPE: easy and efficient parallel processing of massive data sets",
            "venue": "Proceedings of the VLDB Endowment 1,",
            "year": 2008
        },
        {
            "authors": [
                "C. CHAMBERS",
                "A. RANIWALA",
                "F. PERRY",
                "S. ADAMS",
                "R. HENRY",
                "R. BRADSHAW",
                "N. WEIZENBAUM"
            ],
            "title": "FlumeJava: easy, efficient data-parallel pipelines",
            "venue": "In ACM SIGPLAN Notices (2010),",
            "year": 2010
        },
        {
            "authors": [
                "C. CHAMBERS",
                "A. RANIWALA",
                "F. PERRY",
                "S. ADAMS",
                "R.R. HENRY",
                "R. BRADSHAW"
            ],
            "title": "AND WEIZENBAUM, N. FlumeJava: Easy, Efficient Data-parallel Pipelines",
            "venue": "In Proceedings of PLDI",
            "year": 2010
        },
        {
            "authors": [
                "B. CHATTOPADHYAY",
                "L. LIN",
                "W. LIU",
                "S. MITTAL",
                "P. ARAGONDA",
                "V. LYCHAGINA",
                "Y. KWON",
                "M. WONG"
            ],
            "title": "Tenzing: a SQL implementation on the MapReduce framework",
            "venue": "Proceedings of the VLDB Endowment 4,",
            "year": 2011
        },
        {
            "authors": [
                "Y. CHEN",
                "S. ALSPAUGH",
                "R. KATZ"
            ],
            "title": "Interactive analytical processing in big data systems: a cross-industry study of MapReduce workloads",
            "venue": "Proceedings of the VLDB Endowment 5,",
            "year": 2012
        },
        {
            "authors": [
                "A. CHEUNG",
                "A. SOLAR-LEZAMA",
                "S. MADDEN"
            ],
            "title": "Optimizing Database-backed Applications with Query Synthesis",
            "venue": "In Proceedings of PLDI",
            "year": 2013
        },
        {
            "authors": [
                "J. DEAN",
                "S. GHEMAWAT"
            ],
            "title": "MapReduce: a flexible data processing tool",
            "venue": "Communications of the ACM 53,",
            "year": 2010
        },
        {
            "authors": [
                "C. DELIMITROU",
                "C. KOZYRAKIS"
            ],
            "title": "Quasar: Resourceefficient and QoS-aware Cluster Management",
            "venue": "In Proceedings of ASPLOS",
            "year": 2014
        },
        {
            "authors": [
                "A.D. FERGUSON",
                "P. BODIK",
                "S. KANDULA",
                "E. BOUTIN",
                "R. FONSECA"
            ],
            "title": "Jockey: guaranteed job latency in data parallel clusters",
            "venue": "In Proceedings of EuroSys",
            "year": 2012
        },
        {
            "authors": [
                "M.R. GAREY",
                "D.S. JOHNSON",
                "L. STOCKMEYER"
            ],
            "title": "Some simplified NP-complete graph problems",
            "venue": "Theoretical Computer Science",
            "year": 1976
        },
        {
            "authors": [
                "J. GONZALEZ",
                "Y. LOW",
                "H. GU",
                "D. BICKSON",
                "C. GUESTRIN"
            ],
            "title": "PowerGraph: Distributed graph-parallel computation on natural graphs",
            "venue": "In Proceedings of OSDI",
            "year": 2012
        },
        {
            "authors": [
                "J.E. GONZALEZ",
                "R.S. XIN",
                "A. DAVE",
                "D. CRANKSHAW",
                "M.J. FRANKLIN",
                "I. STOICA"
            ],
            "title": "GraphX: Graph Processing in a Distributed Dataflow Framework",
            "venue": "In Proceedings of OSDI",
            "year": 2014
        },
        {
            "authors": [
                "H. HERODOTOU",
                "S. BABU"
            ],
            "title": "Profiling, what-if analysis, and cost-based optimization of MapReduce programs",
            "venue": "Proceedings of the VLDB Endowment 4,",
            "year": 2011
        },
        {
            "authors": [
                "H. HERODOTOU",
                "H. LIM",
                "G. LUO",
                "N. BORISOV",
                "L. DONG",
                "F.B. CETIN",
                "S. BABU"
            ],
            "title": "Starfish: A Self-tuning System for Big Data Analytics",
            "venue": "In Proceedings of CIDR",
            "year": 2011
        },
        {
            "authors": [
                "S. HONG",
                "H. CHAFI",
                "E. SEDLAR",
                "K. OLUKOTUN"
            ],
            "title": "Green-Marl: a DSL for easy and efficient graph analysis",
            "venue": "In Proceedings of ASPLOS",
            "year": 2012
        },
        {
            "authors": [
                "M. ISARD",
                "M. BUDIU",
                "Y. YU",
                "A. BIRRELL"
            ],
            "title": "AND FET- TERLY, D. Dryad: Distributed data-parallel programs from sequential building blocks",
            "venue": "In Proceedings of EuroSys",
            "year": 2007
        },
        {
            "authors": [
                "IU",
                "M.-Y",
                "W. ZWAENEPOEL"
            ],
            "title": "HadoopToSQL: A MapReduce Query Optimizer",
            "venue": "In Proceedings of EuroSys",
            "year": 2010
        },
        {
            "authors": [
                "KE Q",
                "ISARD M",
                "YU"
            ],
            "title": "Optimus: a dynamic rewriting framework for data-parallel execution plans",
            "venue": "In Proceedings of EuroSys",
            "year": 2013
        },
        {
            "authors": [
                "KERNIGHAN B. W",
                "LIN"
            ],
            "title": "An efficient heuristic procedure for partitioning graphs",
            "venue": "Bell System Technical Journal 49,",
            "year": 1970
        },
        {
            "authors": [
                "Z. KHAYYAT",
                "K. AWARA",
                "A. ALONAZI",
                "H. JAMJOOM",
                "D. WILLIAMS",
                "P. KALNIS"
            ],
            "title": "Mizan: a system for dynamic load balancing in large-scale graph processing",
            "venue": "In Proceedings of EuroSys",
            "year": 2013
        },
        {
            "authors": [
                "A. KYROLA",
                "G. BLELLOCH",
                "C. GUESTRIN"
            ],
            "title": "GraphChi: Large-scale Graph Computation on Just a PC",
            "venue": "In Proceedings of OSDI",
            "year": 2012
        },
        {
            "authors": [
                "C. LATTNER",
                "V. ADVE"
            ],
            "title": "LLVM: A Compilation Framework for Lifelong Program Analysis & Transformation",
            "venue": "In Proceedings of CGO (Mar",
            "year": 2004
        },
        {
            "authors": [
                "G. MALEWICZ",
                "M. AUSTERN",
                "A. BIK",
                "J. DEHNERT",
                "I. HORN",
                "N. LEISER",
                "G. CZAJKOWSKI"
            ],
            "title": "Pregel: a system for large-scale graph processing",
            "venue": "In Proceedings of SIGMOD",
            "year": 2010
        },
        {
            "authors": [
                "Y. MAO",
                "R. MORRIS",
                "F. KAASHOEK"
            ],
            "title": "Optimizing MapReduce for multicore architectures",
            "venue": "Tech. Rep. MIT- CSAIL-TR-2010-020, MIT Computer Science and Artificial Intelligence Laboratory,",
            "year": 2010
        },
        {
            "authors": [
                "F. MCSHERRY"
            ],
            "title": "GraphLINQ: A graph library for Naiad",
            "venue": "Big Data at SVC blog,",
            "year": 2014
        },
        {
            "authors": [
                "K. MORTON",
                "M. BALAZINSKA",
                "D. GROSSMAN"
            ],
            "title": "ParaTimer: a progress indicator for MapReduce DAGs",
            "venue": "In Proceedings of SIGMOD",
            "year": 2010
        },
        {
            "authors": [
                "S.C. M\u00dcLLER",
                "G. ALONSO",
                "A. AMARA"
            ],
            "title": "AND CSIL- LAGHY, A. Pydron: Semi-Automatic Parallelization for Multi-Core and the Cloud",
            "venue": "In Proceedings of OSDI",
            "year": 2014
        },
        {
            "authors": [
                "D. MURRAY"
            ],
            "title": "Building new frameworks on Naiad",
            "year": 2014
        },
        {
            "authors": [
                "D. MURRAY",
                "M. SCHWARZKOPF",
                "C. SMOWTON",
                "S. SMITH",
                "A. MADHAVAPEDDY",
                "S. HAND"
            ],
            "title": "CIEL: a universal execution engine for distributed data-flow computing",
            "venue": "In Proceedings of NSDI",
            "year": 2011
        },
        {
            "authors": [
                "D.G. MURRAY"
            ],
            "title": "A distributed execution engine supporting data-dependent control flow",
            "venue": "PhD thesis, University of Cambridge,",
            "year": 2011
        },
        {
            "authors": [
                "D.G. MURRAY",
                "F. MCSHERRY",
                "R. ISAACS",
                "M. ISARD",
                "P. BARHAM",
                "M. ABADI"
            ],
            "title": "Naiad: a timely dataflow system",
            "venue": "In Proceedings of SOSP",
            "year": 2013
        },
        {
            "authors": [
                "C. OLSTON",
                "B. REED",
                "U. SRIVASTAVA",
                "R. KUMAR",
                "A. TOMKINS"
            ],
            "title": "Pig Latin: A Not-So-Foreign Language for Data Processing",
            "venue": "In Proceedings of SIGMOD",
            "year": 2008
        },
        {
            "authors": [
                "B. POTTENGER",
                "R. EIGENMANN"
            ],
            "title": "Idiom Recognition in the Polaris Parallelizing Compiler",
            "venue": "In Proceedings of SC",
            "year": 1995
        },
        {
            "authors": [
                "C. RANGER",
                "R. RAGHURAMAN",
                "A. PENMETSA",
                "G. BRAD- SKI",
                "C. KOZYRAKIS"
            ],
            "title": "Evaluating MapReduce for multi-core and multiprocessor systems",
            "venue": "In Procedings of HPCA",
            "year": 2007
        },
        {
            "authors": [
                "A. ROY",
                "I. MIHAILOVIC",
                "ZWAENEPOEL",
                "W. X"
            ],
            "title": "Stream: edge-centric graph processing using streaming partitions",
            "venue": "In Proceedings of SOSP",
            "year": 2013
        },
        {
            "authors": [
                "A. SIMITSIS",
                "K. WILKINSON",
                "M. CASTELLANOS",
                "U. DAYAL"
            ],
            "title": "Optimizing analytic data flows for multiple execution engines",
            "venue": "In Proceedings of SIGMOD",
            "year": 2012
        },
        {
            "authors": [
                "A. THUSOO",
                "J. SARMA",
                "N. JAIN",
                "Z. SHAO",
                "P. CHAKKA",
                "S. ANTHONY",
                "H. LIU",
                "P. WYCKOFF",
                "R. MURTHY"
            ],
            "title": "Hive \u2013 A Warehousing Solution over a Map-Reduce Framework",
            "venue": "Proceedings of the VLDB Endowment",
            "year": 2009
        },
        {
            "authors": [
                "R.S. XIN",
                "J. ROSEN",
                "M. ZAHARIA",
                "M.J. FRANKLIN",
                "S. SHENKER",
                "I. STOICA"
            ],
            "title": "Shark: SQL and Rich Analytics at Scale",
            "venue": "In Proceedings of SIGMOD",
            "year": 2013
        },
        {
            "authors": [
                "Y. YU",
                "M. ISARD",
                "D. FETTERLY",
                "M. BUDIU"
            ],
            "title": "ERLINGS- SON, \u00da., GUNDA, P., AND CURREY, J. DryadLINQ: A System for General-Purpose Distributed Data-Parallel Computing Using a High-Level Language",
            "venue": "In Proceedings of OSDI",
            "year": 2008
        },
        {
            "authors": [
                "M. ZAHARIA",
                "M. CHOWDHURY",
                "T. DAS",
                "A. DAVE",
                "J. MA",
                "M. MCCAULEY",
                "M. FRANKLIN",
                "S. SHENKER",
                "I. STOICA"
            ],
            "title": "Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing",
            "venue": "In Proceedings of NSDI",
            "year": 2012
        }
    ],
    "sections": [
        {
            "text": "We argue that the ways that workflows are defined should be decoupled from the manner in which they are executed. To explore this idea, we have built Musketeer, a workflow manager which can dynamically map front-end workflow descriptions to a broad range of back-end execution engines.\nOur prototype maps workflows expressed in four highlevel query languages to seven different popular data processing systems. Musketeer speeds up realistic workflows by up to 9\u00d7 by targeting different execution engines, without requiring any manual effort. Its automatically generated back-end code comes within 5%\u201330% of the performance of hand-optimized implementations."
        },
        {
            "heading": "1. Introduction",
            "text": "Choosing the \u201cright\u201d parallel data processing system is difficult. It requires significant expert knowledge about the programming paradigm, design goals and implementation of the many available systems. Even with this knowledge, any move between systems requires time-consuming reimplementation of workflows. Furthermore, head-to-head\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. EuroSys\u201915, April 21\u201324, 2015, Bordeaux, France. Copyright \u00a9 2015 ACM 978-1-4503-3238-5/15/04. . . $15.00. http://dx.doi.org/10.1145/10.1145/2741948.2741968\ncomparisons are difficult because systems often make different assumptions and target different use cases. Users therefore stick to their known, favorite system even if other, \u201cbetter\u201d systems offer superior performance or efficiency gains.\nWe evaluated a range of contemporary data processing systems \u2013 Hadoop, Spark, Naiad, PowerGraph, Metis and GraphChi \u2013 under controlled and comparable conditions. We found that (i) their performance varies widely depending on the high-level workflow; (ii) no single system always outperforms all others; and (iii) almost every system performs best under some circumstances (\u00a72).\nIt thus makes little sense to force the user to target a single system at workflow implementation time. Instead, we argue that users should, in principle, be able to execute their highlevel workflow on any data processing system (\u00a73). Being able to do this has three main benefits:\n1. Users write their workflow once, in a way they choose, but can easily execute it on alternative systems; 2. Multiple sub-components of a workflow can be executed on different back-end systems; and 3. Existing workflows can easily be ported to new systems.\nIn this paper, we present our Musketeer proof-of-concept workflow manager to show that this is feasible, and that the resulting implementations are competitive with hand-written baseline implementations for specific systems.\nNote: In the electronic version of this paper, most figures link to descriptions of the experiments and our data sets (http://goo.gl/BMdT0o).\nTo decouple workflows from their execution, we rely on the fact that users prefer to express their workflows using high-level frameworks, which abstract the low-level details of distributed execution engines (Figure 1). For example, the Hive [40] and Pig [35] frameworks present users with a SQL-like querying interface over the Hadoop MapReduce execution engine; SparkSQL and GraphX [15] offer SQL primitives and vertex-centric interfaces over Spark [43]; and Lindi and GraphLINQ [31] offer the same over Naiad [34].\nMusketeer breaks the tight coupling between frameworks and execution engines (\u00a73). It achieves this by (i) mapping workflow specifications for front-end frameworks to a common intermediate representation; (ii) determining a good decomposition of the workflow into jobs; and (iii) autogenerating efficient code for the chosen back-end systems.\nMusketeer currently supports four front-end frameworks (Hive, Lindi, a custom SQL-like DSL with iteration, and a graph-oriented \u201cGather-Apply-Scatter\u201d DSL). It can map workflows to seven back-end execution systems: Hadoop, Spark, Naiad, PowerGraph, GraphChi, Metis and simple, serial C code. Users can explicitly target back-end execution engines, or leave it to Musketeer to automatically choose a good mapping using a simple heuristic (\u00a75).\nIn a range of experiments with real-world workflows, Musketeer offers compelling advantages (\u00a76):\n1. Better system mapping: Musketeer enables existing workflows implemented for Hive on Hadoop MapReduce to be executed on alternative systems, and achieves a 2\u00d7 speedup on a TPC-H query workflow as a result.\n2. Optimization of executed code: by choosing the most suitable Naiad execution primitive independent of the front-end used to implement the workflow, Musketeer speeds up a TPC-H query workflow by up to 9\u00d7.\n3. Intelligent system combination: Musketeer can combine different execution engines within a workflow, and doing so outperforms fixed, single system mappings for a cross-community PageRank workflow.\n4. Competitive generated code: Musketeer\u2019s generated code has no more than a 5\u201330% overhead over handoptimized baseline implementations.\n5. Good automatic system choice: an automated heuristic for choosing back-ends in Musketeer derives reasonably good mappings without manual user action.\nThese results and our experience of using Musketeer in practice (\u00a77) indicate that decoupling front-end and back-end systems can bring real benefits. Nonetheless, we believe our work represents only the first step in a promising direction. In Section 8, we describe current limitations of our system, and suggest some concrete future work before discussing related research (\u00a79) and concluding (\u00a710)."
        },
        {
            "heading": "2. Motivation",
            "text": "There are many diverse \u201cbig data\u201d processing systems and more keep appearing.2 This makes it difficult to determine which system is best for a given workflow, data set and cluster setup. We illustrate this using a set of simple benchmarks. In all cases, we run over a shared HDFS installation that stores input and output data, and we either implement jobs directly against a particular execution engine, or use a front-end framework with its corresponding native back-end. We measure the makespan \u2013 i.e., the entire time to execute a workflow, including the computation itself and any data loading, pre-processing and output materialization required.\nWe find that no single system systematically outperforms all others. Roughly speaking, system performance depends on: (i) the size of the input data, as single machine frameworks outperform distributed frameworks for small inputs; (ii) the structure of the data, since skew and selectivity impact I/O performance and work distribution; (iii) engineering decisions, with e.g., the cost of loading inputs varying significantly across systems; and (iv) the computation type, since specialized systems often operate more efficiently."
        },
        {
            "heading": "2.1 Query processing micro-benchmarks",
            "text": "Query-based data analytics workflows often consist of relational operators. In the following, we consider the behavior of two operators in an isolated micro-benchmark. Here we use a local cluster of seven nodes as an example of a smallscale data analytics deployment. Later experiments show that our results generalize to more complex workflows and to larger clusters.\nInput size. We first look at a simple string processing workload in which we extract one column from a spaceseparated, two column ASCII input. This corresponds to a PROJECT query in SQL terms, but is also reminiscent of a common pattern in log analysis batch jobs: lines are read from storage, split into tokens, and a few are written back. We consider input sizes ranging from 128MB up to\n2 For a brief summary of systems\u2019 properties, see Table 3.\n32GB. Figure 2a compares the makespan of this workflow on five different systems. Two of these are programmerfriendly SQL-like front-ends (Hive, Lindi), while the others require the user to program against a lower-level API (Hadoop, Metis and Spark). For small inputs (\u2264 0.5GB), the Metis single-machine MapReduce system performs best.3 This matters, as small inputs are common in practice: 40\u2013 80% of Cloudera customers\u2019 MapReduce jobs and 70% of jobs in a Facebook trace have \u2264 1GB of input [8]. I/O efficiency. Once the data size grows, Hive, Spark and Hadoop all surpass the single-machine Metis, not least since they can stream data from and to HDFS in parallel. However, since there is no data re-use in this workflow, Spark performs worse than Hadoop: it loads all data into a distributed inmemory RDD [43] before performing the projection. The Lindi front-end implementation for Naiad performs surprisingly poorly; we tracked this down to an implementation decision in the Naiad back-end, which uses only a single input reader thread per machine, rather than having multi-threaded parallel reads. Since the PROJECT benchmark is primarily limited by I/O bandwidth, this decision proves detrimental.\nData structure. Second, we consider a JOIN workflow. This is highly dependent on the structure of the input data: it may generate less, more, or an equal amount of output compared to its input. We therefore measure two different cases: (i) an input-skewed, asymmetric join of the 4.8M vertices of a social network graph (LiveJournal) and its 69M edges, and (ii) a symmetric join of two uniformly randomly generated 39M row data sets. Figure 2b shows the makespan of different systems (plus a simple implementation in serial C code) for this workflow. The unchallenging asymmetric join (producing 1.28M rows/1.9GB) works best when executed in single-threaded C code on a single machine, as the computation is too small to amortize the overheads of distributed solutions. The far larger symmetric join (1.5B rows/29GB), however, works best on Hadoop. Other systems suffer from inefficient I/O (e.g., Lindi using a single-threaded writer),\n3 The bottleneck here is not the computation, but reading the data from HDFS. With the data already local, Metis performs best up to 2 GB.\nor have overhead due to constructing in-memory state and scheduling tasks sub-optimally (Spark)."
        },
        {
            "heading": "2.2 Iterative graph processing",
            "text": "Many common workflows involve iterative computations on graphs (e.g., social networks). In the following, we compare different systems running PageRank on such graphs. We also vary the size of the EC2 cluster (m1.xlarge instances) in order to determine systems\u2019 efficiency at different scales.\nPerformance. Several specialized graph processing systems based on a vertex-centric or gather-and-scatter (GAS) approach have been built. These computation paradigms are limited, but can deliver significantly better performance for graph workloads. In Figure 3, we show the makespan of a five-iteration PageRank workflow on the small Orkut and the large Twitter graph. It is evident that graph-oriented paradigms have significant advantages for this computation: a GraphLINQ implementation running on Naiad outperforms all other systems.4 PowerGraph also performs very well, since its vertex-centric sharding reduces the communication overhead that dominates PageRank.\nResource efficiency. However, the fastest system is not always the most efficient. While PageRank in GraphLINQ using 100 Naiad nodes has the lowest runtime in Figure 3b, PowerGraph performs better than GraphLINQ when using only 16 nodes (due to its improved sharding).5 Moreover, when the graph is small (e.g., in Figure 3a), GraphChi performs only 50% worse than Spark on 100 nodes, and only slightly worse than PowerGraph on 16 nodes, despite using only one machine."
        },
        {
            "heading": "2.3 Summary",
            "text": "Our experiments show that the \u201cbest\u201d system for a given workflow varies considerably. The right choice \u2013 i.e., the fastest or most efficient system \u2013 depends on the workflow, the input data size and the scale of parallelism available.\n4 Only the GraphLINQ front-end for Naiad is shown here; Lindi is not optimized for graph computations and performs poorly. 5 Running PowerGraph on 32 or 64 nodes showed no benefit over 16 nodes.\nThis information may not be available at workflow implementation time, which motivates our approach of decoupling workflow expression from the execution engine used."
        },
        {
            "heading": "3. All for one, one for all data processing",
            "text": "We believe that a decoupled data processing architecture (Figure 4) gives users additional flexibility. In this approach, we break the execution of a data processing workflow into three layers. First, a user specifies her workflow using a front-end framework. Next, this workflow specification is translated into an intermediate representation. Third, jobs are generated from this representation and executed on one or more back-end execution engines.\nWe give an overview of the three layers below; \u00a74 will describe their realization in our Musketeer prototype.\nFront-ends. User-facing high-level abstractions for workflow expression (\u201cframeworks\u201d) act as front-ends to the system. Many such frameworks exist: SQL-like querying languages and vertex-centric graph abstractions are especially popular. We assume that users write their workflows for such frameworks. The front-end workflow specifications must then be translated to a common form; we do this by either parsing the user input directly, or by building an APIcompatible shim for the front-end.\nIntermediate representation. Ideally, all available frontend frameworks and back-end execution engines would agree on a single common intermediate representation (IR). The IR must simultaneously (i) be sufficiently expressive to support a broad range of workflows, and (ii) maintain enough information to optimize back-end job code to a level competitive with a competent hand-coded implementation.\nOur intermediate representation is a dynamic directed acyclic graph (DAG) of data-flow operators, with edges corresponding to input-output dependencies. This abstraction is general: it supports specific operator types (cf. Dryad\u2019s vertices [19]) and general user-defined functions (UDFs); it can handle iteration by successive expansion of the DAG (as in\nCIEL [32] and Pydron [30]); and it can be extended with new operators in order to enable end-to-end optimizations.\nWe can also perform query optimizations on the dataflow DAG (e.g., to reduce intermediate data volume where possible), as is already commonly done between front-end and back-end in other systems [21, 41].\nBack-ends. Finally, the system must generate code for specific distributed data processing systems (\u201cexecution engines\u201d) at the back-end. A na\u0131\u0308ve approach would simply generate a job for each operator, but this fails to exploit opportunities for optimization within the execution engines (e.g., sharing data scans). Instead, we typically want to run as few independent jobs as possible.\nHowever, some execution engines have limited expressivity and therefore require the data-flow DAG to be partitioned into multiple jobs. Many valid partitioning options exist, depending on the workflow and the execution engines available. In \u00a75, we show that exploring this space is an instance of an NP-hard problem (k-way graph partitioning), and introduce a heuristic to solve it efficiently for large DAGs.\nGiven a suitable partitioning, we generate jobs for the chosen execution engines and dispatch them for execution.\nExtensibility. Our approach is extensible: new front-end frameworks can be added by providing translation logic from framework constructs to the intermediate representation. Similarly, further back-end execution engines can be supported as they emerge by adding appropriate code templates and code generation logic.\nLimitations. Decoupling increases flexibility, but it may obfuscate some end-to-end optimization opportunities from expert users. Our scheme is best suited for non-specialist users writing analytics workflows for high-level front-end frameworks. This is common in industry: up to 80% of jobs running in production clusters come from front-end frameworks such as Pig [35], Hive [40], Shark [41] or DryadLINQ [42], according to a recent study [8]."
        },
        {
            "heading": "4. Musketeer implementation",
            "text": "Musketeer is our proof-of-concept implementation of the decoupled \u201call for one, one for all\u201d approach that we advocate. It translates a workflow defined in a front-end framework into an intermediate representation, applies optimizations and generates code for suitable back-end execution engines. In this section, we describe Musketeer in detail. Figure 5 illustrates the different stages a Musketeer workflow proceeds through from specification to execution."
        },
        {
            "heading": "4.1 Workflow expression",
            "text": "Distributed execution engines simplify data processing by shielding users from the intricacies of writing parallel, faulttolerant code. However, they still require users to express their computation in terms of low-level primitives, such as map and reduce functions [10] or message-passing ver-\n1 SELECT id, street, town FROM properties AS locs; 2 locs JOIN prices ON locs.id = prices.id 3 AS id_price; 4 SELECT street, town, MAX(price) FROM id_price 5 GROUP BY street AND town AS street_price;\nListing 1: Hive code for max-property-price workflow.\ntices [34]. Hence, higher-level \u201cframeworks\u201d that expose more convenient abstractions are commonly built on top.\nMusketeer supports two types of front-end frameworks: (i) SQL-like query languages, and (ii) vertex-centric graph processing abstractions."
        },
        {
            "heading": "4.1.1 SQL-like data analytics queries",
            "text": "Query languages based on SQL are used to express relational queries on data of tabular structure. Listing 1 shows an example analytics workflow that computes the most expensive property on each street for a real-estate data set.\nMusketeer currently supports three SQL-like data analytics front-ends: Hive, Lindi and BEER, our own domainspecific workflow language with support for iteration. Translation from these front-ends to the intermediate representation proceeds by mapping the relational operations to operators in the IR DAG; most relational primitives have directly corresponding Musketeer IR operators."
        },
        {
            "heading": "4.1.2 Graph computations",
            "text": "Domain-specific front-end frameworks for expressing graph computations are popular: Pregel [26] and Giraph abstract over MapReduce, the GreenMarl DSL [18] can emit code for multi-threaded and distributed runtimes, and GraphLINQ offers graph-specific APIs over Naiad vertices and timestamps [28]. These front-ends include user-defined code that is concurrently instantiated for every vertex, and adjacent vertices communicate using messages in repeated rounds. This vertex-centric programming pattern is generalized by the Gather, Apply and Scatter (GAS) model in PowerGraph [14]. In this paradigm, data are first gathered from neighboring nodes, then vertex state is updated and, finally, the new state is disseminated (scattered) to the neighbors.\nMusketeer currently supports graph computations via a domain-specific front-end framework built around combining the GAS model with our BEER DSL. Users run graph computations by defining the three GAS steps, with each step represented by relational operators or UDFs. In Listing 2, we show the implementation of PageRank in Musketeer\u2019s GAS front-end framework.\nWhile HiveQL and our BEER DSL have directly corresponding operators in the IR, the GAS DSL requires both syntactic translation and transformation from the vertexcentric paradigm to the data-flow DAG. Musketeer uses idiom recognition to achieve this, which we describe in \u00a74.3.1.\n1 GATHER = { 2 SUM (vertex_value) 3 } 4 APPLY = { 5 MUL [vertex_value, 0.85] 6 SUM [vertex_value, 0.15] 7 } 8 SCATTER = { 9 DIV [vertex_value, vertex_degree]\n10 } 11 ITERATION_STOP = (iteration < 20) 12 ITERATION = { 13 SUM [iteration, 1]) 14 }\nListing 2: Gather-Apply-Scatter DSL code for PageRank."
        },
        {
            "heading": "4.1.3 Other workloads",
            "text": "In addition to SQL-like query languages and GAS-style graph computations, Musketeer can also support other types of front-ends. If their abstractions map to Musketeer IR operators, they can be translated directly. Abstractions for which no IR operator exists can be mapped to a user-defined function (UDF), or to a \u201cnative\u201d back-end via a \u201cblack box\u201d operator. We discuss extension to other front-ends in \u00a78."
        },
        {
            "heading": "4.2 Intermediate representation",
            "text": "Musketeer uses a directed acyclic graph (DAG) of dataflow operators as its intermediate representation. We chose this abstraction because it is expressive [19, 32, 43] and amenable to analysis and optimization [21, 23].\nMusketeer\u2019s set of operators is extensible: not all frontends use all operators, and not all back-ends must support all operators. Our initial set of operators is loosely based on relational algebra and covers the most common operations in industry workflows [8]. It includes SELECT, PROJECT, UNION, INTERSECT, JOIN and DIFFERENCE, plus aggregators (AGG, GROUP BY), column-level algebraic operations (SUM, SUB, DIV, MUL), and extremes (MAX, MIN). This set of operators is, in our experience, already sufficient to model many widely-used processing paradigms. For example, MapReduce workflows can be directly modeled as a MAP, GROUP BY and AGG step, and many complex graph workflows can be mapped to a specific JOIN, MAP, GROUP BY pattern, as shown by GraphX [15] and Pregelix [3].\nHowever, workflows may also involve iterative computations. To allow data-dependent iteration, Musketeer must be able to dynamically extend the IR DAG based on operators\u2019 output. We use a WHILE operator to do this: it successively extends the DAG every time another iteration is required. As shown by Murray [33, \u00a73.3.3], a DAG with this facility is sufficient to achieve Turing completeness as it can express all while-programs (though not necessarily efficiently).\nOptimizing the IR. Many front-end frameworks already optimize workflows before execution. For example, Pig [35],\nHive [40], Shark [41] and SparkSQL optimize relational queries via rewriting rules and FlumeJava [6], Optimus [21] and RoPE [1] apply optimizations to DAGs. Yet, each such optimization must be implemented independently for each front-end framework.\nOne of the advantages of decoupling front-ends from back-ends is the ability to apply optimizations at the intermediate level, as observed e.g., in the LLVM modular compiler framework [25]. Musketeer can likewise provide benefits to all supported systems (and future ones) by applying optimizations to the intermediate representation.\nWe currently perform a small set of standard query rewriting optimizations on the IR. Most of these re-order operators \u2013 e.g., bringing selective ones closer to the start of the workflow and pushing generative operators to the end."
        },
        {
            "heading": "4.3 Code generation",
            "text": "After Musketeer has translated the workflow to the intermediate representation, it must generate code for execution from the IR. For the time being, we assume that the user explicitly specifies which back-end execution engines to use; in \u00a75, we show how Musketeer can decide automatically.\nMusketeer has code templates for specific combinations of operators and back-ends. Conceptually, it instantiates and concatenates these templates to produce executable jobs. In practice, however, optimizations are required to make the performance of the generated code competitive with handwritten baselines. Musketeer uses traditional database optimizations (e.g., sharing data scans and operator merging), combined with compiler techniques (e.g., idiom recognition and type inference) to improve upon the na\u0131\u0308ve approach. In the following, we explain these optimizations with respect to the max-property-price Hive workflow example (Listing 1) and the GAS PageRank example (Listing 2)."
        },
        {
            "heading": "4.3.1 Idiom recognition",
            "text": "Some back-end execution engines are specialized for a specific type of computation. For example, GraphChi has a vertex-centric computation model and PowerGraph uses the GAS decomposition. Neither system can express computations that do not fit its model. Musketeer must therefore rec-\nognize specific computational idioms in the IR to decide if a back-end is suitable for a workflow. Idiom recognition is a technique used in parallelizing compilers to detect computational idioms that allow transformations to be applied [36]. We use a similar approach to detect high-level paradigms in Musketeer\u2019s IR DAG.\nOur prototype detects vertex-oriented graph-processing algorithms in the IR, even if they were originally expressed in a relational front-end (e.g., in Hive instead of the GAS DSL). The idiom is a reverse variant of the way GraphX abstracts graph computation as data-flow operators [15, \u00a73]. Musketeer looks for a combination of the WHILE and JOIN operators with a GROUP BY operator in a particular structure: the body of the WHILE loop must contain a JOIN operator with two inputs that represent vertices and edges. This JOIN operator must be followed by a GROUP BY operator that groups data by the vertex column.\nThis structure maps to the graph computation paradigms as follows: the JOIN on the vertex column represents sending messages to neighbors (vertex-centric model), or the \u201cscatter\u201d phase (GAS decomposition); the GROUP BY is equivalent to receiving messages, or the \u201cgather\u201d step (GAS); and any other operators in the WHILE body are part of the superstep (vertex-centric) or the \u201capply\u201d step (GAS), updating the state of each vertex.\nOther idioms can also be detected: for example, depending on whether the AGG operator performs an associative or a non-associative (e.g., subtraction, division) aggregation, different operator implementations are appropriate in different back-ends. We plan to support this in future work."
        },
        {
            "heading": "4.3.2 Merging operators",
            "text": "General-purpose systems such as Spark and Naiad can express complex workflows as a single job. However, more restricted systems only support particular idioms (e.g., PowerGraph, GraphChi) or require multiple jobs to express certain operations (e.g., MapReduce). Each back-end job generated for an execution engine comes with some per-job overhead. Musketeer therefore merges operators in order to reduce the number of jobs executed.\n1 locs = 2 properties.map(c => (c.uid, c.street, c.town)) 3 id_price = locs 4 .map(l => (l.uid, (l.street, l.town))) 5 .join(prices) 6 .map((key, (l_rel, r_rel)) => (key, l_rel, r_rel)) 7 street_price = id_price 8 .map(ip => ((ip.street, ip.town), ip.price) 9 .reduceByKey((left, right) => Max(left, right))\nListing 3: Na\u0131\u0308ve Spark code for max-property-price. Four maps are required as data structures must be transformed.\n1 locs = 2 properties.map(c => (c.uid, (c.street, c.town))) 3 id_price = locs 4 .join(prices) 5 .map((key, (l_rel, r_rel)) => 6 ((l_rel.street, l_rel.town), r_rel.price)) 7 street_price = id_price 8 .reduceByKey((left, right) => Max(left, right))\nListing 4: Optimized Spark code for max-property-price. Scan sharing and type inference reduce the maps to two.\nConsider an example: MapReduce-based execution engines only support one group-by-key operation per job [35]. Hence, even a simple workflow like max-property-price requires at least two jobs: (i) Lines 1\u20133 in Listing 1 (\u00a74.1.1) result in a job that selects columns from the properties relation and joins the result with the prices relation using id as the key; and (ii) lines 4\u20135 group by a different key than the prior join, requiring a second job. By contrast, Listing 3 shows simple generated code for the max-propertyprice workflow in Spark, where only one job is required.\nTo model these limitations and avoid extra jobs when possible, Musketeer has a set of per-back-end mergeability rules. These indicate whether operators can be merged into one job either (i) bidirectionally, (ii) unidirectionally, or (iii) not at all. If execution engines only support certain idioms, only operator merges corresponding to these idioms are feasible. The operator merge rules are used by the DAG partitioning algorithm (\u00a75) to decide upon job boundaries. Operator merging is necessary for good performance: in \u00a76.5, we show that it reduces workflow makespan by 2\u20135\u00d7."
        },
        {
            "heading": "4.3.3 Sharing data scans",
            "text": "Operator merging allows Musketeer to execute several operators as a single job, and thus eliminates job creation overheads where possible. However, this is not enough to obtain competitive results compared to hand-coded baselines. For example, the first SELECT and the JOIN operator from the max-property-price in Spark get translated into two map transformations and a join (Listing 3, lines 3\u20136). The first map selects only the columns required by the workflow,\nwhile the second map establishes a key\u2192 \u3008tuple\u3009 mapping over which the join is going to be conducted.\nEven though Spark holds the intermediate RDDs in memory, scanning over the data twice yields a significant performance penalty. Musketeer avoids redundant scans by combining them where supported by the back-end. For example, in the optimized generated Spark code (Listing 4) for the max-property-price workflow, the anonymous lambdas from the first two map transformations (Listing 3, lines 4 and 6) are combined into a single one (Listing 4, lines 5\u20136). As a result, the generated code only scans the data once, selecting the required columns and preparing the relation for the join transformation in one go."
        },
        {
            "heading": "4.3.4 Look-ahead and type inference",
            "text": "Many execution engines (e.g., Spark and Naiad) expose a rich API for manipulating different data types. For example, the SELECT . . . GROUP BY clause in the maxproperty-price workflow (Listing 1, lines 4\u20135) can be implemented directly in Spark using a reduceByKey transformation. However, such API calls often require a specific representation of the input data. In the example, Spark\u2019s reduceByKey requires the data to be represented as a set of \u3008key, value\u3009 tuples. Unfortunately, the preceding join transformation outputs the data in a different format (viz. \u3008key, \u3008left relation, right relation\u3009\u3009). Hence, the na\u0131\u0308ve generated code for Spark ends up generating two map transformations, one to flatten the output of the join (Listing 3, line 6), and another to key the relation by a \u3008town,street\u3009 tuple (line 8).\nTo mitigate this, Musketeer looks ahead and uses type inference to determine the input format of the operators that ingest the current operator\u2019s output. With this optimization, the two map transformations can be expressed as a single transformation (Listing 4, lines 5\u20136). In combination with shared scans, look-ahead and type inference enable Musketeer to guarantee that no unnecessary data scans will take place in most cases."
        },
        {
            "heading": "5. DAG partitioning and automatic mapping",
            "text": "To generate back-end jobs, Musketeer partitions the IR DAG into sub-regions, each representing a job. As we explained in \u00a74.3.2, some execution engines constrain the operators that can be combined in a single job.\nOur method of partitioning the IR DAG must therefore generalize over different back-end constraints and extend to future systems\u2019 properties. Hence, we consider all possible partitionings; when this is too expensive, we apply an efficient heuristic based on dynamic programming (\u00a75.1).\nProvided that back-ends\u2019 relative performance can be predicted with reasonable accuracy, Musketeer can also automatically decide which back-ends to use. The goodness of different options is quantified using a simple cost function that considers information specific to both workflows and back-ends (\u00a75.2)."
        },
        {
            "heading": "5.1 DAG partitioning",
            "text": "There are many ways of breaking the IR DAG into partitions (\u2261 back-end jobs). Musketeer uses a simple cost function to compare different partitioning options. The cost of any partition containing non-mergeable operators is infinite; otherwise it is finite and depends on the back-ends (see \u00a75.2).\nWith a known optimal number of jobs, k, partitioning the DAG is an instance of the k-way graph partitioning problem [22]. Unfortunately, k-way graph partitioning is NP-hard [13]: the best solution is guaranteed to be found only by exploring all k-way partitions. Moreover, the optimal number of jobs into which to partition the DAG is unknown. Hence, Musketeer must solve k-way graph partitioning for all k \u2264 N, where N is the number of operators in the DAG.\nWhere possible, Musketeer uses an exhaustive search to find the cheapest partitioning (in practice, up to about 18 operators). It switches to a dynamic programming heuristic for larger, more complex workflows."
        },
        {
            "heading": "5.1.1 Exhaustive search",
            "text": "The exhaustive search explores all possible graph partitionings. It first considers the cost of running each operator in isolation. Next, it looks at all merge opportunities, and finally, it recursively generates all valid (finite-cost) partitions. The algorithm is guaranteed to find the optimal solution with respect to the cost function. However, it requires exponential time in the number of operators."
        },
        {
            "heading": "5.1.2 Dynamic heuristic",
            "text": "Some industry workflows consist of large DAGs containing up to hundreds of operators [6, \u00a76.2]. To support these workflows, we use a dynamic heuristic. Its execution time scales\nlinearly with the number of operators, and it obtains good solutions in practice. The dynamic heuristic explores only a subset of the possible partitions by focusing on a single linear ordering of operators. In Figure 6, we illustrate the algorithm using the IR DAG for PageRank (Listing 2).\nFirst, Musketeer topologically sorts the DAG to produce a linear ordering. This ordering maintains operator precedence \u2013 i.e., an operator does not appear in the linear ordering before any of its ancestors. Second, Musketeer finds the optimal partitioning of the linear ordering using dynamic programming. The dynamic programming algorithm uses the cost function, cs(o1,o2, . . . , o j), which estimates the cost of running the operators o1, o2, . . . , o j in a single job. It then computes the matrix C[n][m], which stores the minimum cost of running the first n operators in exactly m jobs:\nC[n][m] = min k<n\n( C[k][m\u22121]+min\ns (cs(ok+1 . . .on)) ) In other words, we determine the best combination that runs a k-element prefix of operators in m\u22121 jobs and the remainder in a single job. This approach finds a good solution because it considers all partitions of the linear ordering. The cost function guides it to merge as many operators as possible within each individual job.\nThe dynamic heuristic can miss out on opportunities to merge operators due to the linear ordering breaking operator adjacencies. We discuss this further and show an example in \u00a78; in practice, we found the dynamic heuristic to work well."
        },
        {
            "heading": "5.2 Automatic system mapping",
            "text": "A simple extension of the DAG partitioning algorithm allows Musketeer to automatically choose back-end execution engine mappings. To achieve this, we use Musketeer\u2019s cost function and run the DAG partitioning algorithm for all back-ends. We then pick the best k-way partitioning.\nThe cost function scores the performance of a particular combination of operators, input data and execution engine. The score is based on three high-level components:\n1. Data volume. Each operator has bounds on its output size based on its behavior (e.g., whether it is generative or selective). These bounds are applied to the run-time input data size to predict intermediate and output sizes. 2. Operator performance. In a one-off calibration, Musketeer measures each operator in each back-end and records the rate at which it processes data. 3. Workflow history. Musketeer collects information about each job it runs (e.g., runtime and input/output sizes), and uses this information to refine the scores for subsequent runs of the same workflow.\nThe operator performance calibration only requires modest one-off profiling for a deployed cluster. It supplies Musketeer with the four rates listed in Table 1. PULL and PUSH quantify read and write HDFS throughput at the start and end of a job. We measure them using a \u201cno-op\u201d operator. LOAD,\nby contrast, corresponds to back-end-specific data loading or transformation steps (e.g., partitioning the input in PowerGraph). Finally, PROCESS approximates the rate at which the operator\u2019s computation proceeds. In some systems, we measure this directly, while in others, we subtract the estimated duration of the ingest (from PULL) and output (from PUSH) stages from the overall runtime to obtain PROCESS.\nThis information lets us estimate the benefit of shared scans: we pay the cost of PULL, LOAD and PUSH just once (rather than once per-operator) and combine those with the costs of PROCESS for all the operators.\nThese rate parameters enable generic cost estimates, but we can achieve more accurate scoring by using workflowspecific historical information. When a workflow first executes, no such information is available. Musketeer thus applies conservative data size bounds and only merges selective operators and generative operators with small output bounds. As a result, more jobs may be generated on the first execution \u2013 e.g., due to JOIN operators, which have unknown data size bounds. On subsequent executions, Musketeer tightens the bounds using historical information, which may unlock additional merge opportunities."
        },
        {
            "heading": "6. Evaluation",
            "text": "Musketeer\u2019s goal is to improve flexibility and performance of data processing workflows by dynamically mapping from front-end frameworks to back-end execution engines. In this section, we show that Musketeer meets these goals:\n1. Legacy workflow speedup: Musketeer reduces legacy workflows\u2019 makespan by up to 2\u00d7 by mapping them to a different back-end execution system (\u00a76.2). 2. Flexible combinations of back-ends: by exploring combinations of multiple execution systems for a workflow, Musketeer finds combinations that perform well (\u00a76.3). 3. Increased portability: compared to time-consuming, hand-tuned implementations for specific back-ends, Musketeer\u2019s automatically generated code has low overhead, yet offers superior portability (\u00a76.4, \u00a76.5). 4. Promising automatic system mapping: our automated mapping prototype makes good choices based on simple parameters characterizing execution engines (\u00a76.6, \u00a76.7).\nWe implemented seven real-world workflows to evaluate Musketeer: three batch workflows, three iterative workflows and a hybrid one. The batch workflows are (i) TPC-H query 17, (ii) top-shopper, which identifies an online shop\u2019s top spenders, and (iii) the Netflix movie recommendation algo-\nrithm. The iterative ones are (i) PageRank, (ii) single-source shortest path (SSSP), and (iii) k-means clustering; the hybrid workflow is PageRank with a batch pre-processing stage."
        },
        {
            "heading": "6.1 Setup",
            "text": "Most of our experiments run on a 100-node cluster of m1.xlarge instances on Amazon EC2. However, we also run some experiments on a local, dedicated seven-machine cluster with low variance in performance. We deployed all systems supported by Musketeer6 on these clusters. We use a shared HDFS as the storage layer; this makes sense as HDFS is already supported by Hadoop, Spark and PowerGraph. In order to establish a level playing field for our experiments, we tuned and modified some systems (see Table 2).\nMetrics. As in \u00a72, the makespan of a workflow refers to its total execution time, measured from its launch to the final result appearing in HDFS. This includes time to load inputs from HDFS, pre-process or transform them (e.g. in PowerGraph and GraphChi) and write the outputs back. As a result, the numbers we present are not directly comparable to those in some other papers, which measure the actual computation time only.\nResource efficiency, on the other hand, is a measure of the efficiency loss incurred due to scaling out over multiple machines. We compute it by normalizing a workflow\u2019s fastest single-node execution (assumed to be maximally resource-efficient) to its aggregate execution time over all nodes in a distributed system. For example, a workflow that runs for 30s on all 100 nodes of the EC2 cluster has an aggregate execution time of 3,000s. If the best single-node system completes the same workflow in 2,000s, the resource efficiency of the distributed execution is 66%."
        },
        {
            "heading": "6.2 Dynamic mapping to back-end execution engines",
            "text": "We consider both batch and iterative graph processing workflows to investigate the benefits of Musketeer\u2019s ability to dynamically map workflows to back-ends. This mirrors our motivational experiments in \u00a72.\nBatch workflows. To illustrate the flexibility offered by Musketeer, we run query 17 from the TPC-H business decision benchmark using the HiveQL and Lindi front-ends. Figure 7 shows the resulting makespan as the data size increases from 7.5 GB (scale factor 10) to 75 GB (factor 100).\n6 Hadoop 2.0.0-mr1-chd4.5.0, Spark 0.9, PowerGraph 2.2, GraphChi 0.2, Naiad 0.2 and Metis commit e5b04e2.\nWhen running the Hive workflow directly using its native Hadoop back-end, the makespan ranges from 200\u2013400s.\nMusketeer, however, can map the Hive workflow specification to different back-ends. In this case, mapping it to Naiad reduces the makespan by 2\u00d7. This is not surprising: Hive must run the workflow as three Hadoop jobs due to the restrictive MapReduce paradigm, while Naiad can run the entire workflow in one job.\nHowever, a user might also specify the workflow using the Lindi front-end and target Naiad directly. When using Lindi however, the query scales less well than using Hive and Hadoop, despite running in Naiad. This result comes because Lindi\u2019s high-level GROUP BY operator is non-associative, meaning that data must be collected on a single machine before the operator can be applied. Musketeer supplies an improved GROUP BY operator implemented against Naiad\u2019s low-level vertex API. Consequently, its generated Naiad code scales far better than the Lindi version (up to 9\u00d7 at scale 100). The Naiad developers may of course improve Lindi\u2019s GROUP BY in the future, but this example illustrates that Musketeer\u2019s decoupling can improve\nperformance even for a front-end\u2019s native execution engine by generating improved code.\nIterative workflows. While batch workflows can be expressed using SQL-like front-end frameworks such as Hive and Lindi, iterative graph processing workflows are typically expressed differently (see \u00a74.1.2). To evaluate Musketeer\u2019s benefit for graph computations, we implemented PageRank using our GAS DSL front-end (Listing 2, \u00a74.1.2). We run this workflow on the two social network graphs we evaluated PageRank on in \u00a72 (Orkut and Twitter).\nFigure 8 compares the makespan of a five iterations of PageRank using Musketeer-generated jobs to hand-written baselines for general-purpose systems (Hadoop, Spark), an implementation using Naiad\u2019s GraphLINQ front-end and special-purpose graph processing systems (PowerGraph, GraphChi). Different systems achieve their best performance at different scales, and we only show the best result for each system. The only exception to this is GraphLINQ on Naiad, which is competitive at both 16 and 100 nodes. At each scale, Musketeer\u2019s best mapping is almost as good as the bestin-class baseline. On one node, Musketeer does best when mapping to GraphChi, while a mapping to Naiad (Orkut) or PowerGraph (Twitter) is best at 16 nodes, and a mapping to Naiad is always best at 100 nodes.\nFigure 8c shows the resource efficiency for the same configurations for PageRank on the Twitter graph. Musketeer achieves resource efficiencies close to the best stand-alone implementations at all three scales.\nThis demonstrates that Musketeer\u2019s dynamic mapping approach adds flexibility for batch and iterative computations."
        },
        {
            "heading": "6.3 Combining back-end execution engines",
            "text": "In addition to mapping an entire workflow to different backends, Musketeer can also map parts of a workflow to different systems. We find that this ability to explore many different combinations of systems can yield useful (and sometimes surprising) results.\nWe use the hybrid cross-community PageRank workflow to demonstrate this. This workflow yields the relative popu-\nlarity of the users present in both of two web communities. It involves a batch computation followed by an iterative computation: first, the edge sets of two communities (e.g., all LiveJournal and WordPress users) are intersected, and subsequently, the PageRank of all links present in both communities is computed.\nFigure 9 shows the makespan of cross-community PageRank for different combinations of systems, explored using Musketeer.7 The inputs are the LiveJournal graph (4.8M nodes and 68M edges) and a synthetically generated web community graph (5.8M nodes and 82M edges). Out of the three single-system executions, the workflow runs fastest in Lindi at 153s. However, the makespan is comparable when Musketeer combines Hadoop with a special-purpose graph processing system (e.g., PowerGraph), even though these systems use fewer machines. This happens because generalpurpose systems (like Hadoop) work well for the batch phase of the workflow, but do not run the iterative PageRank as fast as specialized systems. However, a combination of Lindi and GraphLINQ, which both use Naiad as their back-end execution engine, does even better. This comes as this combination avoids the extra I/O to move intermediate data across system boundaries. Musketeer currently does not fully automatically generate the low-level Naiad code to combine Lindi and GraphLINQ; we will support this in future work.\nMusketeer\u2019s ability to flexibly partition a workflow makes it easy to explore different combinations of systems."
        },
        {
            "heading": "6.4 Overhead over hand-tuned, non-portable jobs",
            "text": "For Musketeer to be attractive to some users, its generated code must add minimal overhead over an optimized handwritten implementation. In the following, we show that the overhead over an optimized baseline does not exceed 30% and is usually around 5\u201320%.\nBatch processing. We measure the NetFlix movie recommendation workflow [2]. This workflow highlights any overheads: it contains a large number of operators (13) and is\n7 The 100-node EC2 cluster had similar results, albeit at increased variance.\nvery data-intensive, with up to 600 GB of intermediate data generated. The workflow takes two inputs: a 100 millionrow movie ratings table (2.5GB) and a 17,000-row movie list (0.5MB). The algorithm computes movie recommendations for all users, and finally outputs the top recommended movie for each user. We control the amount of data processed by the algorithm by varying the number of movies used for the prediction. Figure 10 compares Musketeer-generated code for the NetFlix workflow to hand-optimized baselines for the three general-purpose systems that support it (Hadoop, Spark and Lindi on Naiad). We extensively tuned each of the baselines to deliver good performance for the given system, taking advantage of system-specific optimizations available.\nFor all three systems, the overhead added by Musketeer\u2019s generated code is low: it is virtually non-existent for Naiad and remains under 30% for Spark and Hadoop even as the input grows. The remaining overhead for Spark is primarily due to the simplicity of our type-inference algorithm, which can cause the Musketeer-generated code to make an extra pass over the data.\nGraph processing. We also measure Musketeer\u2019s overhead for the iterative PageRank workflow. Figure 11 shows the overhead of Musketeer-generated jobs over hand-written baselines for the back-ends compatible with the PageRank workflow. The average overhead remains below 30% in all cases. Variability in overhead (and improvements over the\nbaseline) are due to performance variance on EC2. Further optimizations of the code generation are possible. Most such optimizations benefit all code Musketeer generates for a particular back-end.\nIn conclusion, Musketeer generates code that performs nearly as well as hand-written baselines. Combined with the improved portability and the ability to dynamically explore multiple execution engines, we believe that this makes for a compelling case."
        },
        {
            "heading": "6.5 Impact of operator merging and shared scans",
            "text": "One key technique that Musketeer uses to reduce overhead is operator merging (\u00a74.3.2). We measure its impact on workflow makespan using a simple micro-benchmark: the top-shopper workflow. This benchmark finds the largest spenders in a certain geographic region by first filtering a set of purchases by region, then aggregating their values by user ID and finally selecting all users above a threshold. The workflow consists of three operators that can be merged into a single job, and indeed a single scan of the data. Figure 12a shows top-shopper\u2019s makespan for varying data size with operator merging turned off and on. In Figure 12b, we show that cross-community PageRank sees the same benefit.\nThese results illustrate that the impact of operator merging can be significant: we observe a one-off reduction in makespan of \u224825\u201350s due to avoiding per-job overheads, along with an additional 5\u201310% linear benefit per 10M users attributable to the use of shared scans."
        },
        {
            "heading": "6.6 DAG partitioning runtime",
            "text": "Next, we focus on the DAG partitioning algorithm (\u00a75). We measure the time it takes the exhaustive search and dynamic heuristic algorithms to partition the operator DAG. Ideally, they should not noticeably affect the total runtime of the workflow.\nFigure 13 compares the runtimes of the two algorithms as the number of operators in a workflow increases. In the experiment, we run subsets of an extended version of the NetFlix workflow with a total of 18 operators. This workload\naffords many operator merging opportunities, thus making a good test case for the DAG partitioning algorithms. Up to 13 operators, the exhaustive search runs in under a second, but its runtime grows exponentially beyond 13 operators. While it guarantees that the optimal partitioning subject to the cost function is found, the delay soon becomes impractical. The dynamic programming heuristic, however, runs in under 10ms even at 18 operators and scales gracefully."
        },
        {
            "heading": "6.7 Automated mapping performance",
            "text": "Musketeer can be used to manually map jobs to back-end execution engines, but we believe that the framework choice should be automated. We first investigate the quality of Musketeer\u2019s automated mapping decisions (\u00a75.2) using the workflows discussed so far, and then test its performance on two additional workflows.\nWe tested Musketeer\u2019s automated choices using the six workflows described before in 33 different configurations by varying the input data size. For each decision, we compare (i) Musketeer\u2019s choice on the first run (with no workflowspecific history), (ii) its choice with incrementally acquired partial history, and (iii) the choice it makes when it has a full history of the per-operator intermediate data sizes. We also\ncompare the choices to those that emerge from a decision tree that we developed. The decision tree considers different back-ends\u2019 features and known characteristics. We consider a choice that achieves a makespan within 10% of the best option to be \u201cgood\u201d, and one within 30% as \u201creasonable\u201d. Figure 14 shows the results: without any knowledge, Musketeer chooses good or optimal back-ends in about 50% of the cases. When partial workflow history is available, over 80% of its choices are good ones. If each workflow is initially executed operator-by-operator for profiling, Musketeer always makes good or optimal choices. By contrast, using the decision tree yields many poor choices. This is due to its inflexible decision thresholds and its inability to consider the benefits of operator merging and shared scans.\nWe also test the automatic mapping on two new workflows: single-source shortest path (SSSP) and k-means clustering. SSSP can be expressed in vertex-centric systems, while k-means cannot. Figure 15 shows the workflows\u2019 makespan for different back-ends and Musketeer\u2019s automated choice. The input for SSSP was the Twitter graph extended with costs, and we used 100M random points for k-means (100 clusters, two dimensions).8 Even with our simple proof-of-concept cost function and a small training set, Musketeer in both cases correctly identifies the appropriate back-end (Naiad)."
        },
        {
            "heading": "7. Practical experience with Musketeer",
            "text": "System integration complexity. We found the effort it take to integrate a front-end framework or a back-end execution engine with Musketeer to be reasonable. A graduate student typically takes a few days to add full support for another back-end execution engine. Our experiences with front-end frameworks were similar, although the effort required varies depending on their expressivity. Additional time and careful profiling is required to fully optimize the performance of generated code, but such improvements only need to be made once in order to benefit all Musketeer users.\n8 Our k-means uses the CROSS JOIN operator, which is inefficient. By replacing it, we could reduce the makespan and address Spark\u2019s OOM condition. However, we are only interested in the automated mapping here.\nBenefit over hand-coded jobs. To anecdotally compare the performance of Musketeer\u2019s generated code to a baseline written by an average programmer, we asked eight CS undergraduate students to implement and optimize the simple JOIN workflow from \u00a72.1 for a given input data set using Hadoop. The best student implementation took 608s, compared to the Musketeer-generated job at 223s. While not a rigorous evaluation, we take this as an indication that using Musketeer offers benefit for non-expert programmers."
        },
        {
            "heading": "8. Limitations and future work",
            "text": "In the following, we highlight some of the current limitations in Musketeer and how they can be addressed in future work.\nFront-ends (\u00a74.1). In the future, we see Musketeer offering better support for user-defined functions in front-ends. Many vertex-centric systems, for example, allow the user to specify arbitrary per-vertex code in Java (Giraph) or C++ (GraphChi). This increases flexibility, but restricts the level of optimization that Musketeer can offer. It either limits its choice to back-ends that can directly execute the userprovided code, or requires use of inefficient foreign-function interfaces. In the future, techniques that perform query synthesis on arbitrary user code [9, 20] might help here.\nIdiom recognition (\u00a74.3.1). As with many idiom recognition techniques, our approach is sound, but not complete. Musketeer may occasionally fail to detect graph workloads, consequently generating less efficient code. For example, a triangle counting workflow may encounter this problem: the user may represent it as a workflow that joins the edges twice and then filters out the triangles. In the latter case, Musketeer fails to detect the opportunity of running the computation in a graph-oriented execution engine. A \u201creverse loop unrolling\u201d heuristic that detects when multiple operators take the same input and produce the same output (or a closure thereof) can partly solve this.\nDynamic DAG partitioning heuristic (\u00a75.1.2). The dynamic programming heuristic returns the optimal k-way partitioning of a given linear order. However, it may miss fruitful merging opportunities, since it only explores a single linear ordering of operators. In Figure 16, we show an example of a workflow for which the dynamic heuristic\ndoes not achieve optimality. In the MapReduce paradigm, it makes sense to run the top JOIN in the same job as the PROJECT, but the linear ordering based on depth-first exploration breaks this merge opportunity. This limitation does not affect general-purpose back-ends (e.g., Naiad and Spark), which are able to merge any sub-region of operators. However, merging opportunities are occasionally be missed for systems with restricted expressivity, such as Hadoop and Metis. A simple solution generates multiple linear orderings and runs the heuristic for each of them."
        },
        {
            "heading": "9. Related Work",
            "text": "Musketeer is, to our knowledge, the first \u201cbig data\u201d workflow manager that decouples front-ends from back-ends and supports multiple execution engines (Table 3). Nonetheless, there is considerable related work:\nWorkflow managers. Pig [35] and Hive [40] are widely used workflow managers on top of Hadoop that present a SQL-like interface to the user. Shark [41] replaces Hive\u2019s physical plan generator to use Spark RDDs and supports fast interactive in-memory queries. SCOPE [4] and Tenzing [7] make the relationship to SQL more explicit, with Tenzing providing an almost complete SQL implementation on top of MapReduce. The semantics of these tools, however, are heavily influenced by the execution engine to which they compile (e.g., Pig relies on COGROUP clauses to delineate MapReduce jobs).\nDynamic paradigm choice. FlumeJava [5] defers execution of operations on Java parallel collections until runtime. The implementation of operations is abstracted away from the user and can range from a local iterator to a MapReduce job, depending on data size. QoX [39] combines databases and data processing engines by separating logical operations and physical implementation, but, unlike Musketeer, is limited to ETL workflows.\nAutomatic system tuning. A number of efforts have looked at automatically tuning the configuration of data processing systems. Starfish [17] automatically infers Hadoop configuration variables, while Jockey [12] and Quasar [11] automatically determine the resources to allocate to a workflow in order to meet its deadline or QoS requirements. Musketeer could be extended to perform these tasks as well [16, 29]."
        },
        {
            "heading": "10. Conclusion",
            "text": "Musketeer decouples front-end frameworks from back-end execution engines. As a result, users benefit from increased flexibility: workflows can be written once and mapped to many systems, different systems can be combined within a workflow and existing workflows seamlessly ported to new execution engines. Musketeer enables compelling performance gains and its generated code performs almost as well as unportable, hand-optimized baseline implementations. Musketeer is open-source, and available from:\nhttp://www.cl.cam.ac.uk/netos/musketeer/"
        },
        {
            "heading": "Acknowledgments",
            "text": "We would like to thank Derek G. Murray, Frank McSherry, John Wilkes, Kim Keeton, Robert N. M. Watson, Jon Crowcroft, Tim Harris and our anonymous reviewers for their valuable feedback. Thanks also go to Anne-Marie Kermarrec, our shepherd. Natacha Crooks and Ionel Gog were partly supported by Google Europe Fellowships; parts of this work were supported by the EPSRC INTERNET Project EP/H040536/1, the Defense Advanced Research Projects Agency (DARPA) and the Air Force Research Laboratory (AFRL), under contract FA8750-11-C-0249. The views, opinions, and/or findings contained in this paper are those of the authors and should not be interpreted as representing the official views or policies, either expressed or implied, of the DARPA or the Department of Defense."
        }
    ],
    "title": "Musketeer: all for one, one for all in data processing systems",
    "year": 2015
}