{
    "abstractText": "We present an analyst-in-the-loop security system, where analyst intuition is put together with stateof-the-art machine learning to build an end-to-end active learning system. The system has four key features: a big data behavioral analytics platform, an ensemble of outlier detection methods, a mechanism to obtain feedback from security analysts, and a supervised learning module. When these four components are run in conjunction on a daily basis and are compared to an unsupervised outlier detection method, detection rate improves by an average of 3.41\u00d7, and false positives are reduced fivefold. We validate our system with a real-world data set consisting of 3.6 billion log lines. These results show that our system is capable of learning to defend against unseen attacks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Kalyan Veeramachaneni"
        },
        {
            "affiliations": [],
            "name": "Ignacio Arnaldo"
        },
        {
            "affiliations": [],
            "name": "Alfredo Cuesta-Infante"
        },
        {
            "affiliations": [],
            "name": "Vamsi Korrapati"
        },
        {
            "affiliations": [],
            "name": "Costas Bassias"
        },
        {
            "affiliations": [],
            "name": "Ke Li"
        }
    ],
    "id": "SP:98db9d45799f461070cd245276f5114c6658523b",
    "references": [
        {
            "authors": [
                "Naoki Abe",
                "Bianca Zadrozny",
                "John Langford"
            ],
            "title": "Outlier detection by active learning",
            "venue": "In Proceedings of the Twelfth ACM SIGKDD International Conference on Knowledge Discovery and Data",
            "year": 2006
        },
        {
            "authors": [
                "Charu C. Aggarwal"
            ],
            "title": "Outlier ensembles: Position paper",
            "venue": "SIGKDD Explor. Newsl.,",
            "year": 2013
        },
        {
            "authors": [
                "Varun Chandola",
                "Arindam Banerjee",
                "Vipin Kumar"
            ],
            "title": "Anomaly detection: A survey",
            "venue": "ACM Comput. Surv.,",
            "year": 2009
        },
        {
            "authors": [
                "Jing Gao",
                "Pang-Ning Tan"
            ],
            "title": "Converting output scores from outlier detection algorithms into probability estimates",
            "venue": "In Proceedings of the Sixth International Conference on Data Mining,",
            "year": 2006
        },
        {
            "authors": [
                "Victoria Hodge",
                "Jim Austin"
            ],
            "title": "A survey of outlier detection methodologies",
            "venue": "Artif. Intell. Rev.,",
            "year": 2004
        },
        {
            "authors": [
                "S.G. Iyengar"
            ],
            "title": "Decision-making with heterogeneous sensors-a copula based approach",
            "venue": "PhD Dissertation,",
            "year": 2011
        },
        {
            "authors": [
                "Hans-Peter Kriegel",
                "Peer Kr\u00f6ger",
                "Erich Schubert",
                "Arthur Zimek"
            ],
            "title": "Interpreting and unifying outlier scores",
            "venue": "In Proceedings of the Eleventh SIAM International Conference on Data Mining, SDM 2011, April 28-30,",
            "year": 2011
        },
        {
            "authors": [
                "David D Lewis",
                "Jason Catlett"
            ],
            "title": "Heterogeneous uncertainty sampling for supervised learning",
            "venue": "In Proceedings of the eleventh international conference on machine learning,",
            "year": 1994
        },
        {
            "authors": [
                "Barbora Micenkov\u00e1",
                "Brian McWilliams",
                "Ira Assent"
            ],
            "title": "Learning outlier ensembles: The best of both worlds\u2013 supervised and unsupervised",
            "venue": "In KDD\u201914 Workshops: Outlier Detection and Description",
            "year": 2014
        },
        {
            "authors": [
                "Dan Pelleg",
                "Andrew W. Moore"
            ],
            "title": "Active learning for anomaly and rare-category detection",
            "venue": "In Advances in Neural Information Processing Systems",
            "year": 2004
        },
        {
            "authors": [
                "Matthias Scholz",
                "Ricardo Vig\u00e1rio"
            ],
            "title": "Nonlinear PCA: a new hierarchical approach",
            "venue": "In Proceedings of the 10th European Symposium on Artificial Neural Networks (ESANN),",
            "year": 2002
        },
        {
            "authors": [
                "Erich Schubert",
                "Remigius Wojdanowski",
                "Arthur Zimek",
                "Hans-Peter Kriegel"
            ],
            "title": "On evaluation of outlier rankings and outlier scores",
            "venue": "In Proceedings of the Twelfth SIAM International Conference on Data Mining,",
            "year": 2012
        },
        {
            "authors": [
                "H.S. Seung",
                "M. Opper",
                "H. Sompolinsky"
            ],
            "title": "Query by committee",
            "venue": "In Proceedings of the Fifth Annual Workshop on Computational Learning Theory,",
            "year": 1992
        },
        {
            "authors": [
                "Ting-Fang Yen"
            ],
            "title": "Detecting stealthy malware using behavioral features in network traffic",
            "venue": "PhD thesis,",
            "year": 2011
        },
        {
            "authors": [
                "Arthur Zimek",
                "Ricardo J.G.B. Campello",
                "J\u00f6rg Sander"
            ],
            "title": "Ensembles for unsupervised outlier detection: Challenges and research questions a position paper",
            "venue": "SIGKDD Explor. Newsl.,",
            "year": 2014
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Today, information security solutions generally fall into two categories: analyst-driven, or unsupervised machine learning-driven. Analyst-driven solutions rely on rules determined by fraud and security experts, and usually lead to high rates of undetected attacks (false negatives), as well as delays between attack detection and implementation of preventative countermeasures. Moreover, bad actors often figure out current rules, and design newer attacks that can sidestep detection.\nUsing unsupervised machine learning to detect rare or anomalous patterns can improve detection of new attacks. However, it may also trigger more false positive alarms and alerts, which can themselves require substantial investigative efforts before they are dismissed. Such false alarms can cause alarm fatigue and distrust, and over time, can cause reversion to analyst-driven solutions, with their attendant weaknesses.\nWe identified three major challenges facing the information security industry, each of which could be addressed by machine learning solutions:\nLack of labeled data: Many enterprises lack labeled examples from previous attacks, undercutting the ability to use supervised learning models.\nConstantly evolving attacks: Even when supervised learning models are possible, attackers constantly change their behaviors, making said models irrelevant.\nLimited investigative time and budget: Relying on analysts to investigate attacks is costly and time-consuming.\nA solution that properly addresses these challenges must use analysts\u2019 time effectively, detect new and evolving attacks in their early stages, reduce response times between detection and attack prevention, and have an extremely low false positive rate. We present a solution that combines analysts\u2019 experience and intuition with state-of-the-art machine learning techniques to provide an end-to-end, artificially intelligent solution. We call this system AI2. AI2 learns and automatically creates models that, when executed on new data, produce predictions as intelligent as those deduced by human analysts. Backed by big data infrastructure, we achieve this in close to real time.\nOur contributions through this paper are as follows: 1. Developed an Active Model Synthesis approach, which:\n(a) computes the behaviors of different entities within a raw big data set,\n(b) presents the analyst with an extremely small set of events (k <<< N ), generated by an unsupervised, machine learning-based outlier detection system,\n(c) collects analyst feedback (labels) about these events,\n(d) learns supervised models using the feedback, (e) uses these supervised models in conjunction with\nthe unsupervised models to predict attacks, and (f) continuously repeats steps (a) - (e).\n2. Designed multivariate methods that are capable of modeling the joint behaviors of mixed variable types (numeric and discrete ordinal). These methods include density-based, matrix decomposition-based, and replicator neural networks. 3. Demonstrated performance of the AI2 system by monitoring a web-scale platform that generated millions of log lines per day over a period of 3 months, for a total of 3.6 billion log lines.\nSummary of results: In Figure 1, we present a snapshot of our system\u2019s progress after 12 weeks of use. With 3 months\u2019 worth of data, and with awareness of attacks, we evaluate\nwhether our solution can improve attack detection rates (recall) while reducing the number of alerts shown to the analyst (\u201cdaily investigation budget\u201d k). Using analyst time effectively: The AI2 system achieves a detection rate of 86.8% even at an extremely low daily investigative budget of k = 200 events. This represents more than tenfold improvement1 over the unsupervised outlier detection approach rate, which is 7.9%. Fixing the daily investigation budget at 200 keeps the false positive rate at 4.4%. Reducing false-positives by a factor 5: If we allow for an higher daily investigative budget (for example, up to 1000), the unsupervised outlier detection based method can still only achieve a 73.7% detection rate, and the false positive rate is > 22%. AI2 achieves > 86% for a false positive rate of 4.4% a reduction by factor of 5. On our choice of the title \u201cTraining a big data machine to defend\u201d: We define a big data system or machine as a software infrastructure that is able to ingest data in real time, compute and generate quantities that can then be analyzed, either by data scientists or a machine learning system. A machine learning substrate that sits on top of this system can analyze the data and automatically produce outliers. We provide a system that collects and incorporates analyst feedback, generates, and uses these models continuously without any involvement from its original developers - that is us. Thus, we are able to deliver a fully automatic system that could be trained by analysts.\nIn Section 2, we present an overview of the system, and the challenges encountered while building it. Section 3 summarizes related work in this area and Section 4 describes the data analyzed by our platform. In Section 5 we present the big data platform for behavioral analytics. Section 6 presents the outlier detection system. With the two key components in place, Section 7 presents the active model synthesis framework. Section 8 presents the experimental setup and the results achieved. Section 9 presents our key findings and conclusions.\n1This result corresponds to the 12th and last week of deployment while the 3.41\u00d7 improvement claimed in the abstract is the average improvement over the 12 weeks.\n2 AI2\nIn this paper, we present an end-to-end system that learns over time thanks to feedback from security analysts. Figure 2 presents a schematic of our system, which is made up of the following components: \u2022 Big data processing system: A platform that can quan-\ntify the behaviors (a.k.a features) of different entities, and compute them from raw data. With high-volume, high-velocity data, this first component requires processing at a challenging scale. We describe this system and what it accomplishes in Section 5 \u2022 Outlier detection system: This system learns a descrip-\ntive model of those features extracted from the data via unsupervised learning, using one of three methods: density, matrix decomposition, or replicator neural networks. To achieve confidence and robustness when detecting rare and extreme events, we fuse multiple scores into a final score that indicates how far a certain entity or event is from others. These methods are described in detail in Section 6. \u2022 Feedback mechanism and continuous learning: This\ncomponent incorporates analyst input through a user interface. It shows the top k outlier events or entities, and asks the analyst to deduce whether or not they are malicious. This feedback is then fed into the supervised learning module. The value of k and the feedback frequency (e.g. daily or weekly) are both decided by the end user. \u2022 Supervised learning module: Given the analyst\u2019s feed-\nback, the supervised learning module learns a model that predicts whether a new incoming event is normal or malicious. As more feedback is gathered, the model is constantly refined."
        },
        {
            "heading": "3 Related Work",
            "text": "Our work exploits ideas from a wide range of fields, including outlier analysis, ensemble learning, active learning, information security, behavioral analytics, and big data computing.\nOutlier analysis methods have been reviewed in Hodge and Austin [2004], Chandola et al. [2009] and Aggarwal [2013a]. Our platform integrates outlier detection methods based on\nPrincipal Component Analysis (Shyu et al. [2003]), neural networks (Hawkins et al. [2002]; Scholz and Viga\u0301rio [2002]; Scholz et al. [2008]), and statistical models.\nEnsemble learning can enhance the robustness of outlier analysis (Schubert et al. [2012]; Aggarwal [2013b]; Zimek et al. [2014]). This approach has received attention only recently, due to two main constraints: first, it is difficult to interpret and compare outlier scores retrieved with different methods (Gao and Tan [2006]; Kriegel et al. [2011]), and second, it is difficult to weight confidence in different methods, since there is no ground truth that can be used for learning. In fact, most works assume a semi-supervised setting, where a set of labels is initially available (Micenkova\u0301 et al. [2014]).\nThe active learning framework (Seung et al. [1992]) has been applied to the outlier analysis task in the past (Pelleg and Moore [2004]; Abe et al. [2006]). In these works, the most ambiguous examples are shown to the user for labeling. This approach is in line with the uncertainty sampling method introduced in Lewis and Catlett [1994].\nBehavioral predictive analytics have shown promising results for network intrusion (Yen [2011]) and internal threat detection (Senator et al. [2013]). However, to the best of our knowledge, we present the first big data security system capable of detecting threats in real time, and of collecting analysts\u2019 feedback to improve detection rates over time."
        },
        {
            "heading": "4 Data characteristics",
            "text": "In this section, we present the typical characteristics of the data ingested by our platform (also summarized in Table 1). Data sources and applications: Our platform processes both web logs and firewall logs. In a typical enterprise system, these logs are delivered in real, streaming time from widely distributed data sources. Web log analysis is aimed at the detection of web attacks, while mining firewall logs allows us to prevent data ex-filtration in enterprise setups.\nData dimensions and unique entities: The computational effort associated with analyzing data can be reasonably estimated by the data size and the number of unique entities. The first refers to the volume of the raw data, and is generally reported in the form of size metrics (GB, TB) and/or number of log lines (for instance, a midsized enterprise platform easily generates tens of millions of log lines on a daily basis). The second is specific to behavioral analytics, and corresponds to the number of unique entities (IP addresses, users, sessions, etc) analyzed on a daily basis.\nThe data set used in this paper corresponds to three months\u2019 worth of logs, generated by an enterprise platform. This platform records millions of log lines per day, each corresponding to a specific user interaction, and has hundreds of thousands of daily active users. Table 1 presents the typical ranges we see in our current use cases. Malicious activity prevalence: Under normal circumstances, malicious activities are extremely rare in an enter-\nprise setup. Attack cases represent a minor fraction of total events (generally < 0.1%). To illustrate this fact, Figure 3 shows the ratio of reported malicious users to the total number of active users in the studied dataset. Three additional observations are worth remarking on: \u2022 This dearth of malicious activity results in extreme class\nimbalance when learning a supervised model, and increases the difficulty of the detection process. \u2022 It is safe to assume that not all malicious activities are\nsystematically reported, either because their incident responses were inconclusive, or because they were not detected in the first place. This introduces noise into the data, since unreported attacks will be considered legitimate activity. \u2022 Attack vectors can take a wide variety of shapes. Even\nwhen malicious activities are reported, we are not always aware of the specific vectors involved. Thus ,it is important to develop robust defense strategies that are capable of detecting as many attacks as possible.\nok"
        },
        {
            "heading": "5 BigData platform for behavioral analytics",
            "text": "Our approach rests on the computation of behavioral descriptors for different entities, such as IP addresses, users, or sessions. These entities can be independent or connected; for instance, the same IP address may be associated with two or more users."
        },
        {
            "heading": "5.1 Behavioral signatures",
            "text": "A typical attack has a behavioral signature, which comprises the series of steps involved in committing it. The information necessary to quantify these signatures is buried deep in the raw data, and is often delivered as logs. These quantitative values can be specified by security experts, and generally correspond to indicators an expert would use to investigate an attack. Also known as variables or features in the field of machine learning, they are usually extracted on a per-entity, per-time-segment basis. Using the platform, we calculate a total of 24 variables per user per day. Take, for example, the per-user behavioral features shown in Figure 4. A platform capable of computing behavioral features in real time is itself valuable, since it allows analysts to monitor applications more dynamically."
        },
        {
            "heading": "5.2 Design requirements",
            "text": "A big data system for real-time behavioral analytics on webscale applications must meet the following criteria:\n1. Capable of analyzing the behavior of 10+ million entities on a daily basis. 2. Capable of updating and retrieving the behavioral signatures of active entities, on demand and in real time. The platform needs to be able to retrieve behavioral signatures for up to 50 thousand entities at once.\nIn the following section, we describe the key aspects that enable our big data system to process logs from many data sources, extract entities, transform raw logs into features, and keep these features up-to-date in real time. The system is designed to horizontally scale, in order to address billions of log lines per day."
        },
        {
            "heading": "5.3 From raw logs to behaviors in real time",
            "text": "To calculate behavioral features for one user over a particular time segment, one must isolate all relevant historic log lines and perform the aggregations that feature definition demands\u2014for example, aggregating the money this user spent during that time segment. This process must be repeated for all the active users, populating the entity-feature matrix as shown on the right hand side of Figure 4. Such computations are challenging because of high volume, distributed storage of data, and the need to aggregate over historical data to compute the feature. We address this challenge by breaking the extraction of features into two processes: Activity Tracking and Activity Aggregation. Activity Tracking: As the system absorbs the log stream generated by the platform, it identifies the entities involved in each log line (e.g. IP address, user, etc.) and updates the corresponding activity records. These activity records are calculated and stored according to two guidelines:\n1. A very short temporal window. In our experiments, the temporal window over which these activity records are computed and stored is one minute. This way, we can compute behavioral features for different time intervals - 30 minutes, 1 hr, 12 hrs and 24 hrs. This allows flexibility in analysis. 2. A design streamlined toward efficient retrieval of the user data necessary for feature computation. Note that, depending on the definition of the feature, aggregating activity records for a larger time window can require anything from simple counters to complex data structures.\nTo elaborate on this second guideline, we show 5 categories of behavioral features, and discuss appropriate structures for efficient data retrieval and aggregation for each category: \u2022 Counts, averages, and standard deviations: these three\nmetrics can be derived from simple counters. For example: the number of successful logins over the last 24 hours. \u2022 Indicators (or boolean variables): Aggregating indica-\ntors is also straightforward and requires no additional data structures. For example: whether at least one address verification failed over the last 24 hours.\n\u2022 Relational features: these features are calculated using data at the intersection of two entities. For example: the maximum outlier score given to an IP address from which the user has accessed the website. To compute these features efficiently, we build graphs that represent relations between entities in the system. \u2022 Temporal behaviors: these variables capture the time\nelapsed between two or more events, and therefore must be analyzed in chronological order. For example: the minimum time from login to checkout). Computing these features requires timestamping all the relevant events (in this case, logins and checkouts), and comparing the time elapsed between consecutive events. \u2022 Unique values: This kind of feature cannot be computed\nwith counters, since duplicated values must be kept track of. We use a dictionary to maintain a set of unique values of the feature, and update it every time new user activity is analyzed. For example: number of different locations from which a user has accessed the website over the last 24 hours.\nActivity aggregation: Computing behavioral features over an interval of time requires two steps:\n1. Retrieve all activity records that fall within the given interval. Note that, for the purposes of this study, we consider behavioral descriptors that have been aggregated over 24 hours and end at the time of the last user activity. This can be graphically represented as a rolling 24-hour window for feature computation.\n2. Aggregate minute-by-minute activity records as the feature demands. Again, this aggregation step depends on the feature type. In the simplest case, counters, one must merely add all the minute-by-minute values together. The more complex case of unique values requires retrieving the unique values of the super set formed by the minute-by-minute sets.\nPerformance considerations: Because the temporal scope of our activity records is 1 minute, we can aggregate records and compute features for flexible time intervals. However, this strategy can result in poor performance. For instance, in the worst case, to compute features over a 24-hour window, we need to retrieve and aggregate 24\u00d760 (minute records)=1440 records. This process has to repeat for millions of entity instances.\nTo improve retrieval and aggregation performance, we maintain activity records with different, overlapping time scopes. In particular, we maintain records on:\n\u2022 a minute-by-minute basis (starting on the dot), \u2022 an hourly basis (starting on the dot), \u2022 a daily basis (starting at midnight), and \u2022 a weekly basis (starting Sunday at midnight).\nThis way, if we need to compute features for long intervals, our record retrieval and aggregation requirements remain bounded and satisfy real-time requirements. For example, with this strategy, the computation of features over the previous 24 hours requires the retrieval and aggregation of no more than 23(hour records)+60(minute records)=83 records."
        },
        {
            "heading": "6 Outlier detection methods",
            "text": "The use of outlier analysis is motivated by the observation that attacks are rare and exhibit distinctive behavior. We combine three unsupervised outlier detection techniques:"
        },
        {
            "heading": "6.1 Matrix Decomposition-based outlier analysis",
            "text": "Key idea: Outlier detection methods based on matrix decomposition use Principal Component Analysis to find cases that violate the correlation structure of the main bulk of the data (Shyu et al. [2003]). To detect these rare cases, PCAbased methods analyze the projection from original variables to the principal components\u2019 space, followed by the inverse projection (or reconstruction) from principal components to the original variables (see Figure 5). If only the first principal components (the components that explain most of the variance in the data) are used for projection and reconstruction, we ensure that the reconstruction error will be low for the majority of the examples, while remaining high for outliers. This is because the first principal components explain the variance of normal cases, while last principal components explain outlier variance (Aggarwal [2013a]).\nLet X be a p-dimensional dataset. Its covariance matrix \u03a3 can be decomposed as: \u03a3 = P \u00d7 D \u00d7 PT , where P is an orthonormal matrix where the columns are the eigenvectors of \u03a3, and D is the diagonal matrix containing the corresponding eigenvalues \u03bb1 . . . \u03bbp. Graphically, an eigenvector can be seen as a line in 2D space, or a plane in higherdimensionality spaces, while its corresponding eigenvalue indicates how much the data is stretched in that direction.\nNote that, at this stage, it is common practice to sort the columns of the eigenvector matrix P and eigenvalue matrix D in order of decreasing eigenvalues. In other words, the eigenvectors and their corresponding eigenvalues are sorted in decreasing order of significance (the first eigenvector accounts for the most variance, the second for the second-most, etc.).\nThe projection of the dataset into the principal component space is given by Y = XP . Note that this projection can be performed with a reduced number of principal components. Let Y j be the projected dataset using the top j principal components: Y j = X \u00d7 P j . In the same way, the reverse projection (from principal component space to original space) is given byRj = (P j\u00d7(Y j)T )T , whereRj is the reconstructed dataset using the top j principal components. This process is schematically depicted in Figure 5.\nWe define the outlier score of point Xi = [xi1 . . . xip] as:\nscore(Xi) = p\u2211 j=1 (|Xi \u2212Rji |)\u00d7 ev(j) (1)\nev(j) =\nj\u2211 k=1 \u03bbk\np\u2211 k=1 \u03bbk\n(2)\nNote that ev(j) represents the percentage of variance explained with the top j principal components. As mentioned above, eigenvalues are sorted in decreasing order of significance; therefore, ev(j) will be monotonically increasing. This\nmeans that, the higher is j, the most variance will be accounted for within the components from 1 to j. With this outlier score definition, large deviations in the top principal components are not heavily weighted, while deviations in the last principal components are. This way, outliers present large deviations in the last principal components, and thus will receive high scores."
        },
        {
            "heading": "6.2 Replicator Neural Networks",
            "text": "Key idea: This method is similar to the previous one, in the sense that it also relies on a compression-reconstruction analysis. However, in this case, we train a multi-layer neural network to compress and reconstruct the data in such a way that the bulk of the data is reconstructed accurately, but outliers are not. This way, the reconstruction error can be directly translated into an outlier score.\nReplicator Neural Networks (RNNs), or autoencoders, are multi-layer feed-forward neural networks. The input and output layers have the same number of nodes, while intermediate layers are composed of a reduced number of nodes. As depicted in Figure 6, we consider RNNs that are composed of three hidden layers. The first and third hidden layers count p/2 neurons, while the second, central layer is composed of p/4 neurons, where p is the dimensionality of the data. The\ntan-sigmoid transfer function is used as an activation function across the network.\nThe network is trained to learn identity-mapping from inputs to outputs. The mapping from inputs to intermediate layers compresses the data. The data is then decompressed to reconstruct the inputs, mapping from intermediate layers to outputs. This reconstruction is lossy\u2014 that is, introduces an error, and the training process is aimed at minimizing it. The reconstruction error for the the i-th example is given by:\nei = p\u2211 j=1 (xij \u2212 rij)2 (3)\nwhere the input vector x and output vector r are both pdimensional. Given a trained RNN, the reconstruction error is used as the outlier score: test instances incurring a high reconstruction error are considered outliers."
        },
        {
            "heading": "6.3 Density-based outlier analysis",
            "text": "Key idea: Next, we incorporate a technique that fits a multivariate model to the data. This results in a joint probability distribution that can be used to detect rare events, because test instances which fall within a low-density region of the distri-\nbution are considered outliers. The outlier score is simply the probability density of a point in the multidimensional space.\nTo build a multivariate model from marginal distributions which are not all Gaussian, we exploit copula functions. A copula framework provides a means of inference after modeling a multivariate joint probability distribution from training data. Because copula frameworks are less well known than other forms of estimation, we will now briefly review copula theory. We will then describe how we construct the individual non-parametric distributions that make up a copula, and how we then couple them to form a multivariate density function.\nA copula function C(u1, . . . um; \u03b8) with parameter \u03b8 is a joint probability distribution of m continuous random variables, each of them uniformly distributed in [0, 1]. According to Sklar\u2019s theorem, any copula function that takes probability distributions Fi(xi) as its arguments defines a valid joint distribution with marginals Fi(xi). Thus, we are able to construct a joint distribution function for x1 . . . xm with arbitrary marginals as\nF (x1 . . . xm) = C(F1(x1) . . . Fm(xm); \u03b8). (4) The joint probability density function (PDF) is obtained by taking the mth order derivative of eqn. (4)\nf(x1 . . . xm) =\n\u2202m\n\u2202x1 . . . \u2202xm C(F1(x1) . . . Fm(xm); \u03b8)\n= m\u220f i=1 fi(xi) \u00b7 c(F1(x1) . . . Fm(xm); \u03b8) (5)\nwhere c(.) is the copula density. Gaussian copula: A multivariate Gaussian copula forms a\nstatistical model for our variables given by CG(u1 . . . um; \u03a3) = FG(\u03a6 \u22121(u1) . . .\u03a6 \u22121(um); \u03a3) (6)\nwhere FG is the CDF of multivariate normal with zero mean vector and \u03a3 as covariance, and \u03a6\u22121 is the inverse of the standard normal. Estimation of parameters: Let \u03a8 = {\u03a3,\u03c8i}i=1...m be the parameters of a joint probability distribution constructed with a copula andmmarginals, being \u03c8i the parameter of marginal ith.\nGiven N i.i.d observations of the variables x = (x11, . . . ,xmN ), the log-likelihood function is:\nL(x; \u03a8) = N\u2211 l=1 log {( m\u220f i=1 f(xil;\u03c8i) )\nc(F (x1) . . . F (xm); \u03a3)\n} (7)\nParameters \u03a8 are estimated via maximum log-likelihood (Iyengar [2011]):\n\u03a8\u0302 = arg max \u03a8 N\u2211 l=1 log {( m\u220f i=1 f(xil;\u03c8i) )\nc(F (x1) . . . F (xm); \u03a3)\n} (8)\nEstimation of Fi(xi): The first step in modeling copula density is to model the individual distributions for each of our features, xi. We model each feature using a non-parametric kernel density-based method, described by:\nf\u03c3(x j i ) =\n1\nn\u03c3 n\u2211 j=1 K ( xji \u2212 \u00b5 \u03c3 ) (9)\nwhere K(.) is a Gaussian kernel with the bandwidth parameter \u03c3. Using this method together with our features, we encounter two problems.\nFirst, most of the features produce extremely skewed distributions, making it hard to set the bandwidth for the Gaussian kernel. We set bandwidth parameter using Scott\u2019s rule of thumb.\nSecond, some of our variables are discrete ordinal. For copula functions to be useful, the probability density of ui = F (xi) should be uniform, and for discrete-valued variables this condition is not met. In Figure 7, we demonstrate this using one of our features. The top left plot in the figure shows histogram for an original feature xi. The histogram on the right is for ui, which is the cdf values for the feature values. As we can see the histogram for ui is not uniform.\nTo overcome this problem, we add additive white Gaussian noise to xi. This simple transformation gives us a continuousvalued feature, given by xci . In our formulation, we add noise to each feature value given by:\nxci = xi + \u03b7(0,np) (10) where np is a variance of the Gaussian distribution \u03b7 used to add noise. This value is determined by evaluating np = Ps SNR , where SNR is the desired signal-to-noise ratio. Ps is the signal power, estimated based on the distribution of all\nvalues for the feature xi 2. For most of our features, the SNR value is set to 20. The bottom left plot in Figure 7 shows the histogram for the transformed variable xci and the plot on the right shows the histogram for uci . This looks closer to uniform. Why Copulas?: In Figure 8 we demonstrate the efficacy of Copulas in modeling a bi-variate distribution. We took two features, plotted a scatter plot, modeled the features using a Gaussian copula with Weibull marginals and overlaid the contours for the density function. The plot on the left shows the result. On right we see the contours for a bi-variate Gaussian fitted to this data. We can see qualitatively that the joint Copula density function fits the data better. For quantitative comparisons, we evaluated the log-likelihood value to evaluate the fit. The Copula fits the data better by an order of magnitude."
        },
        {
            "heading": "6.4 Outlier score interpretation",
            "text": "The three outlier detection methods presented in the previous section assign a score that indicates each example\u2019s incongruity. Therefore, it is possible to rank all the test examples according to the score given by an individual detector. In the same way, one can select the top-k examples, or define a threshold to determine when the score is significant enough to consider the example as an outlier. Three main issues arise from such strategies:\n1. Selecting the top-k examples can lead to false positives, because highly-ranked examples will not necessarily have a high outlier score. Since ranking is determined by comparing examples to each other and not by\n2In future we estimate the signal power value for each individual value of the feature xi separately allowing a more customized noise value\ntheir absolute score, this scenario may occur if the data has few outliers. 2. Thresholding techniques are difficult to implement because scores are not easily interpretable. For instance, joint probability density values differ by more than 50 orders of magnitude (from 10\u221260 to 10\u22122). 3. Because combining scores from different methods is not straightforward, it is also difficult to exploit the robustness of multi-algorithm outlier detection ensembles. Not only can the range of values returned by different methods be completely different, these methods can also result in opposite categorizations; in some cases, such as the matrix decomposition-based method, outliers receive the highest scores, while in other cases, such as probability density estimation methods, normal data points receive higher scores.\nOne solution for overcoming these limitations while still taking advantage of two or more detectors is to combine ranks instead of scores Zimek et al. [2014]. However, highly ranked examples will still be considered outliers, regardless of whether their absolute outlier scores are high or not. As a result, this strategy can result in a high false positive rate.\nAnother solution is to project all scores into the same space, ideally interpretable as probabilities. We adopt this last strategy; however, as we explain in the following subsection, it comes with its own challenges."
        },
        {
            "heading": "6.5 Transforming outlier scores into probabilities",
            "text": "We model matrix decomposition-based outlier scores with a Weibull distribution, which is flexible, and can model a wide variety of shapes. For a given score S, the outlier probability corresponds to the cumulative density function evaluated in S: F (S) = P (X \u2264 S). The exact same technique can be applied to the replicator neural networks scores.\nJoint probability densities require an additional step, because the scores span different orders of magnitude. As a result, most of the information is lost. To mitigate this loss, we first compute the negative logarithm of the scores, and then shift the distribution to have positive support. Once this transformation is performed, we model the transformed scores with a Weibull distribution and determine the outlier probability for each example."
        },
        {
            "heading": "6.6 Outlier detection ensembles",
            "text": "Multi-algorithm ensembles are combinations of predictions from different machine learning models. This strategy improves robustness by compensating for the individual biases of models in the ensemble. In this case, we average outlier probabilities obtained separately by each of the methods. Each example must be highly scored by all methods in order to be highly ranked and shown to the end user."
        },
        {
            "heading": "7 Active Model Synthesis",
            "text": "This system is meant to continually identify new and evolving attacks with the help of an analyst, and to use these identifications to synthesize new models that can predict attacks without the analyst, using behavioral descriptors. For this, we designed a closed-loop system that entwines analyst intuition with machine intelligence.\nWe present an outline of the Active Model Synthesisframework in Figure 10. The algorithm has three phases\u2013TRAINING, DEPLOYMENT and FEEDBACK COLLECTION/UPDATING\u2013and cycles through these phases daily. The entity-feature matrix and the labeled data serve as the algorithm\u2019s inputs. In an everyday workflow, the system trains unsupervised and supervised models, applies these models\nto that day\u2019s incoming data, identifies k entities as extreme events or attacks, and brings them and their data to the analysts\u2019 attention. The analysts then use an interface to sort through these rare events and pick out which could truly be attacks. Finally, we use the analysts\u2019 deductions to build a new predictive model for the next day.\nThe key advantages of this system are: \u2022 Overcomes limited analyst bandwidth: The number of\nevents an analyst can feasibly examine is a tiny fraction of the overall event volume, about 10\u22125 %. To select these events, we rely on the accurate, robust and multimethod outlier detection system presented in Section 6. We update our models daily and use them the next day, as presented in Figure 10. \u2022 Overcomes weaknesses of unsupervised learning: One\nof the key intuitions driving our system is that an event\u2019s rarity (or its status as an outlier) does not constitute maliciousness, and that an event\u2019s score does not capture the intent behind it. If we consider all top k events as malicious, then a simple threshold-based detector would be enough to diagnose them. A non-linear model enables us to imitate analysts\u2019 subjective assessment of the events. \u2022 Actively adapts and synthesizes new models: Analyst\nfeedback delivers labeled data on a daily basis. This increases the training data available to the system, allowing us to change models on a daily basis. This setup captures the cascading effect of the human-machine interaction: the more attacks the predictive system detects, the more feedback it will receive from the analysts; this feedback, in turn, will improve the accuracy of future predictions. Therefore, as time progresses and the systems absorb the analysts\u2019 feedback, we expect to see clear improvement in the detection rate. In addition, we allow the analysts to sort the attacks into multiple categories, enabling us to build custom models for different attacks."
        },
        {
            "heading": "8 Experimental setup",
            "text": "To validate our platform, we experimented with a real-world data set, with reported attacks introduced in Section 4. The experiments performed were designed to show how the analyst\u2019s feedback improved the threat-detection process."
        },
        {
            "heading": "8.1 Types of attacks",
            "text": "To illustrate the variety of threats that may compromise enterprise platforms, we describe the behaviors involved in three representative attacks. \u2022 Account takeover attacks: Account takeover attacks gen-\nerally consist of two steps. First, attackers will try to access a given website using many user/password pairs from a reduced number of IP addresses. At this stage, the bad actors will figure out which user credentials are active, but will perform few or no checkouts. Note that this step can be detected by looking at elevated numbers of login attempts originating from the same IP; however, strictly speaking, no fraud has yet been committed.\nAt a later time, the same or a different bad actor will access the site with stolen \u201dvalidated\u201d credentials, and perform transactions using the credit cards associated with these accounts. In this case, to avoid raising suspicions, attackers will generally use a single user per IP address. \u2022 New account fraud: In a new account fraud, a bad ac-\ntor gains access to a stolen credit card and creates a new account using the credit card owner\u2019s personal information. Once the account is created, the bad actor performs transactions with the stolen credit card. \u2022 Terms of service abuse: This category covers fraudulent\nviolations of the terms of service agreement. Frauds of this sort have very distinct signatures. Two simple examples are the abusive use of promotional codes, or deleting the web browser\u2019s cookies to participate more times than allowed in an online voting platform."
        },
        {
            "heading": "8.2 Analyzing the impact of the analysts\u2019 feedback",
            "text": "We compare the fraud detection rate obtained with a purely unsupervised outlier analysis approach to the Active Model Synthesis strategy explained in Section 7.\nIn some scenarios, we may have access to labeled data from the past, even before the rare event detection system is deployed. We call these labels historic labels. We introduce an additional parameter, d \u2208 {0, 28} to represent the number of days for which we have (albeit incomplete or noisy) labeled examples. For each strategy, we report the total number of detected attacks on a monthly basis, the recall, and the area under the receiver operating characteristic curve (AUC) of the deployed classifier.\nFigure 11 shows the detection rates achieved with userbased features, where the analyst has a fixed daily bandwidth of k = 100 incident investigations. The following observations are worth noting:\n\u2022 The Active Model Synthesis setups beat fully unsupervised outlier detection by a large margin. Over the 12 weeks of the simulation, the outlier detection approach caught a total of 42 attacks, while the Active Model Synthesis setups with d=0 and d=28 detected 143 and 211\nattacks respectively, out of a total of 318 attacks successfully linked to individual users. \u2022 The detection rate of the Active Model Synthesis setups\nwith d=0 and d=28 increases over time, reaching 0.500 and 0.604 respectively at the 12th and final week of the simulation. \u2022 The performance of the classifiers at the end of the 12th\nweek is almost identical between the three Active Model Synthesis setups. In the case of d=0, the AUC of the classifier in the final week reaches 0.940, while the setup considering d=28 reaches 0.946.\nBased on these results, we present the following key findings: \u2022 Over the course of three months, our system with d=0,\nwith no initial labeled examples, increased the attack detection rate by 3.41\u00d7, compared to state-of-the-art unsupervised outlier detection. \u2022 Our platform reduces the number of false positives with\nrespect to state-of-the-art unsupervised outlier analysis. As shown in Figure 1, once the system is trained, we achieve a recall of 0.868 with k (analyst bandwidth) set to 200, whereas the unsupervised-ML approach achieves 0.737, even when the analyst is shown 1000 entities a day. This observation indicates a simultaneous increase of the attack detection rate and a fivefold false positive reduction; therefore, our system improves the analyst\u2019s efficiency and mitigates alarm fatigue issues. \u2022 The system learns to defend against unseen attacks and\ncan be bootstrapped without labeled data. Given enough interactions with the analyst, the system reaches a performance similar to that obtained when historic attack examples are available."
        },
        {
            "heading": "9 Conclusion",
            "text": "We present an end-to-end system that combines analyst intelligence with state-of-the-art machine learning techniques to detect new attacks and reduce the time elapsed between attack detection and successful prevention. The system presents four key features: a big data behavioral analytics platform,\nk= 50\nk= 10\n0 k=\n20 0\nk= 50\n0 k=\n75 0\nk= 10\n00\nO D\nA L\nO D\nA L\nO D\nA L\nO D\nA L\nO D\nA L\nO D\nA L\nw ee\nk FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr FP\nr T\nPr\n1 0.\n01 3\n0. 13\n3 0.\n01 3\n0. 13\n3 0.\n02 6\n0. 13\n3 0.\n02 6\n0. 13\n3 0.\n05 1\n0. 13\n3 0.\n05 1\n0. 13\n3 0.\n12 9\n0. 33\n3 0.\n12 9\n0. 33\n3 0.\n19 3\n0. 40\n0 0.\n19 3\n0. 40\n0 0.\n25 7\n0. 40\n0 0.\n25 7\n0. 46\n7\n2 0.\n01 3\n0. 17\n4 0.\n01 3\n0. 13\n0 0.\n02 7\n0. 21\n7 0.\n02 7\n0. 30\n4 0.\n05 4\n0. 39\n1 0.\n05 4\n0. 34\n8 0.\n13 5\n0. 65\n2 0.\n13 5\n0. 78\n3 0.\n20 3\n0. 82\n6 0.\n20 3\n0. 87\n0 0.\n27 1\n0. 91\n3 0.\n27 1\n0. 91\n3\n3 0.\n02 0\n0. 03\n7 0.\n02 0\n0. 00\n0 0.\n03 9\n0. 07\n4 0.\n03 9\n0. 11\n1 0.\n07 9\n0. 25\n9 0.\n07 9\n0. 22\n2 0.\n19 7\n0. 63\n0 0.\n19 7\n0. 63\n0 0.\n29 6\n0. 63\n0 0.\n29 6\n0. 85\n2 0.\n39 5\n0. 81\n5 0.\n39 4\n0. 96\n3\n4 0.\n01 3\n0. 00\n0 0.\n01 3\n0. 04\n8 0.\n02 6\n0. 09\n5 0.\n02 6\n0. 14\n3 0.\n05 3\n0. 19\n0 0.\n05 3\n0. 42\n9 0.\n13 3\n0. 28\n6 0.\n13 2\n0. 66\n7 0.\n19 9\n0. 52\n4 0.\n19 9\n0. 71\n4 0.\n26 5\n0. 71\n4 0.\n26 5\n0. 85\n7\n5 0.\n01 2\n0. 04\n8 0.\n01 2\n0. 04\n8 0.\n02 4\n0. 04\n8 0.\n02 4\n0. 28\n6 0.\n04 8\n0. 04\n8 0.\n04 7\n0. 47\n6 0.\n11 9\n0. 42\n9 0.\n11 9\n0. 71\n4 0.\n17 9\n0. 52\n4 0.\n17 9\n0. 81\n0 0.\n23 8\n0. 61\n9 0.\n23 8\n0. 85\n7\n6 0.\n01 3\n0. 04\n2 0.\n01 3\n0. 00\n0 0.\n02 6\n0. 08\n3 0.\n02 6\n0. 29\n2 0.\n05 2\n0. 16\n7 0.\n05 2\n0. 45\n8 0.\n13 0\n0. 25\n0 0.\n13 0\n0. 62\n5 0.\n19 5\n0. 37\n5 0.\n19 5\n0. 66\n7 0.\n26 0\n0. 45\n8 0.\n26 0\n0. 62\n5\n7 0.\n01 2\n0. 16\n0 0.\n01 2\n0. 12\n0 0.\n02 5\n0. 24\n0 0.\n02 4\n0. 52\n0 0.\n05 0\n0. 32\n0 0.\n04 9\n0. 64\n0 0.\n12 4\n0. 56\n0 0.\n12 4\n0. 72\n0 0.\n18 6\n0. 64\n0 0.\n18 6\n0. 80\n0 0.\n24 9\n0. 80\n0 0.\n24 9\n0. 88\n0\n8 0.\n01 3\n0. 07\n4 0.\n01 3\n0. 29\n6 0.\n02 7\n0. 14\n8 0.\n02 6\n0. 66\n7 0.\n05 3\n0. 33\n3 0.\n05 3\n0. 81\n5 0.\n13 4\n0. 44\n4 0.\n13 3\n1. 00\n0 0.\n20 0\n0. 74\n1 0.\n20 0\n1. 00\n0 0.\n26 7\n0. 81\n5 0.\n26 7\n0. 96\n3\n9 0.\n01 3\n0. 22\n6 0.\n01 3\n0. 58\n1 0.\n02 6\n0. 29\n0 0.\n02 6\n0. 67\n7 0.\n05 3\n0. 38\n7 0.\n05 2\n0. 80\n6 0.\n13 2\n0. 67\n7 0.\n13 2\n0. 87\n1 0.\n19 8\n0. 74\n2 0.\n19 8\n0. 87\n1 0.\n26 5\n0. 74\n2 0.\n26 5\n0. 87\n1\n10 0.\n01 3\n0. 10\n0 0.\n01 2\n0. 30\n0 0.\n02 5\n0. 10\n0 0.\n02 5\n0. 63\n3 0.\n05 1\n0. 20\n0 0.\n05 0\n0. 76\n7 0.\n12 7\n0. 50\n0 0.\n12 6\n0. 86\n7 0.\n19 0\n0. 73\n3 0.\n19 0\n0. 93\n3 0.\n25 3\n0. 76\n7 0.\n25 3\n0. 93\n3\n11 0.\n01 4\n0. 08\n3 0.\n01 4\n0. 36\n1 0.\n02 8\n0. 11\n1 0.\n02 8\n0. 55\n6 0.\n05 6\n0. 16\n7 0.\n05 6\n0. 69\n4 0.\n14 1\n0. 30\n6 0.\n14 1\n0. 72\n2 0.\n21 2\n0. 44\n4 0.\n21 2\n0. 80\n6 0.\n28 3\n0. 63\n9 0.\n28 2\n0. 80\n6\n12 0.\n01 1\n0. 02\n6 0.\n01 1\n0. 34\n2 0.\n02 3\n0. 05\n3 0.\n02 2\n0. 63\n2 0.\n04 5\n0. 07\n9 0.\n04 4\n0. 86\n8 0.\n11 3\n0. 28\n9 0.\n11 2\n0. 89\n5 0.\n16 9\n0. 39\n5 0.\n16 8\n0. 92\n1 0.\n22 5\n0. 73\n7 0.\n22 5\n0. 94\n7\nTa bl\ne 2:\nFa ls\ne po\nsi tiv\ne ra\nte (F\nPr )\nan d\ntr ue\npo si\ntiv e\nra te\n(T Pr\n) of\nth e\nA ct\niv e\nM od\nel Sy\nnt he\nsi sa\nnd un\nsu pe\nrv is\ned ou\ntli er\nde te\nct io\nn ov\ner th\ne 12\nw ee\nks of\nde pl\noy m\nen t.\nW e\nre po\nrt th\ne FP\nra nd\nT Pr\nof th\ne co\nm pa\nre d\nap pr\noa ch\nes fo\nrd iff\ner en\ntd ai\nly in\nve st\nig at\nio n\nbu dg\net s\n(k \u2208\n5 0 ,1\n0 0 ,2\n0 0 ,5\n0 0 ,1\n0 0 0)\nan ensemble of outlier detection methods, a mechanism for obtaining feedback from security analysts, and a supervised learning module. We validate our platform with a real-world data set consisting of 3.6 billion log lines. The results show that the system learns to defend against unseen attacks: as time progresses and feedback is collected, the detection rate shows an increasing trend, improving by 3.41\u00d7 with respect to a state-of-the-art unsupervised anomaly detector, and reducing false positives by more than 5\u00d7."
        }
    ],
    "title": "AI : Training a big data machine to defend",
    "year": 2016
}