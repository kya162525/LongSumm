{
    "abstractText": "Computer networks have experienced an explosive growth over the past few years and with that growth have come severe congestion problems. For example, it is now common to see internet gateways drop 10% of the incoming packets because of local buffer overflows. Our investigation of some of these problems has shown that much of the cause lies in transport protocol implementations ( not in the protocols themselves): The \u2018obvious\u2019 ways to implement a window-based transport protocol can result in exactly the wrong behavior in response to network congestion. We give examples of \u2018wrong\u2019 behavior and describe some simple algorithms that can be used to make right things happen. The algorithms are rooted in the idea of achieving network stability by forcing the transport connection to obey a \u2018packet conservation\u2019 principle. We show how the algorithms derive from this principle and what effect they have on traffic over congested networks. In October of \u201986, the Internet had the first of what became a series of \u2018congestion collapses\u2019. During this period, the data throughput from LBL to UC Berkeley (sites separated by 400 yards and two IMP hops) dropped from 32 Kbps to 40 bps. We were fascinated by this sudden factor-of-thousand drop in bandwidth and embarked on an investigation of why things had gotten so bad. In particular, we wondered if the 4.3 BSD (Berkeley UNIX) TCP was mis-behaving or if it could be tuned to work better under abysmal network conditions. The answer to both of these questions was \u201cyes\u201d.",
    "authors": [
        {
            "affiliations": [],
            "name": "Van Jacobson"
        },
        {
            "affiliations": [],
            "name": "Michael J. Karels"
        }
    ],
    "id": "SP:7d43bea23b37194932ffe6f5619d833c7706b7b7",
    "references": [
        {
            "authors": [
                "J. ROMKEY"
            ],
            "title": "A Nonstandard for Transmission of IP Datagrams Over Serial Lines: Slip. ARPANET Working Group Requests for Comment, DDN Network Information Center, SRI International",
            "year": 1988
        },
        {
            "authors": [
                "L. ZHANG"
            ],
            "title": "Why TCP timers don\u2019t work well",
            "venue": "InProceedings of SIGCOMM",
            "year": 1986
        }
    ],
    "sections": [
        {
            "text": "Congestion Avoidance and Control\u2217\nVan Jacobson\u2020 Lawrence Berkeley Laboratory\nMichael J. Karels\u2021 University of California at Berkeley\nNovember, 1988\nIntroduction\nComputer networks have experienced an explosive growth over the past few years and with that growth have come severe congestion problems. For example, it is now common to see internet gateways drop 10% of the incoming packets because of local buffer overflows. Our investigation of some of these problems has shown that much of the cause lies in transport protocol implementations (not in the protocols themselves): The \u2018obvious\u2019 ways to implement a window-based transport protocol can result in exactly the wrong behavior in response to network congestion. We give examples of \u2018wrong\u2019 behavior and describe some simple algorithms that can be used to make right things happen. The algorithms are rooted in the idea of achieving network stability by forcing the transport connection to obey a \u2018packet conservation\u2019 principle. We show how the algorithms derive from this principle and what effect they have on traffic over congested networks.\nIn October of \u201986, the Internet had the first of what became a series of \u2018congestion collapses\u2019. During this period, the data throughput from LBL to UC Berkeley (sites separated by 400 yards and two IMP hops) dropped from 32 Kbps to 40 bps. We were fascinated by this sudden factor-of-thousand drop in bandwidth and embarked on an investigation of why things had gotten so bad. In particular, we wondered if the 4.3BSD (Berkeley UNIX) TCP was mis-behaving or if it could be tuned to work better under abysmal network conditions. The answer to both of these questions was \u201cyes\u201d.\n\u2217Note: This is a very slightly revised version of a paper originally presented at SIGCOMM \u201988 [12]. If you wish to reference this work, please cite [12].\n\u2020This work was supported in part by the U.S. Department of Energy under Contract Number DE-AC0376SF00098.\n\u2021This work was supported by the U.S. Department of Commerce, National Bureau of Standards, under Grant Number 60NANB8D0830.\n1\nSince that time, we have put seven new algorithms into the 4BSD TCP:\n(i) round-trip-time variance estimation\n(ii) exponential retransmit timer backoff\n(iii) slow-start\n(iv) more aggressive receiver ack policy\n(v) dynamic window sizing on congestion\n(vi) Karn\u2019s clamped retransmit backoff\n(vii) fast retransmit\nOur measurements and the reports of beta testers suggest that the final product is fairly good at dealing with congested conditions on the Internet.\nThis paper is a brief description of (i) \u2013 (v) and the rationale behind them. (vi) is an algorithm recently developed by Phil Karn of Bell Communications Research, described in [16]. (vii) is described in a soon-to-be-published RFC (ARP NET \u201cRequest for Comments\u201d).\nAlgorithms (i) \u2013 (v) spring from one observation: The flow on aTCP connection (or ISO TP-4 or XeroxNS SPPconnection) should obey a \u2018conservation of packets\u2019 principle. And, if this principle were obeyed, congestion collapse would become the exception rather than the rule. Thus congestion control involves finding places that violate conservation and fixing them.\nBy \u2018conservation of packets\u2019 we mean that for a connection \u2018in equilibrium\u2019, i.e., running stably with a full window of data in transit, the packet flow is what a physicist would call \u2018conservative\u2019: A new packet isn\u2019t put into the network until an old packet leaves. The physics of flow predicts that systems with this property should be robust in the face of congestion.1 Observation of the Internet suggests that it was not particularly robust. Why the discrepancy? There are only three ways for packet conservation to fail:\n1. The connection doesn\u2019t get to equilibrium, or\n2. A sender injects a new packet before an old packet has exited, or\n3. The equilibrium can\u2019t be reached because of resource limits along the path.\nIn the following sections, we treat each of these in turn."
        },
        {
            "heading": "1 Getting to Equilibrium: Slow-start",
            "text": "Failure (1) has to be from a connection that is either starting or restarting after a packet loss. Another way to look at the conservation property is to say that the sender uses acks as a \u2018clock\u2019 to strobe new packets into the network. Since the receiver can generate acks no\n1A conservative flow means that for any given time, the integral of the packet density around the sender\u2013 receiver\u2013sender loop is a constant. Since packets have to \u2018diffuse\u2019 around this loop, the integral is sufficiently continuous to be a Lyapunov function for the system. A constant function trivially meets the conditions for Lyapunov stability so the system is stable and any superposition of such systems is stable. (See [3], chap. 11\u2013 12 or [21], chap. 9 for excellent introductions to system stability theory.)\nfaster than data packets can get through the network, the protocol is \u2018self clocking\u2019 (fig. 1). Self clocking systems automatically adjust to bandwidth and delay variations and have a wide dynamic range (important considering thatTCP spans a range from 800 Mbps Cray channels to 1200 bps packet radio links). But the same thing that makes a self-clocked system stable when it\u2019s running makes it hard to start \u2014 to get data flowing there must be acks to clock out packets but to get acks there must be data flowing.\nTo start the \u2018clock\u2019, we developed aslow-start algorithm to gradually increase the amount of data in-transit.2 Although we flatter ourselves that the design of this algorithm is rather subtle, the implementation is trivial \u2014 one new state variable and three lines of code in the sender:\n2Slow-start is quite similar to theCUTE algorithm described in [14]. We didn\u2019t know aboutCUTE at the time we were developing slow-start but we should have\u2014CUTE preceded our work by several months.\nWhen describing our algorithm at the Feb., 1987, Internet Engineering Task Force (IETF) meeting, we called it soft-start, a reference to an electronics engineer\u2019s technique to limit in-rush current. The nameslow-startwas coined by John Nagle in a message to the IETF mailing list in March, \u201987. This name was clearly superior to ours and we promptly adopted it.\nis the round-trip-time andW is the window size in packets (fig. 2). This means the window opens quickly enough to have a negligible effect on performance, even on links with a large bandwidth\u2013delay product. And the algorithm guarantees that a connection will source data at a rate at most twice the maximum possible on the path. Without slow-start, by contrast, when 10 Mbps Ethernet hosts talk over the 56 Kbps Arpanet via IP gateways, the\nfirst-hop gateway sees a burst of eight packets delivered at 200 times the path bandwidth. This burst of packets often puts the connection into a persistent failure mode of continuous retransmissions (figures 3 and 4)."
        },
        {
            "heading": "2 Conservation at equilibrium: round-trip timing",
            "text": "Once data is flowing reliably, problems (2) and (3) should be addressed. Assuming that the protocol implementation is correct, (2) must represent a failure of sender\u2019s retransmit timer. A good round trip time estimator, the core of the retransmit timer, is the single most\nimportant feature of any protocol implementation that expects to survive heavy load. And it is frequently botched ([26] and [13] describe typical problems).\nOne mistake is not estimating the variation,\u03c3R, of the round trip time,R. From queuing theory we know thatR and the variation inR increase quickly with load. If the load is\u03c1 (the ratio of average arrival rate to average departure rate),R and\u03c3R scale like(1\u2212\u03c1)\u22121. To make this concrete, if the network is running at 75% of capacity, as the Arpanet was in last April\u2019s collapse, one should expect round-trip-time to vary by a factor of sixteen (\u22122\u03c3 to +2\u03c3).\nTheTCPprotocol specification[2] suggests estimating mean round trip time via the lowpass filter R\u2190 \u03b1R+(1\u2212\u03b1)M whereR is the averageRTT estimate,M is a round trip time measurement from the most recently acked data packet, and\u03b1 is a filter gain constant with a suggested value of 0.9. Once theRestimate is updated, the retransmit timeout interval,rto, for the next packet sent is set to\u03b2R.\nThe parameter\u03b2 accounts forRTT variation (see [5], section 5). The suggested\u03b2 = 2 can adapt to loads of at most 30%. Above this point, a connection will respond to load increases by retransmitting packets that have only been delayed in transit. This forces the network to do useless work, wasting bandwidth on duplicates of packets that will eventually be delivered, at a time when it\u2019s known to be having trouble with useful work. I.e., this is the network equivalent of pouring gasoline on a fire.\nWe developed a cheap method for estimating variation (see appendix A)3 and the resulting retransmit timer essentially eliminates spurious retransmissions. A pleasant side effect of estimating\u03b2 rather than using a fixed value is that low load as well as high load performance improves, particularly over high delay paths such as satellite links (figures 5 and 6).\nAnother timer mistake is in the backoff after a retransmit: If a packet has to be retransmitted more than once, how should the retransmits be spaced? For a transport endpoint embedded in a network of unknown topology and with an unknown, unknowable and constantly changing population of competing conversations, only one scheme has any hope of working\u2014exponential backoff\u2014but a proof of this is beyond the scope of this paper.4\n3We are far from the first to recognize that transport needs to estimate both mean and variation. See, for example, [6]. But we do think our estimator is simpler than most.\n4See [8]. Several authors have shown that backoffs \u2018slower\u2019 than exponential are stable given finite populations and knowledge of the global traffic. However, [17] shows that nothing slower than exponential behavior will work in the general case. To feed your intuition, consider that an IP gateway has essentially the same behavior as the \u2018ether\u2019 in an ALOHA net or Ethernet. Justifying exponential retransmit backoff is the same as\nTo finesse a proof, note that a network is, to a very good approximation, a linear system. That is, it is composed of elements that behave like linear operators \u2014 integrators, delays, gain stages, etc. Linear system theory says that if a system is stable, the stability is exponential. This suggests that an unstable system (a network subject to random load shocks and prone to congestive collapse5) can be stabilized by adding some exponential damping (exponential timer backoff) to its primary excitation (senders, traffic sources)."
        },
        {
            "heading": "3 Adapting to the path: congestion avoidance",
            "text": "If the timers are in good shape, it is possible to state with some confidence that a timeout indicates a lost packet and not a broken timer. At this point, something can be done about (3). Packets get lost for two reasons: they are damaged in transit, or the network is congested and somewhere on the path there was insufficient buffer capacity. On most network paths, loss due to damage is rare ( 1%) so it is probable that a packet loss is due to congestion in the network.6\nshowing that no collision backoff slower than an exponential will guarantee stability on an Ethernet. Unfortunately, with an infinite user population even exponential backoff won\u2019t guarantee stability (although it \u2018almost\u2019 does\u2014see [1]). Fortunately, we don\u2019t (yet) have to deal with an infinite user population.\n5The phrasecongestion collapse(describing a positive feedback instability due to poor retransmit timers) is again the coinage of John Nagle, this time from [23].\n6Because a packet loss empties the window, the throughput of any window flow control protocol is quite sensitive to damage loss. For an RFC793 standard TCP running with windoww (wherew is at most the bandwidth-delay product), a loss probability ofp degrades throughput by a factor of(1+2pw)\u22121. E.g., a 1% damage loss rate on an Arpanet path (8 packet window) degradesTCP throughput by 14%.\nThe congestion control scheme we propose is insensitive to damage loss until the loss rate is on the order of the window equilibration length (the number of packets it takes the window to regain its original size after a loss). If the pre-loss size isw, equilibration takes roughlyw2/3 packets so, for the Arpanet, the loss sensitivity\nA \u2018congestion avoidance\u2019 strategy, such as the one proposed in [15], will have two components: The network must be able to signal the transport endpoints that congestion is occurring (or about to occur). And the endpoints must have a policy that decreases utilization if this signal is received and increases utilization if the signal isn\u2019t received.\nIf packet loss is (almost) always due to congestion and if a timeout is (almost) always due to a lost packet, we have a good candidate for the \u2018network is congested\u2019 signal. Particularly since this signal is delivered automatically by all existing networks, without special modification (as opposed to [15] which requires a new bit in the packet headers and a modification toall existing gateways to set this bit).\nThe other part of a congestion avoidance strategy, the endnode action, is almost identical in the DEC/ISO scheme and ourTCP7 and follows directly from a first-order time-series model of the network:8 Say network load is measured by average queue length over fixed intervals of some appropriate length (something near the round trip time). IfLi is the load at interval i, an uncongested network can be modeled by sayingLi changes slowly compared to the sampling time. I.e.,\nLi = N\n(N constant). If the network is subject to congestion, this zeroth order model breaks down. The average queue length becomes the sum of two terms, theN above that accounts for the average arrival rate of new traffic and intrinsic delay, and a new term that accounts for the fraction of traffic left over from the last time interval and the effect of this left-over traffic (e.g., induced retransmits):\nLi = N+ \u03b3Li\u22121\n(These are the first two terms in a Taylor series expansion ofL(t). There is reason to believe one might eventually need a three term, second order model, but not until the Internet has grown substantially.)\nWhen the network is congested,\u03b3 must be large and the queue lengths will start increasing exponentially.9 The system will stabilize only if the traffic sources throttle back at least as quickly as the queues are growing. Since a source controls load in a window-based protocol by adjusting the size of the window,W, we end up with the sender policy\nOn congestion: Wi = dWi\u22121 (d < 1)\nI.e., a multiplicative decrease of the window size (which becomes an exponential decrease over time if the congestion persists).\nthreshold is about 5%. At this high loss rate, the empty window effect described above has already degraded throughput by 44% and the additional degradation from the congestion avoidance window shrinking is the least of one\u2019s problems.\nWe are concerned that the congestion control noise sensitivity is quadratic inw but it will take at least another generation of network evolution to reach window sizes where this will be significant. If experience shows this sensitivity to be a liability, a trivial modification to the algorithm makes it linear inw. An in-progress paper explores this subject in detail.\n7This is not an accident: We copied Jain\u2019s scheme after hearing his presentation at [10] and realizing that the scheme was, in a sense, universal.\n8See any good control theory text for the relationship between a system model and admissible controls for that system. A nice introduction appears in [21], chap. 8.\n9I.e., the system behaves likeLi \u2248 \u03b3Li\u22121, a difference equation with the solution Ln = \u03b3nL0\nwhich goes exponentially to infinity for any\u03b3 > 1.\nIf there\u2019s no congestion,\u03b3 must be near zero and the load approximately constant. The network announces, via a dropped packet, when demand is excessive but says nothing if a connection is using less than its fair share (since the network is stateless, it cannot know this). Thus a connection has to increase its bandwidth utilization to find out the current limit. E.g., you could have been sharing the path with someone else and converged to a window that gives you each half the available bandwidth. If she shuts down, 50% of the bandwidth will be wasted unless your window size is increased. What should the increase policy be?\nThe first thought is to use a symmetric, multiplicative increase, possibly with a longer time constant,Wi = bWi\u22121, 1 < b\u2264 1/d. This is a mistake. The result will oscillate wildly and, on the average, deliver poor throughput. The analytic reason for this has to do with that fact that it is easy to drive the net into saturation but hard for the net to recover (what [18], chap. 2.1, calls therush-hour effect).10 Thus overestimating the available bandwidth is costly. But an exponential, almost regardless of its time constant, increases so quickly that overestimates are inevitable.\nWithout justification, we\u2019ll state that the best increase policy is to make small, constant changes to the window size:11\nOn no congestion: Wi = Wi\u22121 +u (u Wmax)\nwhereWmax is thepipesize(the delay-bandwidth product of the path minus protocol overhead \u2014 i.e., the largest sensible window for the unloaded path). This is the additive increase / multiplicative decrease policy suggested in [15] and the policy we\u2019ve implemented inTCP. The only difference between the two implementations is the choice of constants ford andu. We used 0.5 and 1 for reasons partially explained in appendix D. A more complete analysis is in yet another in-progress paper.\nThe preceding has probably made the congestion control algorithm sound hairy but it\u2019s not. Like slow-start, it\u2019s three lines of code:\n\u2022 On any timeout, setcwnd to half the current window size (this is the multiplicative decrease).\n\u2022 On each ack for new data, increasecwndby 1/cwnd(this is the additive increase).12 10In fig. 1, note that the \u2018pipesize\u2019 is 16 packets, 8 in each path, but the sender is using a window of 22\npackets. The six excess packets will form a queue at the entry to the bottleneck andthat queue cannot shrink, even though the sender carefully clocks out packets at the bottleneck link rate. This stable queue is another, unfortunate, aspect of conservation: The queue would shrink only if the gateway could move packets into the skinny pipe faster than the sender dumped packets into the fat pipe. But the system tunes itself so each time the gateway pulls a packet off the front of its queue, the sender lays a new packet on the end.\nA gateway needs excess output capacity (i.e.,\u03c1 < 1) to dissipate a queue and the clearing time will scale like (1\u2212\u03c1)\u22122 ([18], chap. 2 is an excellent discussion of this). Since at equilibrium our transport connection \u2018wants\u2019 to run the bottleneck link at 100% (\u03c1 = 1), we have to be sure that during the non-equilibrium window adjustment, our control policy allows the gateway enough free bandwidth to dissipate queues that inevitably form due to path testing and traffic fluctuations. By an argument similar to the one used to show exponential timer backoff is necessary, it\u2019s possible to show that an exponential (multiplicative) window increase policy will be \u2018faster\u2019 than the dissipation time for some traffic mix and, thus, leads to an unbounded growth of the bottleneck queue.\n11See [4] for a complete analysis of these increase and decrease policies. Also see [8] and [9] for a controltheoretic analysis of a similar class of control policies.\n12This increment rule may be less than obvious. We want to increase the window by at most one packet over a time interval of lengthR (the round trip time). To make the algorithm \u2018self-clocked\u2019, it\u2019s better to increment by a small amount on each ack rather than by a large amount at the end of the interval. (Assuming, of course,\n\u2022 When sending, send the minimum of the receiver\u2019s advertised window andcw . Note that this algorithm isonly congestion avoidance, it doesn\u2019t include the previously described slow-start. Since the packet loss that signals congestion will result in a re-start, it will almost certainly be necessary to slow-start in addition to the above. But, because both congestion avoidance and slow-start are triggered by a timeout and both manipulate the congestion window, they are frequently confused. They are actually independent algorithms with completely different objectives. To emphasize the difference, the two algorithms have been presented separately even though in practise they should be implemented together. Appendix B describes a combined slow-start/congestion avoidance algorithm.13\nFigures 7 through 12 show the behavior ofTCPconnections with and without congestion avoidance. Although the test conditions (e.g., 16 KB windows) were deliberately chosen to stimulate congestion, the test scenario isn\u2019t far from common practice: The ArpanetIMP end-to-end protocol allows at most eight packets in transit between any pair of gateways. The default 4.3BSD window size is eight packets (4 KB). Thus simultaneous conversations between, say, any two hosts at Berkeley and any two hosts atMIT would exceed the network capacity of theUCB\u2013MIT IMP path and would lead14 to the type of behavior shown."
        },
        {
            "heading": "4 Future work: the gateway side of congestion control",
            "text": "While algorithms at the transport endpoints can insure the network capacity isn\u2019t exceeded, they cannot insure fair sharing of that capacity. Only in gateways, at the convergence of flows, is there enough information to control sharing and fair allocation. Thus, we view the gateway \u2018congestion detection\u2019 algorithm as the next big step.\nthe sender has effectivesilly windowavoidance (see [5], section 3) and doesn\u2019t attempt to send packet fragments because of the fractionally sized window.) A window of sizecwndpackets will generate at mostcwndacks in oneR. Thus an increment of 1/cwndper ack will increase the window by at most one packet in oneR. In TCP, windows and packet sizes are in bytes so the increment translates tomaxseg*maxseg/cwndwheremaxsegis the maximum segment size andcwndis expressed in bytes, not packets.\n13We have also developed a rate-based variant of the congestion avoidance algorithm to apply to connectionless traffic (e.g., domain server queries,RPCrequests). Remembering that the goal of the increase and decrease policies is bandwidth adjustment, and that \u2018time\u2019 (the controlled parameter in a rate-based scheme) appears in the denominator of bandwidth, the algorithm follows immediately: The multiplicative decrease remains a multiplicative decrease (e.g., double the interval between packets). But subtracting a constant amount from interval doesnot result in an additive increase in bandwidth. This approach has been tried, e.g., [19] and [24], and appears to oscillate badly. To see why, note that for an inter-packet intervalI and decrementc, the bandwidth change of a decrease-interval-by-constant policy is\n1 I \u2192 1\nI \u2212c a non-linear, and destablizing, increase.\nAn update policy that does result in a linear increase of bandwidth over time is\nIi = \u03b1Ii\u22121\n\u03b1+ Ii\u22121\nwhereIi is the interval between sends when theith packet is sent and\u03b1 is the desired rate of increase in packets per packet/sec.\nWe have simulated the above algorithm and it appears to perform well. To test the predictions of that simulation against reality, we have a cooperative project with Sun Microsystems to prototypeRPCdynamic congestion control algorithms usingNFS as a test-bed (sinceNFS is known to have congestion problems yet it would be desirable to have it work over the same range of networks asTCP).\n14did lead.\nThe goal of this algorithm to send a signal to the endnodes as early as possible, but not so early that the gateway becomes starved for traffic. Since we plan to continue using packet drops as a congestion signal, gateway \u2018self protection\u2019 from a mis-behaving host should fall-out for free: That host will simply have most of its packets dropped as the gateway trys to tell it that it\u2019s using more than its fair share. Thus, like the endnode algorithm, the gateway algorithm should reduce congestion even if no endnode is modified to do congestion avoidance. And nodes that do implement congestion avoidance will get their fair share of bandwidth and a minimum number of packet drops.\nSince congestion grows exponentially, detecting it early is important. If detected early, small adjustments to the senders\u2019 windows will cure it. Otherwise massive adjustments are necessary to give the net enough spare capacity to pump out the backlog. But, given the bursty nature of traffic, reliable detection is a non-trivial problem. Jain[15] proposes a scheme based on averaging between queue regeneration points. This should yield good burst filtering but we think it might have convergence problems under high load or significant second-order dynamics in the traffic.15 We plan to use some of our earlier work on ARMAX models for round-trip-time/queue length prediction as the basis of detection.\n15These problems stem from the fact that the average time between regeneration points scales like(1\u2212\u03c1)\u22121 and the variance like(1\u2212\u03c1)\u22123 (see Feller[7], chap. VI.9). Thus the congestion detector becomes sluggish as congestion increases and its signal-to-noise ratio decreases dramatically.\nPreliminary results suggest that this approach works well at high load, is immune to secondorder effects in the traffic and is computationally cheap enough to not slow down kilopacketper-second gateways."
        },
        {
            "heading": "Acknowledgements",
            "text": "We are grateful to the members of the Internet Activity Board\u2019s End-to-End and InternetEngineering task forces for this past year\u2019s interest, encouragement, cogent questions and network insights. Bob Braden of ISI and Craig Partridge of BBN were particularly helpful in the preparation of this paper: their careful reading of early drafts improved it immensely.\nThe first author is also deeply in debt to Jeff Mogul of DEC Western Research Lab. Without Jeff\u2019s interest and patient prodding, this paper would never have existed."
        },
        {
            "heading": "A A fast algorithm for rtt mean and variation",
            "text": "A.1 Theory\nThe RFC793 algorithm for estimating the mean round trip time is one of the simplest examples of a class of estimators calledr cursive prediction erroror stochastic gradient algorithms. In the past 20 years these algorithms have revolutionized estimation and control theory [20] and it\u2019s probably worth looking at the RFC793 estimator in some detail.\nGiven a new measurementm of the RTT (round trip time),TCP updates an estimate of the averageRTT a by a\u2190 (1\u2212g)a+gm whereg is a \u2018gain\u2019 (0< g < 1) that should be related to the signal-to-noise ratio (or, equivalently, variance) ofm. This makes a more sense, and computes faster, if we rearrange and collect terms multiplied byg to get\na\u2190 a+g(m\u2212a)\nThink of a as a prediction of the next measurement.m\u2212 a is the error in that prediction and the expression above says we make a new prediction based on the old prediction plus some fraction of the prediction error. The prediction error is the sum of two components: (1) error due to \u2018noise\u2019 in the measurement (random, unpredictable effects like fluctuations in competing traffic) and (2) error due to a bad choice ofa. Calling the random errorEr and the estimation errorEe, a\u2190 a+gEr +gEe The gEe term givesa a kick in the right direction while thegEr term gives it a kick in a random direction. Over a number of samples, the random kicks cancel each other out so this algorithm tends to converge to the correct average. Butg represents a compromise: We want a largeg to get mileage out ofEe but a smallg to minimize the damage fromEr . Since theEe terms movea toward the real average no matter what value we use forg, it\u2019s almost always better to use a gain that\u2019s too small rather than one that\u2019s too large. Typical gain choices are 0.1\u20130.2 (though it\u2019s a good idea to take long look at your raw data before picking a gain).\nIt\u2019s probably obvious thata will oscillate randomly around the true average and the standard deviation ofa will be gsdev(m). Also thata converges to the true average exponentially with time constant 1/g. So a smallerg gives a stablera at the expense of taking a much longer time to get to the true average.\nIf we want some measure of the variation inm, say to compute a good value for the TCP retransmit timer, there are several alternatives. Variance,\u03c32, is the conventional choice because it has some nice mathematical properties. But computing variance requires squaring (m\u2212a) so an estimator for it will contain a multiply with a danger of integer overflow. Also, most applications will want variation in the same units asa ndm, so we\u2019ll be forced to take the square root of the variance to use it (i.e., at least a divide, multiply and two adds).\nA variation measure that\u2019s easy to compute is the mean prediction error or mean deviation, the average of|m\u2212a|. Also, since\nmdev2 = ( \u2211 |m\u2212a| )2 \u2265 \u2211 |m\u2212a|2 = \u03c32\nmean deviation is a more conservative (i.e., larger) estimate of variation than standard deviation.16\nThere\u2019s often a simple relation between mdev and sdev. E.g., if the prediction errors are normally distributed,mdev= \u221a \u03c0/2sdev. For most common distributions the factor to go from sdevto mdevis near one ( \u221a\n\u03c0/2\u2248 1.25). I.e.,mdevis a good approximation ofsdev and is much easier to compute.\nA.2 Practice\nFast estimators for averagea and mean deviationv given measurementm follow directly from the above. Both estimators compute means so there are two instances of the RFC793 algorithm:\nErr \u2261m\u2212a a\u2190 a+gErr\nv\u2190 v+g(|Err|\u2212v) To be computed quickly, the above should be done in integer arithmetic. But the ex-\npressions contain fractions (g < 1) so some scaling is needed to keep everything integer. A reciprocal power of 2 (i.e.,g = 1/2n for somen) is a particularly good choice forg since the scaling can be implemented with shifts. Multiplying through by 1/g gives\n2na\u2190 2na+Err 2nv\u2190 2nv+(|Err|\u2212v)\nTo minimize round-off error, the scaled versions ofa and v, sa and sv, should be kept rather than the unscaled versions. Pickingg = .125= 18 (close to the .1 suggested in RFC793) and expressing the above in C:\n/\u2217 update Average estimator\u2217/ m \u2212= (sa >> 3); sa += m; /\u2217 update Deviation estimator\u2217/ if (m < 0) m = \u2212m; m \u2212= (sv >> 3); sv += m;\nIt\u2019s not necessary to use the same gain fora andv. To force the timer to go up quickly in response to changes in theRTT, it\u2019s a good idea to givev a larger gain. In particular, because of window\u2013delay mismatch there are oftenRTT artifacts at integer multiples of the window size.17 To filter these, one would like 1/g in thea estimator to be at least as large as the window size (in packets) and 1/g in thev estimator to be less than the window size.18\n16Purists may note that we elided a factor of 1/n, the number of samples, from the previous inequality. It makes no difference to the result.\n17E.g., see packets 10\u201350 of figure 5. Note that these window effects are due to characteristics of the Arpa/Milnet subnet. In general, window effects on the timer are at most a second-order consideration and depend a great deal on the underlying network. E.g., if one were using the Wideband with a 256 packet window, 1/256 would not be a good gain fora (1/16 might be).\n18Although it may not be obvious, the absolute value in the calculation ofv introduces an asymmetry in the timer: Becausev has the same sign as an increase and the opposite sign of a decrease, more gain inv m kes the\nUsing a gain of .25 on the deviation and computing the retransmit timer,rto, asa+4v, the final timer code looks like:\nm \u2212= (sa >> 3); sa += m; if (m < 0) m = \u2212m; m \u2212= (sv >> 2); sv += m; rto = (sa >> 3) + sv;\nIn general this computation will correctly roundrto: Because of thesa truncation when computingm\u2212a, sawill converge to the true mean rounded up to the next tick. Likewise with sv. Thus, on the average, there is half a tick of bias in each. Therto computation should be rounded by half a tick and one tick needs to be added to account for sends being phased randomly with respect to the clock. So, the 1.75 tick bias contribution from 4v approximately equals the desired half tick rounding plus one tick phase correction."
        },
        {
            "heading": "B The combined slow-start with congestion avoidance algorithm",
            "text": "The sender keeps two state variables for congestion control: a slow-start/congestion window, cwnd, and a threshold size,ssthresh, to switch between the two algorithms. The sender\u2019s output routine always sends the minimum ofcwndand the window advertised by the receiver. On a timeout, half the current window size is recorded inssthresh(this is the multiplicative decrease part of the congestion avoidance algorithm), thencwnd is set to 1 packet (this initiates slow-start). When new data is acked, the sender does\nif (cwnd < ssthresh) /\u2217 if we\u2019re still doing slow\u2212start \u2217 open window exponentially\u2217/ cwnd += 1; else\n/\u2217 otherwise do Congestion \u2217 Avoidance increment\u2212by\u22121 \u2217/ cwnd += 1/cwnd;\nThus slow-start opens the window quickly to what congestion avoidance thinks is a safe operating point (half the window that got us into trouble), then congestion avoidance takes over and slowly increases the window size to probe for more bandwidth becoming available on the path.\nNote that theelseclause of the above code will malfunction ifcwnd is an integer in unscaled, one-packet units. I.e., if the maximum window for the path isw packets,cwnd\ntimer go up quickly and come down slowly, \u2018automatically\u2019 giving the behavior suggested in [22]. E.g., see the region between packets 50 and 80 in figure 6.\nmust cover the range 0..w with resolution of at least 1/w.19 Since sending packets smaller than the maximum transmission unit for the path lowers efficiency, the implementor must take care that the fractionally sizedcwnddoesnot result in small packets being sent. In reasonableTCP implementations, existing silly-window avoidance code should prevent runt packets but this point should be carefully checked.\nC Interaction of window adjustment with round-trip timing\nSomeTCP connections, particularly those over a very low speed link such as a dial-up SLIP line[25], may experience an unfortunate interaction between congestion window adjustment and retransmit timing: Network paths tend to divide into two classes:delay-dominated, where the store-and-forward and/or transit delays determine theRTT, andbandwidth-dominated, where (bottleneck) link bandwidth and average packet size determine theRTT.20 On a bandwidth-dominated path of bandwidthb, a congestion-avoidance window increment of \u2206w will increase theRTT of post-increment packets by\n\u2206R\u2248 \u2206w b\nIf the pathRTT variationV is small,\u2206R may exceed the 4V cushion inrto, a retransmit timeout will occur and, after a few cycles of this,ssthresh(and, thus,cwnd) end up clamped at small values.\nTherto calculation in appendix A was designed to prevent this type of spurious retransmission timeout during slow-start. In particular, theRTT variationV is multiplied by four in therto calculation because of the following: A spurious retransmit occurs if the retransmit timeout computed at the end of slow-start roundi, rtoi , is ever less than or equal to the actualRTT of the next round. In the worst case of all the delay being due the window, R doubles each round (since the window size doubles). ThusRi+1 = 2Ri (whereRi is the measuredRTT at slow-start roundi). But\nVi = Ri\u2212Ri\u22121 = Ri/2\nand\nrtoi = Ri +4Vi = 3Ri > 2Ri > Ri+1\nso spurious retransmit timeouts cannot occur.21\n19For TCP this happens automatically since windows are expressed in bytes, not packets. For protocols such as ISO TP4, the implementor should scalewndso that the calculations above can be done with integer arithmetic and the scale factor should be large enough to avoid the fixed point (zero) ofb1/cwndc in the congestion avoidance increment.\n20E.g., TCP over a 2400 baud packet radio link is bandwidth-dominated since the transmission time for a (typical) 576 byte IP packet is 2.4 seconds, longer than any possible terrestrial transit delay.\n21The original SIGCOMM \u201988 version of this paper suggested calculatingrto asR+ 2V rather thanR+ 4V. Since that time we have had much more experience with low speed SLIP links and observed spurious retransmissions during connection startup. An investigation of why these occured led to the analysis above and the change to therto calculation in app. A.\nSpurious retransmission due to a window increase can occur during the congestion avoidance window increment since the window can only be changed in one packet increments so, for a packet sizes, there may be as many ass\u22121 packets between increments, long enough for anyV increase due to the last window increment to decay away to nothing. But this problem is unlikely on a bandwidth-dominated path since the increments would have to be more than twelve packets apart (the decay time of theV filt r times its gain in the rto calculation) which implies that a ridiculously large window is being used for the path.22 Thus one should regard these timeouts as appropriate punishment for gross mis-tuning and their effect will simply be to reduce the window to something more appropriate for the path.\nAlthough slow-start and congestion avoidance are designed to not trigger this kind of spurious retransmission, an interaction with higher level protocols frequently does: Application protocols likeSMTP andNNTP have a \u2018negotiation\u2019 phase where a few packets are exchanged stop-and-wait, followed by data transfer phase where all of a mail message or news article is sent. Unfortunately, the \u2018negotiation\u2019 exchanges open the congestion window so the start of the data transfer phase will dump several packets into the network with no slow-start and, on a bandwidth-dominated path, faster thanrto can track theRTT increase caused by these packets. The root cause of this problem is the same one described in sec. 1: dumping too many packets into an empty pipe (the pipe is empty since the negotiation exchange was conducted stop-and-wait) with no ack \u2018clock\u2019. The fix proposed in sec. 1, slow-start, will also prevent this problem if theTCP implementation can detect the phase change. And detection is simple: The pipe is empty because we haven\u2019t sent anything for at least a round-trip-time (another way to viewRTT is as the time it takes the pipe to empty after the most recent send). So, if nothing has been sent for at least oneRTT, the next send should setcwnd to one packet to force a slow-start. I.e., if the connection state variablelastsndholds the time the last packet was sent, the following code should appear early in theTCP output routine:\nint idle = (snd max == snduna); if (idle && now \u2212 lastsnd> rto)\ncwnd = 1;\nThe booleanidle is true if there is no data in transit (all data sent has been acked) so theif says \u201cif there\u2019s nothing in transit and we haven\u2019t sent anything for \u2018a long time\u2019, slow-start.\u201d Our experience has been that either the currentRTT estimate or therto estimate can be used for \u2018a long time\u2019 with good results23"
        },
        {
            "heading": "D Window Adjustment Policy",
            "text": "A reason for using12 as a the decrease term, as opposed to the 7 8 in [15], was the following handwaving: When a packet is dropped, you\u2019re either starting (or restarting after a drop) or steady-state sending. If you\u2019re starting, you know that half the current window size \u2018worked\u2019, i.e., that a window\u2019s worth of packets were exchanged with no drops (slowstart guarantees this). Thus on congestion you set the window to the largest size that you know works then slowly increase the size. If the connection is steady-state running and\n22The the largest sensible window for a path is the bottleneck bandwidth times the round-trip delay and, by definition, the delay is negligible for a bandwidth-dominated path so the window should only be a few packets.\n23Therto estimate is more convenient since it is kept in units of time whileRTT is scaled.\na packet is dropped, it\u2019s probably because a new connection started up and took some of your bandwidth. We usually run our nets with\u03c1 \u2264 0.5 so it\u2019s probable that there are now exactly two conversations sharing the bandwidth. I.e., you should reduce your window by half because the bandwidth available to you has been reduced by half. And, if there are more than two conversations sharing the bandwidth, halving your window is conservative \u2014 and being conservative at high traffic intensities is probably wise.\nAlthough a factor of two change in window size seems a large performance penalty, in system terms the cost is negligible: Currently, packets are dropped only when a large queue has formed. Even with the ISO IP \u2018congestion experienced\u2019 bit [11] to force senders to reduce their windows, we\u2019re stuck with the queue because the bottleneck is running at 100% utilization with no excess bandwidth available to dissipate the queue. If a packet is tossed, some sender shuts up for twoRTT, exactly the time needed to empty the queue. If that sender restarts with the correct window size, the queue won\u2019t reform. Thus the delay has been reduced to minimum without the system losing any bottleneck bandwidth.\nThe 1-packet increase has less justification than the 0.5 decrease. In fact, it\u2019s almost certainly too large. If the algorithm converges to a window size ofw, there areO(w2) packets between drops with an additive increase policy. We were shooting for an average drop rate of<1% and found that on the Arpanet (the worst case of the four networks we tested), windows converged to 8\u201312 packets. This yields 1 packet increments for a 1% average drop rate.\nBut, since we\u2019ve done nothing in the gateways, the window we converge to is the maximum the gateway can accept without dropping packets. I.e., in the terms of [15], we are just to the left of the cliff rather than just to the right of the knee. If the gateways are fixed so they start dropping packets when the queue gets pushed past the knee, our increment will be much too aggressive and should be dropped by about a factor of four (since our measurements on an unloaded Arpanet place its \u2018pipe size\u2019 at 4\u20135 packets). It appears trivial to implement a second order control loop to adaptively determine the appropriate increment to use for a path. But second order problems are on hold until we\u2019ve spent some time on the first order part of the algorithm for the gateways."
        }
    ],
    "year": 1998
}