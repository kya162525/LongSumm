{
    "abstractText": "Users of today\u2019s popular wide-area apps (e.g., Twitter, Google Docs, and Words with Friends) must no longer save and reload when updating shared data; instead, these applications are reactive, providing the illusion of continuous synchronization across mobile devices and the cloud. Achieving this illusion poses a complex distributed data management problem for programmers. This paper presents the first reactive data management service, called Diamond, which provides persistent cloud storage, reliable synchronization between storage and mobile devices, and automated execution of application code in response to shared data updates. We demonstrate that Diamond greatly simplifies the design of reactive applications, strengthens distributed data sharing guarantees, and supports automated reactivity with low performance overhead.",
    "authors": [
        {
            "affiliations": [],
            "name": "Irene Zhang"
        },
        {
            "affiliations": [],
            "name": "Niel Lebeck"
        },
        {
            "affiliations": [],
            "name": "Pedro Fonseca"
        },
        {
            "affiliations": [],
            "name": "Brandon Holt"
        },
        {
            "affiliations": [],
            "name": "Raymond Cheng"
        },
        {
            "affiliations": [],
            "name": "Ariadna Norberg"
        },
        {
            "affiliations": [],
            "name": "Arvind Krishnamurthy"
        },
        {
            "affiliations": [],
            "name": "Henry M. Levy"
        }
    ],
    "id": "SP:d004bf95e7f6c418e3de123cd1e66ad658cb0a91",
    "references": [
        {
            "authors": [
                "D. Abrahams",
                "S. Seefeld"
            ],
            "title": "http://www.boost.org/doc/libs/1 60 0/libs/python/ doc/html/index.html",
            "venue": "Boost C++ libraries,",
            "year": 2015
        },
        {
            "authors": [
                "A. Adya",
                "G. Cooper",
                "D. Myers",
                "M. Piatek"
            ],
            "title": "Thialfi: a client notification service for internet-scale applications",
            "venue": "Proc. of SOSP,",
            "year": 2011
        },
        {
            "authors": [
                "S. Alvos-Bock"
            ],
            "title": "The convergence of iOS and OSX user interface",
            "year": 2015
        },
        {
            "authors": [
                "K. Apt"
            ],
            "title": "Principles of Constraint Programming",
            "venue": "Cambridge University Press,",
            "year": 2003
        },
        {
            "authors": [
                "J. Baker",
                "C. Bond",
                "J.C. Corbett",
                "J. Furman",
                "A. Khorlin",
                "J. Larson",
                "J.-M. Leon",
                "Y. Li",
                "A. Lloyd",
                "V. Yushprakh"
            ],
            "title": "Megastore: Providing scalable, highly available storage for interactive services",
            "venue": "Proc. of CIDR,",
            "year": 2011
        },
        {
            "authors": [
                "N.M. Belaramani",
                "J. Zheng",
                "A. Nayate",
                "R. Soul\u00e9",
                "M. Dahlin",
                "R. Grimm"
            ],
            "title": "PADS: A policy architecture for distributed storage systems",
            "venue": "Proc. of NSDI,",
            "year": 2009
        },
        {
            "authors": [
                "J.K. Bennett",
                "J.B. Carter",
                "W. Zwaenepoel"
            ],
            "title": "Munin: Distributed shared memory based on type-specific memory coherence",
            "venue": "Proc. of PPOPP,",
            "year": 1990
        },
        {
            "authors": [
                "P.A. Bernstein",
                "V. Hadzilacos",
                "N. Goodman"
            ],
            "title": "Concurrency Control and Recovery in Database Systems",
            "venue": "Addison Wesley,",
            "year": 1987
        },
        {
            "authors": [
                "J.A. Blakeley",
                "P.-A. Larson",
                "F.W. Tompa"
            ],
            "title": "Efficiently updating materialized views",
            "venue": "Proc. of SIGMOD,",
            "year": 1986
        },
        {
            "authors": [
                "J. Callaham"
            ],
            "title": "Yes, windows 10 is the next version of windows phone",
            "venue": "Windows Central, Sept",
            "year": 2014
        },
        {
            "authors": [
                "S. Chakravarthy"
            ],
            "title": "Sentinel: an object-oriented DBMS with event-based rules",
            "venue": "Proc. of SIGMOD,",
            "year": 1997
        },
        {
            "authors": [
                "F. Chang",
                "J. Dean",
                "S. Ghemawat",
                "W.C. Hsieh",
                "D.A. Wallach",
                "M. Burrows",
                "T. Chandra",
                "A. Fikes",
                "R.E. Gruber"
            ],
            "title": "Bigtable: A distributed storage system for structured data",
            "venue": "ACM Transactions on Computer Systems,",
            "year": 2008
        },
        {
            "authors": [
                "J.C. Corbett",
                "J. Dean",
                "M. Epstein",
                "A. Fikes",
                "C. Frost",
                "J.J. Furman",
                "S. Ghemawat",
                "A. Gubarev",
                "C. Heiser",
                "P. Hochschild",
                "W. Hsieh",
                "S. Kanthak",
                "E. Kogan",
                "H. Li",
                "A. Lloyd",
                "S. Melnik",
                "D. Mwaura",
                "D. Nagle",
                "S. Quinlan",
                "R. Rao",
                "L. Rolig",
                "Y. Saito",
                "M. Szymaniak",
                "C. Taylor",
                "R. Wang",
                "D. Woodford"
            ],
            "title": "Spanner: Google\u2019s globallydistributed database",
            "venue": "Proc. of OSDI,",
            "year": 2012
        },
        {
            "authors": [
                "M. Dahlin",
                "L. Gao",
                "A. Nayate",
                "A. Venkataramana",
                "P. Yalagandula",
                "J. Zheng"
            ],
            "title": "PRACTI replication",
            "venue": "Proc. of NSDI,",
            "year": 2006
        },
        {
            "authors": [
                "G. DeCandia",
                "D. Hastorun",
                "M. Jampani",
                "G. Kakulapati",
                "A. Lakshman",
                "A. Pilchin",
                "S. Sivasubramanian",
                "P. Vosshall",
                "W. Vogels"
            ],
            "title": "Dynamo: Amazon\u2019s highly available keyvalue store",
            "venue": "Proc. of SOSP,",
            "year": 2007
        },
        {
            "authors": [
                "R.T. Fielding"
            ],
            "title": "Architectural Styles and the Design of Network-based Software Architectures",
            "venue": "PhD thesis, University of California, Irvine,",
            "year": 2000
        },
        {
            "authors": [
                "M. Herlihy"
            ],
            "title": "Optimistic concurrency control for abstract data types",
            "venue": "Proc. of PODC. ACM,",
            "year": 1986
        },
        {
            "authors": [
                "M. Herlihy"
            ],
            "title": "Apologizing versus asking permission: Optimistic concurrency control for abstract data types",
            "venue": "ACM Transactions on Database Systems,",
            "year": 1990
        },
        {
            "authors": [
                "N. Herman",
                "J.P. Inala",
                "Y. Huang",
                "L. Tsai",
                "E. Kohler",
                "B. Liskov",
                "L. Shrira"
            ],
            "title": "Type-aware transactions for faster concurrent code",
            "venue": "eurosys,",
            "year": 2016
        },
        {
            "authors": [
                "T. Hoff"
            ],
            "title": "Playfish\u2019s social gaming architecture - 50 million monthly users and growing",
            "venue": "High Scalability, Sept",
            "year": 2010
        },
        {
            "authors": [
                "T. Hoff"
            ],
            "title": "The architecture that Twitter uses to deal with 150m active users, 300k qps, a 22 mb/s firehose, and send tweets in under 5 seconds",
            "venue": "High Scalability, July",
            "year": 2013
        },
        {
            "authors": [
                "M. Humphries"
            ],
            "title": "Ellen DeGeneres crashes",
            "venue": "Twitter with Oscar selfie,",
            "year": 2014
        },
        {
            "authors": [
                "R.K. Jonas Boner",
                "Dave Farley",
                "M. Thompson"
            ],
            "title": "The reactive manifesto",
            "venue": "Sept 2014. http://www.reactivemanifesto. org/",
            "year": 2014
        },
        {
            "authors": [
                "J.J. Kistler",
                "M. Satyanarayanan"
            ],
            "title": "Disconnected operation in the coda file system",
            "venue": "ACM Transactions on Computer Systems,",
            "year": 1992
        },
        {
            "authors": [
                "T. Kraska",
                "G. Pang",
                "M.J. Franklin",
                "S. Madden",
                "A. Fekete"
            ],
            "title": "MDCC: multi-data center consistency",
            "venue": "Proc. of EuroSys,",
            "year": 2013
        },
        {
            "authors": [
                "A. Lakshman",
                "P. Malik"
            ],
            "title": "Cassandra: A decentralized structured storage system",
            "venue": "ACM SIGOPS Operating Systems Review,",
            "year": 2010
        },
        {
            "authors": [
                "K. Li",
                "P. Hudak"
            ],
            "title": "Memory coherence in shared virtual memory systems",
            "venue": "ACM Transactions on Computer Systems,",
            "year": 1989
        },
        {
            "authors": [
                "B.F. Lieuwen",
                "N. Gehani",
                "R. Arlein"
            ],
            "title": "The Ode active database: trigger semantics and implementation",
            "venue": "Proc. of ICDE, Feb",
            "year": 1996
        },
        {
            "authors": [
                "A. Margara",
                "G. Salvaneschi"
            ],
            "title": "We have a DREAM: Distributed reactive programming with consistency guarantees",
            "venue": "Proc. of DEBS. ACM,",
            "year": 2014
        },
        {
            "authors": [
                "M. Mode"
            ],
            "title": "New mobile apps revolutionize how organizations respond to crises and operations issues, Aug 2014. http://www.missionmode.com/new-mobile-appsrevolutionize-organizations-respond-crises-operationsissues",
            "year": 2014
        },
        {
            "authors": [
                "I. Moraru",
                "D.G. Andersen",
                "M. Kaminsky"
            ],
            "title": "There is more consensus in egalitarian parliaments",
            "venue": "Proc. of SOSP,",
            "year": 2013
        },
        {
            "authors": [
                "R. Mulia"
            ],
            "title": "Firebase - maintain/guarantee consistency",
            "venue": "Stack Overflow, Jan",
            "year": 2016
        },
        {
            "authors": [
                "A. Muthitacharoen",
                "B. Chen",
                "D. Mazi\u00e8res"
            ],
            "title": "A lowbandwidth network file system",
            "venue": "Proc. of SOSP,",
            "year": 2001
        },
        {
            "authors": [
                "B.M. Oki",
                "B.H. Liskov"
            ],
            "title": "Viewstamped replication: A new primary copy method to support highly-available distributed systems",
            "venue": "Proc. of PODC,",
            "year": 1988
        },
        {
            "authors": [
                "D. Perkins",
                "N. Agrawal",
                "A. Aranya",
                "C. Yu",
                "Y. Go",
                "H.V. Madhyastha",
                "C. Ungureanu"
            ],
            "title": "Simba: tunable end-toend data consistency for mobile apps",
            "venue": "Proc. of EuroSys,",
            "year": 2015
        },
        {
            "authors": [
                "D.R.K. Ports",
                "A.T. Clements",
                "I. Zhang",
                "S. Madden",
                "B. Liskov"
            ],
            "title": "Transactional consistency and automatic management in an application data cache",
            "venue": "Proc. of OSDI,",
            "year": 2010
        },
        {
            "authors": [
                "M. Shapiro",
                "N. Pregui\u00e7a",
                "C. Baquero",
                "M. Zawirski"
            ],
            "title": "Conflict-free replicated data types",
            "venue": "Proc. of SSS,",
            "year": 2011
        },
        {
            "authors": [
                "M. Stonebraker",
                "J.M. Hellerstein"
            ],
            "title": "Readings in Database Systems",
            "venue": "Morgan Kaufmann San Francisco,",
            "year": 1998
        },
        {
            "authors": [
                "J. Strauss",
                "J.M. Paluska",
                "C. Lesniewski-Laas",
                "B. Ford",
                "R. Morris",
                "M.F. Kaashoek"
            ],
            "title": "Eyo: Device-transparent personal storage",
            "venue": "Proc. of USENIX ATC,",
            "year": 2011
        },
        {
            "authors": [
                "J. Stribling",
                "Y. Sovran",
                "I. Zhang",
                "X. Pretzer",
                "J. Li",
                "M.F. Kaashoek",
                "R. Morris"
            ],
            "title": "Flexible, wide-area storage for distributed systems with WheelFS",
            "venue": "Proc. of NSDI,",
            "year": 2009
        },
        {
            "authors": [
                "R. Sumbaly",
                "J. Kreps",
                "L. Gao",
                "A. Feinberg",
                "C. Soman",
                "S. Shah"
            ],
            "title": "Serving large-scale batch computed data with Project Voldemort",
            "venue": "Proc. of FAST,",
            "year": 2012
        },
        {
            "authors": [
                "D.B. Terry",
                "M.M. Theimer",
                "K. Petersen",
                "A.J. Demers",
                "M.J. Spreitzer",
                "C.H. Hauser"
            ],
            "title": "Managing update conflicts in bayou, a weakly connected replicated storage system",
            "venue": "Proc. of SOSP,",
            "year": 1995
        },
        {
            "authors": [
                "Z. Wan",
                "P. Hudak"
            ],
            "title": "Functional reactive programming from first principles",
            "venue": "Proc. of PLDI,",
            "year": 2000
        },
        {
            "authors": [
                "W.E. Weihl"
            ],
            "title": "Local atomicity properties: modular concurrency control for abstract data types",
            "venue": "ACM Trans. Prog. Lang. Syst.,",
            "year": 1989
        },
        {
            "authors": [
                "I. Zhang",
                "N.K. Sharma",
                "A. Szekeres",
                "A. Krishnamurhty",
                "D.R.K. Ports"
            ],
            "title": "Building consistent transactions with inconsistent replication",
            "venue": "Proc. of SOSP,",
            "year": 2015
        },
        {
            "authors": [
                "I. Zhang",
                "A. Szekeres",
                "D.V. Aken",
                "I. Ackerman",
                "S.D. Gribble",
                "A. Krishnamurthy",
                "H.M. Levy"
            ],
            "title": "Customizable and extensible deployment for mobile/cloud applications",
            "venue": "Proc. of OSDI,",
            "year": 2014
        }
    ],
    "sections": [
        {
            "text": ""
        },
        {
            "heading": "1 Introduction",
            "text": "The modern world\u2019s ubiquitous mobile devices, infinite cloud storage, and nearly constant network connectivity are changing applications. Led by social networks (e.g., Twitter), social games (e.g., Words with Friends) and collaboration tools (e.g., Google Docs), today\u2019s popular applications are reactive [41]: they provide users with the illusion of continuous synchronization across their devices without requiring them to explicitly save, reload, and exchange shared data. This trend, not limited merely to mobile apps, includes the latest distributed versions of traditional desktop apps on both Windows [13] and OSX [4].\nMaintaining this illusion presents a challenging distributed data management problem for application programmers. Modern reactive applications consist of widely distributed processes sharing data across mobile devices, desktops, and cloud servers. These processes make concurrent data updates, can stop or fail at any time, and may be connected by slow or unreliable links. While distributed storage systems [17, 77, 15, 23, 20] provide persistence and availability, programmers still face the formidable challenge of synchronizing updates between application processes and distributed storage in a fault-tolerant, con-\nsistent manner. This paper presents Diamond, the first reactive data management service (RDS) for wide-area applications that continuously synchronizes shared application data across distributed processes. Specifically, Diamond performs the following functions on behalf of an application: (1) it ensures that updates to shared data are consistent and durable, (2) it reliably coordinates and synchronizes shared data updates across processes, and (3) it automatically triggers reactive code when shared data changes so that processes can perform appropriate tasks. For example, when a user updates data on one device (e.g., a move in a multi-player game), Diamond persists the update, reliably propagates it to other users\u2019 devices, and transparently triggers application code on those devices to react to the changes.\nReactive data management in the wide-area context requires a balanced consideration of performance trade-offs and reasoning about complex correctness requirements in the face of concurrency. Diamond implements the difficult mechanisms required by these applications (such as logging and concurrency control), letting programmers focus on high-level data-sharing requirements (e.g., atomicity, concurrency, and data layout). Diamond introduces three new concepts:\n1. Reactive Data Map (rmap), a primitive that lets applications create reactive data types \u2013 shared, persistent data structures \u2013 and map them into the Diamond data management service so it can automatically synchronize them across distributed processes and persistent storage. 2. Reactive Transactions, an interactive transaction type that automatically re-executes in response to shared data updates. These \u201clive\u201d transactions run application code to make local, application-specific updates (e.g., UI changes). 3. Data-type Optimistic Concurrency Control (DOCC), a mechanism that leverages data-type semantics to concurrently commit transactions executing commutative operations (e.g., writes to different list elements, increments to a counter). Our experiments show that DOCC copes with wide-area\nUSENIX Association 12th USENIX Symposium on Operating Systems Design and Implementation 723\nlatencies very effectively, reducing abort rates by up to 5x.\nWe designed and implemented a Diamond prototype in C++ with language bindings for C++, Python, and Java on both x86 and Android platforms. We evaluate Diamond by building and measuring both Diamond and custom versions (using explicit data management) of four reactive apps. Our experiments show that Diamond significantly reduces the complexity and size of reactive applications, provides strong transactional guarantees that eliminate data races, and supports automatic reactivity with performance close to that of custom-written reactive apps."
        },
        {
            "heading": "2 Traditional Data Management Techniques for Reactive Apps",
            "text": "Reactive applications require synchronized access to distributed shared data, similar to shared virtual memory systems [46, 10]. For practical performance in the wide-area environment, apps must be able to control: (1) what data in each process is shared, (2) how often it is synchronized, and (3) when concurrency control is needed. Existing applications use one of several approaches to achieve synchronization with control. This section demonstrates that these approaches are all complex, error-prone, and make it difficult to reason about application data consistency.\nAs an example, we analyze a simple social game based on the 100 game [1]. Such games are played by millions [78], and their popularity changes constantly; therefore, game developers want to build them quickly and focus on game logic rather than data management. Because game play increasingly uses real money (almost $2 billion last year [24]), their design parallels other reactive applications where correctness is crucial (e.g., apps for first responders [52] and payment apps [81, 72]).\nIn the 100 game, players alternately add a number between 1 and 10 to the current sum, and the first to reach 100 wins. Players make moves and can join or leave the game at different times; application processes can fail at any time. Thus, for safety, the game must maintain traditional ACID guarantees \u2013 atomicity, consistency, isolation and durability \u2013 as well as reactivity for data updates. We call this combination of properties ACID+R. While a storage system provides ACID guarantees for its own data, those guarantees do not extend to application processes. In particular, pushing updates to storage on mobile devices is insufficient for reactivity because application processes must re-compute local data derived from shared data to make changes visible to users and other components."
        },
        {
            "heading": "2.1 Roll-your-own Data Management",
            "text": "Many current reactive apps \u201croll-their-own\u201d application-specific synchronization across distributed processes on top of general-purpose distributed storage (e.g., Spanner [17], Dropbox [23]). Figure 1\nshows a typical three-tiered architecture used by these apps (e.g., PlayFish uses it to serve over 50 million users/month [34]). Processes on client devices access stateless cloud servers, which store persistent game state in a distributed storage system and use a reliable notification service (e.g., Thialfi [3]) to trigger changes in other processes for reactivity. While all application processes can fail, we assume strong guarantees \u2013 such as durability and linearizability \u2013 for the storage system and notification service. Although such apps could rely on a single server to run the game, this would create a centralized failure point. Clients cache game data to give users a responsive experience and to reduce load on the cloud servers [34].\nThe numbers in Figure 1 show the data management steps that the application must explicitly perform for Alice\u2019s move (adding 5 to the sum). Alice\u2019s client: (1) updates turn and sum locally, (2) calculates new values for myturn? and curplay, and (3) sends the move to a cloud server. The server: (4) writes turn and sum to distributed storage, and (5) sends a notification to Bob. The notification service: (6) delivers the notification to Bob\u2019s client, which (7) contacts a cloud server to get the latest move. The server: (8) reads from distributed storage and returns the latest turn and sum. Bob\u2019s client: (9) updates turn and sum locally, and (10) re-calculates myturn? and curplay.\nNote that such data management must be customized to such games, making it difficult to implement a general-purpose solution. For example, only the application knows that: (1) clients share turn and sum (but not myname), (2) it needs to synchronize turn and sum after each turn (but not players), and (3) it does not need concurrency control because turn already coordinates moves.\nCorrectly managing this application data demands that the programmer reason about failures and data races at every step. For example, the cloud server could fail in the\n724 12th USENIX Symposium on Operating Systems Design and Implementation USENIX Association\nmiddle of step 4, violating atomicity. It could also fail between steps 4 and 5, making the application appear as if it is no longer reactive.\nA new player, Charlie, could join the game while Bob makes his move, leading to a race; if Alice receives Bob\u2019s notification first, but Charlie writes to storage first, then both Alice and Charlie would think that it was their turn, violating isolation.\nFinally, even if the programmer were to correctly handle every failure and data race and write bug-free code, reasoning about the consistency of application data would prove difficult. Enforcing a single global ordering of join, leave and move operations requires application processes to either forgo caching shared data (or data derived from shared data) altogether or invalidate all cached copies and update the storage system atomically on every operation. The first option is not realistic in a wide-area environment, while the second is not possible when clients may be unreachable."
        },
        {
            "heading": "2.2 Wide-area Storage Systems",
            "text": "A simple, alternative way to manage data manually is to store shared application data in a wide-area storage system (e.g., Dropbox [23]). That is, rather than calling move in step 3, the application stores and updates turn and sum in a wide-area storage system. Though simple, this design can be very expensive. Distributed file systems are not designed to frequently synchronize small pieces of data, so their coarse granularity can lead to moving more data than necessary and false sharing.\nFurther, while this solution synchronizes Alice\u2019s updates with the cloud, it does not ensure that Bob receives Alice\u2019s updates. To simulate reactive behavior and ensure that Bob sees Alice\u2019s updates, Alice must still use a wide-area notification system (e.g., Apple Push Notifications [6]) to notify Bob\u2019s client after her update. Unfortunately, this introduces a race condition: if Bob\u2019s client receives the notification before the wide-area storage system synchronizes Alice\u2019s update, then Bob will not see Alice\u2019s changes. Worse, Bob will never check the storage system again, so he will never see Alice\u2019s update, leaving him unable to make progress. Thus, this solution retains all of the race conditions described in Section 2.1 and introduces some new ones."
        },
        {
            "heading": "2.3 Reactive Programming Frameworks",
            "text": "Several programming frameworks (e.g., Firebase [26], Parse [60] with React [64], Meteor [51]) have recently been commercially developed for reactive applications. These frameworks combine storage and notification systems and automate data management and synchronization across systems. However, they do not provide a clear consistency model, making it difficult for programmers to reason about the guarantees provided by their synchro-\nnization mechanisms. Further, they offer no distributed concurrency control, leaving application programmers to contend with race conditions; for example, they can lead to the race condition described in Section 2.1."
        },
        {
            "heading": "3 Diamond\u2019s System and Programming Model",
            "text": "Diamond is a new programming platform designed to simplify the development of wide-area reactive applications. This section specifies its data and transaction models and system call API."
        },
        {
            "heading": "3.1 System Model",
            "text": "Diamond applications consist of processes running on mobile devices and cloud servers. Processes can communicate through Diamond or over a network, which can vary from local IPC to the Internet. Every application process is linked to a client-side library, called LIBDIAMOND, which provides access to the shared Diamond cloud \u2013 a highly available, fault-tolerant, durable storage system. Diamond subsumes some applications\u2019 server-side functionality, but our goal is not to eliminate such code. We expect cloud servers to continue providing reliable and efficient access to computation and datacenter services (e.g., data mining) while accessing shared data needed for these tasks through Diamond.\nFigure 2 shows the 100 game data model using Diamond. Compared to Figure 1, the application can directly read and write to shared data in memory, and Diamond ensures updates are propagated to cloud storage and other processes. Further, Diamond\u2019s strong transactional guarantees eliminate the need for programmers to reason about failures and concurrency."
        },
        {
            "heading": "3.2 Data Model",
            "text": "Diamond supports reactive data types for fine-grained synchronization, efficient concurrency control, and persistence. As with popular data structure stores [19], such as Redis [67] and Riak [68], we found that simple data types are general enough to support a wide range of applications\nUSENIX Association 12th USENIX Symposium on Operating Systems Design and Implementation 725\nLongList Get(idx), Set(idx, long) Append(long) Number list StringSet Get(idx), Contains(str) Insert(str) Ordered string set StringList Get(idx), Set(idx, str) Append(str) String list HashTable Get(key), Set(key, val) Unordered map\nand provide the necessary semantics to enable commutativity and avoid false sharing. Table 1 lists the supported persistent data types and their operations. In addition to primitive data types, like String, Diamond supports simple Conflict-free Replicated Data-types (CRDTs) [69] (e.g., Counter) and collection types (e.g., LongSet) with efficient type-specific interfaces. Using the most specific type possible provides the best performance (e.g., using a Counter for records that are frequently incremented).\nA single Diamond instance provides a set of tables; each table is a key-to-data-type map, where each entry, or record, has a single persistent data type. Applications access Diamond through language bindings; however, applications need not be written in a single language. We currently support C++, Python and Java on both x86 and Android but could easily add support for other languages (e.g., Swift [5])."
        },
        {
            "heading": "3.3 System Calls",
            "text": "While apps interact with Diamond largely through reactive data types, we provide a minimal system call interface, shown in Table 2, to support transactions and rmap.\n3.3.1 The rmap Primitive\nrmap is Diamond\u2019s key abstraction for providing shared memory that is flexible, persistent, and reactive across wide-area application processes. Applications call rmap with an application variable and a key to the Diamond record, giving them control over what data in their address space is shared and how it is organized. In this way, different application processes (e.g., an iOS and an Android client) and different application versions (e.g., a new and current code release) can effectively share data. When rmapping records to variables, the data types must match. Diamond\u2019s system call library checks at runtime and returns an error from the rmap call if a mismatch occurs.\ncreate(table, [isolation]) Create table status = rmap(var, table, key) Bind var to key id = execute txn(func, cb) Start read-write transaction id = register reactxn(func) Start reactive transaction reactxn stop(txn id) Stop re-executing commit txn(), abort txn() Commit/Abort and exit"
        },
        {
            "heading": "3.3.2 Transaction model",
            "text": "Application processes use Diamond transactions to read and write rmapped variables. Diamond transactions are interactive [73], i.e., they let applications interleave application code with accesses to reactive data types. We support both standard read-write transactions and new reactive transactions. Applications cannot execute transactions across rmapped variables from different tables, while operations executed outside transactions are treated as single-op transactions.\nRead-write transactions. Diamond\u2019s read-write transactions let programmers safely and easily access shared reactive data types despite failures and concurrency. Applications invoke read-write transactions using execute txn. The application passes closures for both the transaction and a completion callback. Within the transaction closure, the application can read or write rmapped variables and variables in the closure, but it cannot modify program variables outside the closure. This limitation ensures: (1) the transaction can access all needed variables when it executes asynchronously (and they have not changed), and (2) the application is not affected by the side effects of aborted transactions. Writes to rmapped variables are buffered locally until commit, while reads go to the clientside cache or to cloud storage.\nBefore execute txn returns, Diamond logs the transaction, with its read and write sets, to persistent storage. This step guarantees that the transaction will eventually execute and that the completion callback will eventually execute even if the client crashes and restarts. This guarantee lets applications buffer transactions if the network is unavailable and easily implement custom retry functionality in the completion callback. If the callback reports that the transaction successfully committed, then Diamond guarantees ACID+R semantics for all accesses to rmapped records; we discuss these in more detail in Section 3.4. On abort, Diamond rolls back all local modifications to rmapped variables.\nReactive transactions. Reactive transactions help application processes automatically propagate changes made to reactive data types. Each time a read-write transaction modifies an rmapped variable in a reactive transaction\u2019s read set, the reactive transaction re-executes, prop-\n726 12th USENIX Symposium on Operating Systems Design and Implementation USENIX Association\nagating changes to derived local variables. As a result, reactive transactions provide a \u201clive\u201d view that gives the illusion of reactivity while maintaining an imperative programming style comfortable to application programmers. Further, because they read a consistent snapshot of rmapped data, reactive transactions avoid application-level bugs common to reactive programming models [48].\nApplications do not explicitly invoke reactive transactions; instead, they register them by passing a closure to register reactxn, which returns a txn id that can be used to unregister the transaction with reactxn stop. Within the reactive transaction closure, the application can read but not write rmapped records, preventing potential data flow cycles. Since reactive transactions are designed to propagate changes to local variables, the application can read and write to local variables at any time and trigger side-effects (i.e., print-outs, updating the UI). Diamond guarantees that reactive transactions never abort because it commits read-only transactions locally at the client. Section 4 details the protocol for reactive transactions.\nReactive transactions run in a background thread, concurrently with application threads. Diamond transactions do not protect accesses to local variables, so the programmer must synchronize with locks or other mechanisms. The read set of a reactive transaction can change on every execution; Diamond tracks the read set from the latest execution. Section 6.2 explains how to use reactive transactions to build general-purpose, reactive UI elements."
        },
        {
            "heading": "3.4 Reactive Data Management Guarantees",
            "text": "Diamond\u2019s guarantees were designed to meet the requirements of reactive applications specified in Section 2, eliminating the need for each application to implement its own complex data management. To do so, Diamond enforces ACID+R guarantees for reactive data types:\n\u2022 Atomicity: All or no updates to shared records in a read-write transaction succeed. \u2022 Consistency: Accesses in all transactions reflect a consistent view of shared records.1 \u2022 Isolation: Accesses in all transactions reflect a global ordering of committed read-write transactions. \u2022 Durability: Updates to shared records in committed read-write transactions are never lost. \u2022 Reactivity: Accesses to modified records in registered reactive transactions will eventually re-execute.\nThese guarantees create a producer-consumer relationship: Diamond\u2019s read-write transactions produce updates to reactive data types, while reactive transactions consume those updates and propagate them to locally derived data. However, unlike the traditional producer-consumer\n1The C in ACID is not well defined outside a database context. Diamond simply guarantees that each transaction reads a consistent snapshot.\nparadigm, this mechanism is transparent to applications because the ACID+R guarantees ensure that Diamond automatically re-executes the appropriate reactive transactions when read-write transactions commit.\nTable 3 lists Diamond\u2019s isolation levels, which can be set per table. Diamond\u2019s default is strict serializability because it eliminates the need for application programmers to deal with inconsistencies caused by data races and failures. Lowering the isolation level leads to fewer aborts and more concurrency; however, more anomalies arise, so applications should either expect few conflicts, require offline access, or tolerate inaccuracy (e.g., Twitter\u2019s most popular hash tag statistics). Section 5.1 describes how DOCC increases concurrency and reduces aborts for transactions even at the highest isolation levels."
        },
        {
            "heading": "3.5 A Simple Code Example",
            "text": "To demonstrate the power of Diamond to simplify reactive applications, Figure 3 shows code to implement the 100 game from Section 2 in Diamond. This implementation provides persistence, atomicity, isolation and reactivity for every join and move operation in only 34 lines of code. We use three reactive data types for shared game data, declared on line 2 and rmapped in lines 7-9. It is important to ensure a strict ordering of updates, so we create a table in strict serializable mode on line 6. On line 12, we define a general-purpose transaction callback for potential transaction failures. On line 16, we execute a read-write transaction to add the player to the game, passing myname by value into the transaction closure. Using DOCC allows Diamond to commit two concurrent executions of this transaction while guaranteeing strict serializability.\nLine 20 registers a reactive transaction to print out the score and current turn. Diamond\u2019s ACID+R guarantees ensure that the transaction re-executes if players, turn or sum change, so the user always has a consistent, up-todate view. Note that we can print to stdout because the reactive transaction will not abort, and the printouts reflect a serializable snapshot, avoiding reactive glitches [48]. On line 32, we wait for user input in the while loop and use a read-write transaction to commit the entered move.\nDiamond\u2019s strong guarantees eliminate the need for programmers to reason about data races or failures. Taking our examples from Section 2, Diamond ensures that when the game commits Alice\u2019s move, the move is never\nUSENIX Association 12th USENIX Symposium on Operating Systems Design and Implementation 727\n1 int main(int argc , char **argv) { 2 DStringSet players; DCounter sum , turn; 3 string myname = string(argv [1]); 4 5 / / Map game s t a t e 6 create(\"100 game\", STRICT_SERIALIZABLE ); 7 rmap(players , \"100 game\", \"players\"); 8 rmap(sum , \"100 game\", \"sum\"); 9 rmap(turn , \"100 game\", \"turn\");\n36 myname == players[turn % players.size ()];\nlost and Bob eventually sees it. Diamond also ensures that, if Charlie joins before Bob makes his move, Alice either sees Charlie join without Bob\u2019s move, or both, but never sees Bob\u2019s move without seeing Charlie join. As a result, programmers no longer need to reason about race conditions, greatly simplifying the game\u2019s design. To our knowledge, no other system provides all of Diamond\u2019s ACID+R properties."
        },
        {
            "heading": "3.6 Offline Support",
            "text": "Wi-Fi and cellular data networks have become widely available, and reactive applications typically have limited offline functionality; thus, Diamond focuses on providing online reactivity, unlike storage systems (e.g., Bayou [77] and Simba [61]). However, Diamond still provides limited offline support. If the network is unavailable, execute txn logs and transparently retries, while Diamond\u2019s CRDTs make it more likely that transactions commit after be-\ning retried. For applications with higher contention, Diamond\u2019s read committed mode enables commits locally at the client while offline, and any modifications eventually converge to a consistent state for Diamond\u2019s CRDTs."
        },
        {
            "heading": "3.7 Security",
            "text": "Similar to existing client-focused services, like Firebase [26] and Dropbox [23], Diamond trusts application clients not to be malicious. Application clients authenticate with the Diamond cloud through their LIBDIAMOND client before they can rmap or access reactive data types. Diamond supports isolation between users through access control lists (ACLs); applications can set rmap, read, and write permissions per table. Within tables, keys function as capabilities; a client with a key to a record has permission to access it. Applications can defend against potentially malicious clients by implementing server-side security checks using reactive transactions on a secure cloud server."
        },
        {
            "heading": "4 Diamond\u2019s System Design",
            "text": "This section relates Diamond\u2019s architecture, the design of rmap, and its transaction protocols."
        },
        {
            "heading": "4.1 Data Management Architecture",
            "text": "Figure 4 presents an overview of Diamond\u2019s key components. Each LIBDIAMOND client provides client-side caching and access to cloud storage for the application process. It also registers, tracks and re-executes reactive transactions and keeps a persistent transaction log to handle device and network failures.\nThe Diamond cloud consists of front-end servers and back-end storage servers, which together provide durable storage and reliable notifications for reactive transactions. Front-end servers are scalable, stateless nodes that provide LIBDIAMOND clients access to Diamond\u2019s back-end storage, which is partitioned for scalability and replicated (using Viewstamped Replication (VR) [58]) for fault tolerance. LIBDIAMOND clients could directly access back-end storage, but front-end servers give clients a single connection point to the Diamond cloud, avoiding the need for\n728 12th USENIX Symposium on Operating Systems Design and Implementation USENIX Association\nthem to authenticate with many back-end servers or track the partitioning scheme.\n4.2 rmap and Language Bindings\nDiamond language bindings implement the library of reactive data types for apps to use as rmap variables. Diamond interposes on every operation to an rmapped variable. During a transaction, LIBDIAMOND collects an operation set for DOCC to later check for conflicts. Reads may hit the LIBDIAMOND client-side cache or require a wide-area access to the Diamond cloud, while writes (and increments, appends, etc.) are buffered in the cache until commit."
        },
        {
            "heading": "4.3 Transaction Coordination Overview",
            "text": "Figure 5 shows the coordination needed across LIBDIAMOND clients, front-end servers and back-end storage for both read-write and reactive transactions. This section briefly describes the transaction protocols.\nDiamond uses timestamp ordering to enforce isolation across LIBDIAMOND clients and back-end storage; it assigns every read-write transaction a unique commit timestamp that is provided by a replicated timestamp service (tss) (not shown in Figure 4). Commit timestamps reflect the transaction commit order, e.g., in strict serializability mode, they reflect a single linearizable ordering of committed, read-write transactions. Both Diamond\u2019s clientside cache and back-end storage are multi-versioned using these commit timestamps."
        },
        {
            "heading": "4.3.1 Running Distributed Transactions",
            "text": "Read-write and reactive transactions execute similarly; however, as Section 5 relates, reactive transactions can commit locally and often avoid wide-area accesses altogether. We lack the space to cover Diamond\u2019s transaction protocol in depth; however, it is similar to Spanner\u2019s [17] with two key differences: (1) Diamond uses DOCC for concurrency control rather than a locking mechanism, and (2) Diamond uses commit timestamps from the timestamp service (tss) rather than TrueTime [17].\nAs shown in Figure 5 (left), transactions progress through two phases, execution and commit. During the execution phase, LIBDIAMOND runs the application code in the transaction closure passed into txn execute. It runs the code locally on the LIBDIAMOND client node (i.e., not on a storage node like a stored procedure).\nThe execution phase completes when the application exits the transaction closure or calls txn commit explicitly. Reactive transactions commit locally; for read-write transactions, LIBDIAMOND sends the operation sets to the front-end server, which acts as the coordinator for a twophase commit (2PC) protocol, as follows:\n1. It sends Prepare to all participants (i.e., partitions of the Diamond back-end that hold records in the operation sets), which replicate it via VR.\n2. Each participant runs a DOCC validation check (described in Section 5); if DOCC validation succeeds, the participant adds the transaction to a prepared list and returns true; otherwise, it returns false. 3. As an optimization, the front-end server concurrently retrieves a commit timestamp from the tss. 4. If all participants respond true, the front-end sends Commits to the participants with the commit timestamp; otherwise, it sends Aborts. Then, it returns the transaction outcome to the LIBDIAMOND client. When the client receives the response, it logs the transaction outcome and invokes the transaction callback."
        },
        {
            "heading": "4.3.2 Managing Reactive Transactions",
            "text": "As shown in Figure 5 (right), when an application registers a reactive transaction, the LIBDIAMOND client: (1) gives the reactive transaction a txn id, (2) executes the reactive transaction at its latest known timestamp, and (3) sends the txn id, the timestamp, and the read set in a Register request to the front-end server. For each key in the read set, the front-end server creates a Subscribe request and sends those requests, along with the timestamp, to each key\u2019s back-end partition.\nFor efficiency, LIBDIAMOND tracks read set changes between executions and re-registers. We expect each reactive transaction\u2019s read set to change infrequently, reducing the overhead of registrations; if it changes often, we can use other techniques (e.g., map objectrange described in Section 6.2) to improve performance.\nWhen read-write transactions commit, Diamond executes the following steps for each updated record:\n1. The leader in the partition sends a Publish request with the transaction\u2019s commit timestamp to each front-end subscribed to the updated record. 2. For each Publish, the front-end server looks up the reactive transactions that have the updated record in their read sets and checks if the commit timestamp\nUSENIX Association 12th USENIX Symposium on Operating Systems Design and Implementation 729\nis bigger than the last notification sent to that client. 3. If so, the front-end server sends a Notify request to\nthe client with the commit timestamp and the reactive transaction id. 4. The client logs the notification on receipt, updates its latest known timestamp, and re-executes the reactive transaction at the commit timestamp. For keys that are updated frequently, back- and front-end servers batch updates. Application clients can bound the batching latency (e.g., to 5 seconds), ensuring that reactive transactions refresh at least once per batching latency when clients are connected."
        },
        {
            "heading": "4.3.3 Handling Failures",
            "text": "While both the back-end storage and tss are replicated using VR, Diamond can suffer failures of the LIBDIAMOND clients or front-end servers. On client failure, LIBDIAMOND runs a client recovery protocol using its transaction log to ensure that read-write transactions eventually commit. For each completed but unprocessed transaction (i.e., in the log but with no outcome), LIBDIAMOND retries the commit. If the cloud store has a record of the transaction, it returns the outcome; otherwise, it re-runs 2PC. For each reactive transaction, the application re-registers on recovery. LIBDIAMOND uses its log to find the last timestamp at which it ran the transaction.\nAlthough front-end servers are stateless, LIBDIAMOND clients must set up a new front-end server connection when they fail. They use the client recovery protocol to do this and re-register each reactive transaction with its latest notification timestamp. Front-end servers also act as coordinators for 2PC, so back-end storage servers use the cooperative termination protocol [11] if they do not receive Commit requests after some timeout."
        },
        {
            "heading": "5 Wide-area Optimizations",
            "text": "This section discusses Diamond\u2019s optimizations to reduce wide-area overhead."
        },
        {
            "heading": "5.1 Data-type Optimistic Concurrency Control",
            "text": "Diamond uses an optimistic concurrency control (OCC) mechanism to avoid locking across wide-area clients. Unfortunately, OCC can perform poorly across the wide area due to the higher latency between a transaction\u2019s read of a record and its subsequent commit. This raises the likelihood that a concurrent write will invalidate the read, thereby causing a transaction abort. For example, to increment a counter, the transaction reads the current value, increments it, and then commits the updated value; if another transaction attempts the same operation at the same time, an abort occurs.\nDOCC tackles this issue in two ways. First, it uses finegrained concurrency control based on the semantics of reactive data types, e.g., allowing concurrent updates to different list elements. Second, it uses conflict-free data\ntypes with commutative operations, such as counters and ordered sets. As noted in Section 4.3.1, LIBDIAMOND collects an operation set for every data type operation during the transaction\u2019s execution phase. For each operation, it collects the key and table. It also collects the read version for every Get, the written value for every Put, the index (e.g., list index or hash table key) for every collection operation, and the diff (e.g., the increment value or the insert or append element) for every commutative CRDT operation. We show in Section 6 that although fine-grained tracking slightly increases DOCC overhead, it improves overall performance.\nUsing operation sets, DOCC runs a validation procedure that checks every committing transaction for potential violations of isolation guarantees. A conflicting access occurs for an operation if the table, key, and index (for collection types) match an operation in a prepared transaction. For a read, a conflict also occurs if the latest write version (or commutative CRDT operation) to the table, key, and index is bigger than the read version. For each, DOCC makes an abort decision, as noted in Table 4.\nSince transactions that contain only commutative operations can concurrently commit, DOCC can allow many concurrent transactions that modify the same keys. This property is important for workloads with high write contention, e.g., the Twitter \u201clike\u201d counter for popular celebrities [36]. Further, because Diamond runs read-only and reactive transactions in serializable snapshot mode, they do not conflict with read-write transactions with commutative CRDT operations."
        },
        {
            "heading": "5.2 Client Caching with Bounded Validity Intervals",
            "text": "Some clients in the wide-area setting may occasionally be unavailable, making it impossible to atomically invalidate all cache entries on every write to enforce strong ordering. Diamond therefore uses multi-versioning in both the client-side cache and back-end storage to enforce a global ordering of transactions. To do this, it tags each version with a validity interval [62], which begins at the start timestamp and is terminated by the end timestamp. In Diamond\u2019s back-end storage, a version\u2019s start timestamp is the commit timestamp of the transaction that wrote the\n730 12th USENIX Symposium on Operating Systems Design and Implementation USENIX Association\nversion. The end timestamp is either the commit timestamp of the transaction writing the next version (making that version out-of-date) or unbounded for the latest version. Figure 6 shows an example of back-end storage with three keys.\nOn reads, the Diamond cloud tags the returned value with a validity interval for the LIBDIAMOND client-side cache. These validity intervals are conservative; back-end storage guarantees that the returned version is valid at least within the validity interval, although it may be valid beyond. If the version is the latest, back-end storage will bound the validity interval by setting the end timestamp to the latest commit timestamp of a transaction that accessed that record. For example, in Figure 6, the validity interval of the latest version of B and C are capped at timestamp 16 in the cache, while they are unbounded in storage. Most importantly, bounded validity intervals eliminate the need for cache invalidations because the version is always valid within the validity interval. Diamond eventually garbage collects cached versions as they become too outdated to use."
        },
        {
            "heading": "5.3 Data Push Notifications",
            "text": "Reactive transactions require many round-trips to synchronously fetch each update; these can be expensive in a wide-area network. Fortunately, unlike stand-alone notifications services (e.g., Thialfi), Diamond has insight into what data the application is likely to access when the reactive transaction re-executes. Thus, Diamond uses data push notifications to batch updates along with notifications, reducing wide-area round trips.\nWhen front-end servers receive Publish requests from back-end storage, they perform a snapshot read of every key in the reactive transaction\u2019s last read set at the updating transaction\u2019s commit timestamp, then piggyback the results with the Notify request to the LIBDIAMOND client. LIBDIAMOND re-executes the reactive transaction at the commit timestamp; therefore, if its read set has not changed, then it requires no additional wide-area re-\nTable 5: Application comparison. Diamond both reduces code size and adds to the application\u2019s ACID+R guarantees.\nApplication LoC w/o Diamond LoC w/ Diamond LoC Saved\nAdded\nA C I D R\n100 Game 46 34 26% DDD Chat Room 355 225 33% DDD D PyScrabble 8729 7603 13% D D Twitter clone 14278 12554 13% DDD\nquests. Further, since the reads were done at the commit timestamp, LIBDIAMOND knows that the transaction can be serialized at that timestamp and committed locally, eliminating all wide-area communication."
        },
        {
            "heading": "6 Experience and Evaluation",
            "text": "This section evaluates Diamond with respect to both programming ease and performance. Overall, our results demonstrate that Diamond simplifies the design of reactive applications, provides stronger guarantees than existing custom solutions, and supports automated reactivity with low performance overhead."
        },
        {
            "heading": "6.1 Prototype Implementation",
            "text": "We implemented a Diamond prototype in 11,795 lines of C++, including support for C++, Python and Java language bindings on both x86 and ARM. The Java bindings (939 LoC) use javacpp [39], and the Python bindings (115 LoC) use Boost [2]. We cross-compiled Diamond and its dependencies for Android using the NDK standalone toolchain [29]. We implemented most Diamond data types, but not all are supported by DOCC. Our current prototype does not include client-side persistence and relies on in-memory replication for the back-end store; however, we expect disk latency on SSDs to have a low performance impact compared to wide-area network latency, with NVRAM reducing storage latency even further in the future."
        },
        {
            "heading": "6.2 Programming Experience",
            "text": "This section evaluates our experience in building new Diamond apps, porting existing apps to Diamond, and creating libraries to support the needs of reactive programs."
        },
        {
            "heading": "6.2.1 Simplifying Reactive Applications",
            "text": "To evaluate Diamond\u2019s programming benefits, we implemented applications both with and without Diamond. Table 5 shows the lines of code for both cases. For all of the apps, Diamond simultaneously decreased program size and added important reliability or correctness properties. We briefly describe the programs and results below.\n100 Game. Our non-Diamond version of the 100 game is based on the design in Figure 1. For simplicity, we used Redis [67] for both storage and notifications. We found\nUSENIX Association 12th USENIX Symposium on Operating Systems Design and Implementation 731\nseveral data races between storage updates and notifications when running experiments for Figure 9, forcing us to include updates in the notifications to ensure clients did not read stale data from the store. The Diamond version eliminated these bugs and the complexities described in Section 2 and guaranteed correctness with atomicity and isolation; in addition, it reduced the code size by 26%.\nChat Room. As another simple but representative example of a reactive app, we implemented two versions of a chat room. Our version with explicit data management used Redis for storage and the Jetty [40] web server to implement a REST [25] API. It used POST requests to send messages and polled using GET requests for displaying the log. This design is similar to that used by Twitter [80, 35] to manage its reactive data (e.g., Twitter has POST and GET requests for tweets, timelines, etc.). The Diamond version used a StringList for the chat log, a read-write transaction to append messages, and a reactive transaction to display the log. In comparison, Diamond not only eliminated the need for a server or storage system, it also provided atomicity (the Redis version has no failure guarantees), isolation (the Redis version could not guarantee that all clients saw a consistent view of the chat log), and reactivity (the Redis version polled for new messages). Diamond also shrunk the 355-line app by 130 lines, or 33%.\nPyScrabble and Diamond Scrabble. To evaluate the impact of reactive data management in an existing application, we built a Diamond version of PyScrabble [16], an open-source, multiplayer Scrabble game. The original PyScrabble does not implement persistence (i.e., it has no storage system) and uses a centralized server to process moves and notify players. The centralized server enforces isolation and consistency only if there are no failures. We made some changes to add persistence and accommodate Diamond\u2019s transaction model. We chose to directly rmap the Scrabble board to reactive data types and update the UI in a reactive transaction, so our implementation had to commit and share every update to make it visible to the user; thus, other users could see the player lay down tiles in real-time rather than at the end of the move, as in the original design. Overall, our port of PyScrabble to Diamond removed over 1000 lines of code from the 8700-line app (13%) while transparently simplifying the structure (removing the server), adding fault tolerance (persistence) and atomicity, and retaining strong isolation.\nTwimight and Diamond Dove. As another modern reactive application, we implemented a subset of Twitter using an open-source Android Twitter client (Twimight [79]) and a custom back-end. The Diamond version eliminated much of the data management in the Twimight version, i.e., pushing and retrying updates to the server and maintaining consistency between a client-side SQLite [71]\ncache and back-end storage. Diamond directly plugged into UI elements and published updates with read-write transactions. As a result, it simplified the design, eliminated 1700 lines (13%) from the 14K-line application, transparently provided stronger atomicity and isolation guarantees, and eliminated inconsistent behaviors (e.g., a user seeing a retweet before the original tweet)."
        },
        {
            "heading": "6.2.2 Simplifying Reactive Libraries",
            "text": "In addition to simplifying the design and programming of reactive apps, we found that Diamond facilitates the creation of general-purpose reactive libraries. As one example, Diamond transactions naturally lend themselves to managing UI elements. For instance, a check box usually rmaps a Boolean, re-draws a UI element in a reactive transaction, and writes to the Boolean in a read-write transaction when the user checks/unchecks the box. We implemented a general library of Android UI elements, including a text box and check box. Each element required under 50 lines of code yet provided strong ACID+R guarantees. Note that these elements tie the user\u2019s UI to shared data, making it impossible to update the UI only locally; for example, if a user wants to preview a message before sharing it with others, the app must update the UI in some other way.\nFor generality, Diamond makes no assumptions about an app\u2019s data model, but we can build libraries using rmap for common data models. For example, we implemented object-relational mapping for Java objects whose fields were Diamond data types. Using Java reflection, rmap object maps each Diamond data type inside an object to a key derived from a base key and the field\u2019s name. We also support rmap for subsets of Diamond collections, e.g., rmap range for Diamond\u2019s primitive list types, which binds a subset of the list to an array, and rmap objectrange, which maps a list of objects using rmap object.\nThese library functions were easy to build (under 75 lines of code) and greatly simplified several applications; for example, our Diamond Twitter implementation stores a user\u2019s timeline as a LongList of tweet ids and uses map objectrange to directly bind the tail of the user\u2019s timeline into a custom Android adapter, which then plugs into the Twimight Android client and automatically manages reactivity. In addition to reducing application complexity, these abstractions also provide valuable hints for prefetching and for how reactive transaction read sets might change. Overall, we found Diamond\u2019s programming model to be extremely flexible, powerful, and easy to generalize into widely useful libraries."
        },
        {
            "heading": "6.3 Performance Evaluation",
            "text": "Our performance measurements demonstrate that Diamond\u2019s automated data management and strong consistency impose a low performance cost relative to custom-\n732 12th USENIX Symposium on Operating Systems Design and Implementation USENIX Association\nwritten applications. Using transactions with strong isolation properties lowers throughput, as one would expect. We also show that Diamond\u2019s DOCC improves performance of transactional guarantees, and that data push notifications reduce the latency of wide-area transactions. Finally, our experiments prove that Diamond has low overhead on mobile devices and can recover quickly from failures."
        },
        {
            "heading": "6.3.1 Experimental Setup",
            "text": "We ran experiments on Google Compute Engine [30] using 16 front-end servers and 5 back-end partitions, each with 3 replicas placed in different availability zones in the same geographic region (US-Central). Our replication protocol used adaptive batching with a batch size of 64. We placed clients in a different geographic region in the same country (US-East). The latency between zones was \u22481 ms, while the latency between regions was \u224836 ms. For our mobile device experiments, we used Google Nexus 7 LRX22G tablets connected via Wi-Fi and, for desktop experiments, we used a Dell workstation with an Intel Xeon E5-1650 CPU and 16 GB RAM.\nWe used a benchmark based on Retwis [45], a Redisbased Twitter clone previously used to benchmark transactional storage systems [84]. The benchmark was designed to be a representative, although not realistic, reflection of a Twitter-like workload that provides control over contention. It ran a mix of five transactions that range from 4-21 operations, including: loading a user\u2019s home timeline (50%), posting a tweet (20%), following a user (5%), creating a new user (1%), and \u201clike\u201d-ing a tweet (24%). To increase contention, we used 100K keys and a Zipf distribution with a co-efficient of 0.8."
        },
        {
            "heading": "6.3.2 Overhead of Automated Data Management",
            "text": "For comparison, we built an implementation of the Retwis benchmark that explicitly manages reactive data using Jetty [40] and Redis [67]. The Redis WAIT command offers synchronous in-memory replication, which matches Diamond\u2019s fault-tolerance guarantees but provides no operation or transaction ordering [66]. The leftmost bar in Figure 7 shows the peak Retwis throughput of 31K trans./sec. for the Redis-based implementation, while the second bar\nin Figure 7 shows the Diamond read-committed (RC) version, whose performance (30.5K trans./sec.) is nearly identical. Unlike the Redis-based implementation, however, the Diamond benchmark provides strong consistency based on VR, i.e., it enforces a single global order of operations but not transactions. The Diamond version also provides all of its reactivity support features. Diamond therefore provides better consistency properties and simplifies programming at little additional cost.\nAs we add stronger isolation through transactions, throughput declines because two-phase commit requires each back-end server to process an extra message per transaction. As the graph shows, snapshot isolation (SI) and strict serializability (SS) reduce throughput by nearly 50% from RC. The graph also shows SI and SS both with and without DOCC; eliminating DOCC hurts SS more than SI (27% vs. 13%) because SI lets transactions with read-write conflicts commit (leading to write skew).\nFrom this experiment, we conclude that Diamond\u2019s general-purpose data management imposes almost no throughput overhead. Also, achieving strong transactional isolation guarantees does impose a cost due to the more complex message protocol required. Depending on the application, programmers can choose to offset the cost by allocating more servers or tolerate inconsistencies that result from weaker transactional guarantees."
        },
        {
            "heading": "6.3.3 Benefit of DOCC",
            "text": "DOCC\u2019s benefit depends on both contention and transaction duration. To evaluate this effect, we measured the throughput improvement of DOCC for each type of Retwis transaction with at least one CRDT operation (Figure 8).\nThe add user and like transactions are short and thus unlikely to abort, but they still see close to a 2x improvement. add follower gets a larger benefit (4x) because it is a longer transaction with more commutative operations. Even get timeline, a read-only transaction, gets a tiny improvement (2.5%) due to reduced load on the servers from aborting transactions. Further, because get timeline runs in serializable snapshot mode, post tweet transactions can commit concurrently with get timeline transactions.\nThe post tweet transaction appends a user\u2019s new tweet to his timeline and his followers\u2019 home timelines (each user has between 5 and 20 followers). If a user follows a large number of people that tweet frequently, conventional OCC makes it highly likely that a conflicting Append would cause the entire transaction to fail. With DOCC, all Appends to a user\u2019s home timeline can commute, avoiding these aborts. As a result, we saw a 5x improvement in abort rate with DOCC over conventional OCC for post tweet, leading to a 25x improvement in throughput. Overall, these results show that Diamond\u2019s support for data types in its API and concurrency control mechanism is crucial to reducing the cost of transactional guarantees.\nUSENIX Association 12th USENIX Symposium on Operating Systems Design and Implementation 733"
        },
        {
            "heading": "6.3.4 Benefit of Data Push Notifications",
            "text": "Although Diamond\u2019s automated data management imposes a low throughput overhead, it can hurt latency due to wide-area round trips to the Diamond cloud. For example, the latency of a Retwis transaction is twice as high for Diamond relative to our Redis implementation because Diamond requires two round trips per transaction, one to read and one to commit, while Redis needs only one.\nData push notifications reduce this latency by batching updates with reactive transaction notifications to populate the client-side cache. We turned our implementation of the 100 game from Figure 3 into a benchmark: two players join each game, and players make a move as soon as the other player finishes (i.e., zero \u201cthink\u201d time). This experiment is ideal because the read set of the reactive transaction does not change, and it overlaps with the read set of the read-write transaction. We also design an implementation using Redis, where notifications carry updates to clients as a manual version of data push notifications. We measure the latency from one player\u2019s client for each player to take a turn or for one round of the game. Figure 9 shows that data push notifications reduce the overall latency by almost 50% by eliminating wide-area reads for both the reactive and read-write transactions in the game. As a result, Diamond has 30% lower latency and stronger transactional guarantees than our Redis implementation."
        },
        {
            "heading": "6.3.5 Impact of Wide-area Storage Server Failures",
            "text": "Failures affect the latency of both reactive and read-write transactions. To measure this impact, we used the same 100 game workload and killed a back-end server during the game. To increase the recovery overhead, we georeplicated the back-end servers across Asia, US-Central and Europe, while clients remained in US-East.\nFigure 10 shows the latency of each round. Note that the latency is higher than that in the previous experiment because the VR leader has to wait for a response from a quorum of replicas, which take at least 100 ms, and up to 150 ms, to contact. About 15 seconds into the game, we kill the leader in US-Central, switching it to Europe. The latency of each round increases to almost 4 seconds afterwards: the latency between the front-end servers and the leader in Europe increases to 100 ms, and the latency from the leader to the remaining replica in Asia increases to 250 ms. Despite this, the round during the failure takes only 7 seconds, meaning that Diamond can detect the failure and replace the leader in less than 3 seconds."
        },
        {
            "heading": "6.3.6 End-user Application Latency",
            "text": "To evaluate Diamond\u2019s impact on the user experience, we measure the latency of user operations in two apps from Section 6.2 built with and without Diamond. PyScrabble is a desktop application, while our Chat Room app runs on Android. The ping times to the Diamond cloud were \u224838 ms on the desktop and \u224846 ms on the Android tablet.\nFigure 11 (left) shows two operations for PyScrabble: MakeMove commits a transaction that updates the user\u2019s move, and DisplayMove includes MakeMove plus the notification and reactive transaction to make it visible. Compared to the original PyScrabble, Diamond\u2019s latency is slightly higher (9% and 16%, respectively). Figure 11 (right) shows operations for the Chat Room on an Android tablet. ReadLog gets the full chat log, and PostMessage gets the chat log, appends a message, and commits it back. The Diamond version is a few percent faster than the Redis version because it runs in native C++, while the Redis version uses a Java HTTP client. Overall, we found the latency differences between Diamond and non-Diamond operations were not perceivable to users."
        },
        {
            "heading": "7 Related Work",
            "text": "Diamond takes inspiration from wide-area storage systems, transactional storage systems and databases, reactive programming, distributed programming frameworks, shared memory systems and notification systems.\nSeveral commercial platforms [51, 26, 60] provide\n734 12th USENIX Symposium on Operating Systems Design and Implementation USENIX Association\nan early form of reactive data management without distributed transactions. Other open source projects [38, 55, 21, 59, 70] have replicated the success of their commercial counterparts. Combined, they comprise a mobile back-end market of $1.32 billion dollars [49].\nHowever, these products do not meet the requirements of reactive applications, still requiring programmers to address failures and race conditions. Meteor [51] lets clientside code directly access the database interface. However, because it uses existing databases (MongoDB [53], and most recently, Postgres [63]) that do not support distributed transactions and offer weak consistency guarantees by default, programmers must still reason about race conditions and consistency bugs. Parse [60] and Firebase [26] similarly enable clients to read, write, and subscribe to objects that are automatically synchronized across mobile devices; however, these systems offer no concurrency control or transactions. As demonstrated by these Stack Overflow questions [56, 50], programmers find this to be a significant issue with these systems. Diamond addresses this clear developer need by providing ACID+R guarantees for reactive applications.\nThere has been significant work in wide-area storage systems for distributed and mobile applications, including numerous traditional instantiations [77, 42, 57] as well as more recent work [18, 9, 74, 61, 75]. Many mobile applications today use commercial storage services such as Dropbox and others [23, 22, 37], while users can also employ revision-based storage (e.g., git [27]). Applications often combine distributed storage with notifications [3, 6]. As discussed, these systems help with data management, but none offers a complete solution.\nDiamond shares a data-type-based storage model with data structure stores [67, 68]. Document stores (e.g., MongoDB [53]) support application objects; this prevents them from leveraging semantics for better performance. These datastores, along with more traditional key-value and relational storage systems [15, 8, 44, 76], were not designed for wide-area use although they could support reactive applications with additional work.\nReactive transactions in Diamond are similar to database triggers [47], events [14], and materialized views [12]. They differ from these mechanisms because they modify local application state and execute application code rather than database queries that update storage\nstate. Diamond\u2019s design draws on Thialfi [3]; however, Thialfi cannot efficiently support data push notifications without insight into the application\u2019s access patterns.\nDOCC is similar to Herlihy [32, 31] and Weihl\u2019s [83] work on concurrency control for abstract data types. However, Diamond applies their techniques to CRDTs [69] over a range of isolation levels in the wide area. DOCC is also related to MDCC [43] and Egalitarian Paxos [54]; however, DOCC uses commutativity for transactional concurrency control rather than Paxos ordering and supports more data types. DOCC extends recent work on software transactional objects [33] for single-node databases to the wide area; integrating the two would let programmers implement custom data types in Diamond.\nDiamond does not strive to support a fully reactive, data-flow-based programming model, like functional reactive or constraint-based programming [82, 7]; however, reactive transactions are based on the idea of change propagation. Recent interest in reactive programming for web client UIs has resulted in Facebook\u2019s popular React.js [64], the ReactiveX projects [65], and Google\u2019s Agera[28]. DREAM [48], a recently proposed, distributed reactive platform, lacks transactional guarantees. Sapphire [85], another recent programming platform for mobile/could applications, does not support reactivity, distributed transactions, or general-purpose data management."
        },
        {
            "heading": "8 Conclusion",
            "text": "This paper described Diamond, the first data management service for wide-area reactive applications. Diamond introduced three new concepts: the rmap primitive, reactive transactions, and DOCC. Our evaluation demonstrated that: (1) Diamond\u2019s programming model greatly simplifies reactive applications, (2) Diamond\u2019s strong transactional guarantees eliminate data race bugs, and (3) Diamond\u2019s low performance overhead has no impact on the end-user."
        },
        {
            "heading": "9 Acknowledgements",
            "text": "We thank the UW systems lab for their comments throughout the project. This work was supported by Google, National Science Foundation grant CNS-1518702 and NSF GRFP, and MSR Ph.D. fellowships. We also thank our anonymous reviewers and our shepherd, Bryan Ford, for their feedback."
        }
    ],
    "title": "Diamond: Automating Data Management and Storage for Wide-Area, Reactive Applications",
    "year": 2016
}