{
    "abstractText": "The overturning of the Internet Privacy Rules by the Federal Communications Commissions (FCC) in late March 2017 allows Internet Service Providers (ISPs) to collect, share and sell their customers\u2019 Web browsing data without their consent. With third-party trackers embedded on Web pages, this new rule has put user privacy under more risk. The need arises for users on their own to protect their Web browsing history from any potential adversaries. Although some available solutions such as Tor, VPN, and HTTPS can help users conceal their online activities, their use can also significantly hamper personalized online services, i.e., degraded utility. In this paper, we design an effective Web browsing history anonymization scheme, PBooster, aiming to protect users\u2019 privacy while retaining the utility of their Web browsing history. The proposed model pollutes users\u2019 Web browsing history by automatically inferring how many and what links should be added to the history while addressing the utility-privacy trade-off challenge. We conduct experiments to validate the quality of the manipulated Web browsing history and examine the robustness of the proposed approach for user privacy protection.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ghazaleh Beigi"
        },
        {
            "affiliations": [],
            "name": "Ruocheng Guo"
        },
        {
            "affiliations": [],
            "name": "Alexander Nou"
        },
        {
            "affiliations": [],
            "name": "Yanchao Zhang"
        },
        {
            "affiliations": [],
            "name": "Huan Liu"
        }
    ],
    "id": "SP:813853eec0f73518002716ae1789045284bf23c1",
    "references": [
        {
            "authors": [
                "Hamidreza Alvari",
                "Elham Shaabani",
                "Paulo Shakarian"
            ],
            "title": "Early Identification of Pathogenic Social Media Accounts",
            "venue": "In IEEE Intelligence and Security Informatics (ISI). IEEE",
            "year": 2018
        },
        {
            "authors": [
                "Hamidreza Alvari",
                "Paulo Shakarian",
                "JE Kelly Snyder"
            ],
            "title": "Semi-supervised learning for detecting human trafficking",
            "venue": "Security Informatics",
            "year": 2017
        },
        {
            "authors": [
                "Ero Balsa",
                "Carmela Troncoso",
                "Claudia Diaz"
            ],
            "title": "OB-PWS: Obfuscationbased private web search",
            "venue": "In Security and Privacy (SP),",
            "year": 2012
        },
        {
            "authors": [
                "Ghazaleh Beigi",
                "Huan Liu"
            ],
            "title": "Privacy in Social Media: Identification, Mitigation and Applications",
            "venue": "arXiv preprint arXiv:1808.02191",
            "year": 2018
        },
        {
            "authors": [
                "Ghazaleh Beigi",
                "Huan Liu"
            ],
            "title": "Similar but Different: Exploiting Users\u2019 Congruity for Recommendation Systems",
            "venue": "In International Conference on Social Computing,",
            "year": 2018
        },
        {
            "authors": [
                "Ghazaleh Beigi",
                "Kai Shu",
                "Yanchao Zhang",
                "Huan Liu"
            ],
            "title": "Securing Social Media User Data: AnAdversarial Approach",
            "venue": "In Proceedings of the 29th on Hypertext and Social Media",
            "year": 2018
        },
        {
            "authors": [
                "Ghazaleh Beigi",
                "Jiliang Tang",
                "Suhang Wang",
                "Huan Liu"
            ],
            "title": "Exploiting emotional information for trust/distrust prediction",
            "venue": "In Proceedings of the 2016 SIAM international conference on data mining",
            "year": 2016
        },
        {
            "authors": [
                "DavidMBlei",
                "Andrew YNg",
                "andMichael I Jordan"
            ],
            "title": "Latent dirichlet allocation",
            "venue": "Journal of machine Learning research",
            "year": 2003
        },
        {
            "authors": [
                "Jordi Castell\u00e0-Roca",
                "Alexandre Viejo",
                "Jordi Herrera-Joancomart\u00ed"
            ],
            "title": "Preserving user\u00e2\u0102\u0179s privacy in web search engines",
            "venue": "Computer Communications 32,",
            "year": 2009
        },
        {
            "authors": [
                "Nicolas Christin",
                "Sally S Yanagihara",
                "Keisuke Kamataki"
            ],
            "title": "Dissecting one click frauds",
            "venue": "In Proceedings of ACM conference on Computer and communications security",
            "year": 2010
        },
        {
            "authors": [
                "Alissa Cooper"
            ],
            "title": "A survey of query log privacy-enhancing techniques from a policy perspective",
            "venue": "ACM Transactions on the Web (TWEB)",
            "year": 2008
        },
        {
            "authors": [
                "Steven Englehardt",
                "Arvind Narayanan"
            ],
            "title": "Online tracking: A 1-millionsite measurement and analysis",
            "venue": "In ACM SIGSAC Conference on Computer and Communications Security",
            "year": 2016
        },
        {
            "authors": [
                "Uriel Feige",
                "Vahab S Mirrokni",
                "Jan Vondrak"
            ],
            "title": "Maximizing non-monotone submodular functions",
            "venue": "SIAM J. Comput. 40,",
            "year": 2011
        },
        {
            "authors": [
                "Arthur Gervais",
                "Reza Shokri",
                "Adish Singla",
                "Srdjan Capkun",
                "Vincent Lenders"
            ],
            "title": "Quantifying web-search privacy",
            "venue": "In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security",
            "year": 2014
        },
        {
            "authors": [
                "Michaela Gotz",
                "Ashwin Machanavajjhala",
                "Guozhang Wang",
                "Xiaokui Xiao",
                "Johannes Gehrke"
            ],
            "title": "Publishing search logs\u00e2\u0102\u0164a comparative study of privacy guarantees",
            "venue": "IEEE Transactions on Knowledge and Data Engineering 24,",
            "year": 2012
        },
        {
            "authors": [
                "Rachid Guerraoui",
                "Anne-Marie Kermarrec",
                "Mahsa Taziki"
            ],
            "title": "The Utility and Privacy Effects of a Click",
            "venue": "In Proceedings of ACM",
            "year": 2017
        },
        {
            "authors": [
                "Daniel C Howe",
                "Helen Nissenbaum"
            ],
            "title": "TrackMeNot: Resisting surveillance in web search. Lessons from the Identity trail: Anonymity, privacy, and identity in a networked society",
            "year": 2009
        },
        {
            "authors": [
                "Jingyu Hua",
                "Chang Xia",
                "Sheng Zhong"
            ],
            "title": "Differentially Private Matrix Factorization",
            "venue": "In IJCAI",
            "year": 2015
        },
        {
            "authors": [
                "Andreas Krause",
                "Eric Horvitz"
            ],
            "title": "A utility-theoretic approach to privacy in online services",
            "venue": "Journal of Artificial Intelligence Research",
            "year": 2010
        },
        {
            "authors": [
                "Andreas Krause",
                "Ajit Singh",
                "Carlos Guestrin"
            ],
            "title": "Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies",
            "venue": "Journal of Machine Learning Research",
            "year": 2008
        },
        {
            "authors": [
                "Adam Lerner",
                "Anna Kornfeld Simpson",
                "Tadayoshi Kohno",
                "Franziska Roesner"
            ],
            "title": "Internet Jones and the Raiders of the Lost Trackers: An Archaeological Study of Web Tracking",
            "venue": "In USENIX Security Symposium",
            "year": 2016
        },
        {
            "authors": [
                "Lei Li",
                "Dingding Wang",
                "Tao Li",
                "Daniel Knox",
                "Balaji Padmanabhan"
            ],
            "title": "SCENE: a scalable two-stage personalized news recommendation system",
            "venue": "In Proceedings ACM SIGIR",
            "year": 2011
        },
        {
            "authors": [
                "Ashwin Machanavajjhala",
                "Aleksandra Korolova",
                "Atish Das Sarma"
            ],
            "title": "Personalized social recommendations: accurate or private",
            "venue": "Proceedings of the VLDB Endowment",
            "year": 2011
        },
        {
            "authors": [
                "Miller McPherson",
                "Lynn Smith-Lovin",
                "James M Cook"
            ],
            "title": "Birds of a feather: Homophily in social networks",
            "venue": "Annual review of sociology 27,",
            "year": 2001
        },
        {
            "authors": [
                "Frank McSherry",
                "Ilya Mironov"
            ],
            "title": "Differentially private recommender systems: building privacy into the net",
            "venue": "In Proceedings of SIGKDD",
            "year": 2009
        },
        {
            "authors": [
                "Wei Meng",
                "Byoungyoung Lee",
                "Xinyu Xing",
                "Wenke Lee"
            ],
            "title": "TrackMeOrNot: Enabling Flexible Control on Web Tracking",
            "venue": "In Proceedings of the 25th WWW",
            "year": 2016
        },
        {
            "authors": [
                "Arvind Narayanan",
                "Vitaly Shmatikov"
            ],
            "title": "De-anonymizing social networks",
            "venue": "In Security and Privacy,",
            "year": 2009
        },
        {
            "authors": [
                "George LNemhauser",
                "Laurence AWolsey",
                "andMarshall L Fisher"
            ],
            "title": "An analysis of approximations for maximizing submodular set functions\u00e2\u0102\u0164I",
            "venue": "Mathematical Programming 14,",
            "year": 1978
        },
        {
            "authors": [
                "Tu Minh Phuong"
            ],
            "title": "Gender prediction using browsing history",
            "venue": "In Knowledge and Systems Engineering",
            "year": 2014
        },
        {
            "authors": [
                "Radim Rehurek",
                "Petr Sojka"
            ],
            "title": "Software framework for topic modelling with large corpora",
            "venue": "Proceedings of the LREC 2010Workshop on New Challenges for NLP Frameworks. Citeseer",
            "year": 2010
        },
        {
            "authors": [
                "Badrul M Sarwar",
                "George Karypis",
                "Joseph Konstan",
                "John Riedl"
            ],
            "title": "Recommender systems for large-scale e-commerce: Scalable neighborhood formation using clustering",
            "venue": "In International conference on computer and information technology",
            "year": 2002
        },
        {
            "authors": [
                "Yilin Shen",
                "Hongxia Jin"
            ],
            "title": "Privacy-preserving personalized recommendation: An instance-based approach via differential privacy",
            "venue": "In Proceedings of ICDM. IEEE",
            "year": 2014
        },
        {
            "authors": [
                "Yilin Shen",
                "Hongxia Jin"
            ],
            "title": "EpicRec: towards practical differentially private framework for personalized recommendation",
            "venue": "In Proceedings of ACM SIGSAC. ACM",
            "year": 2016
        },
        {
            "authors": [
                "Adish Singla",
                "Eric Horvitz",
                "Ece Kamar",
                "Ryen White"
            ],
            "title": "Stochastic privacy",
            "venue": "In AAAI",
            "year": 2014
        },
        {
            "authors": [
                "Jessica Su",
                "Aneesh Sharma",
                "Sharad Goel"
            ],
            "title": "The effect of recommendations on network structure",
            "venue": "In Proceedings of WWW",
            "year": 2016
        },
        {
            "authors": [
                "Jessica Su",
                "Ansh Shukla",
                "Sharad Goel",
                "Arvind Narayanan"
            ],
            "title": "Deanonymizing web browsing data with social networks",
            "venue": "In Proceedings of the 26th International Conference on World Wide Web",
            "year": 2017
        },
        {
            "authors": [
                "Lyle H Ungar",
                "Dean P Foster"
            ],
            "title": "Clustering methods for collaborative filtering",
            "venue": "In AAAI workshop on recommendation systems,",
            "year": 1998
        },
        {
            "authors": [
                "Hui Yang",
                "Ian Soboroff",
                "Li Xiong",
                "Charles LA Clarke",
                "Simson L Garfinkel"
            ],
            "title": "Privacy-Preserving IR 2016: Differential Privacy, Search, and Social Media",
            "venue": "In ACM SIGIR",
            "year": 2016
        },
        {
            "authors": [
                "Shaozhi Ye",
                "Felix Wu",
                "Raju Pandey",
                "Hao Chen"
            ],
            "title": "Noise injection for search privacy protection",
            "venue": "In Computational Science and Engineering,",
            "year": 2009
        },
        {
            "authors": [
                "Sicong Zhang",
                "Hui Yang",
                "Lisa Singh"
            ],
            "title": "Anonymizing query logs by differential privacy",
            "venue": "In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval",
            "year": 2016
        },
        {
            "authors": [
                "Yun Zhu",
                "Li Xiong",
                "Christopher Verdery"
            ],
            "title": "Anonymizing user profiles for personalized web search",
            "venue": "In WWW. ACM",
            "year": 2010
        },
        {
            "authors": [
                "Sebastian Zimmeck",
                "Jie S Li",
                "Hyungtae Kim",
                "Steven M Bellovin",
                "Tony Jebara"
            ],
            "title": "A privacy analysis of cross-device tracking",
            "venue": "In 26th Security Symposium",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "CCS CONCEPTS \u2022 Security and Privacy\u2192 Data Anonymization and Sanitization; \u2022 Security and privacy\u2192 Privacy protections;\nKEYWORDS Web Browsing History Anonymization, Privacy, Utility, Trade-off ACM Reference Format: Ghazaleh Beigi, Ruocheng Guo, Alexander Nou, Yanchao Zhang, Huan Liu. 2019. Protecting User Privacy: An Approach for Untraceable Web Browsing History and Unambiguous User Profiles. In The Twelfth ACM International Conference on Web Search and Data Mining (WSDM \u201919), February 11\u201315, 2019, Melbourne, VIC, Australia. ACM, New York, NY, USA, 9 pages. https: //doi.org/10.1145/3289600.3291026"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "The web browsing history is the list of web pages a user has visited in past browsing sessions and includes the name of the web pages as well as their corresponding URLs. Online users usually\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WSDM \u201919, February 11\u201315, 2019, Melbourne, VIC, Australia \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5940-5/19/02. . . $15.00 https://doi.org/10.1145/3289600.3291026\nexpect a secure environment when surfing the Web wherein their personally identifiable information (a.k.a. PII) could be kept hidden from prying eyes. However, the web browsing history log is stored by the web browser on the device\u2019s local hard drive. In addition to the web browser, users\u2019 browsing histories are recorded via thirdparty trackers embedded on the web pages to help improve online advertising and web surfing experience. Moreover, Internet Service Providers (ISPs) such as AT&T and Verizon, have full access to individuals\u2019 web browsing histories. ISPs can infer different types of personal information such as users\u2019 political views, sexual orientations and financial information based on the sites they visit. Some countries have policies for protecting individuals\u2019 privacy. For example, European Union (EU) has regulated a new data protection and privacy policy for all individuals within the European Union and the European Economic Area (a.k.a. General Data Protection Regulation (GDPR)).1United States government also had Federal Communications Commission\u2019s (FCC) landmark Internet privacy protections for users such that ISPs could have been punished by the Federal Trade Commission (FTC) for violating their customers\u2019 privacy. However, not all countries have such policies. FCC\u2019s Internet privacy protection has been also removed in late March of 2017. This new legislation allows ISPs to monitor, collect, share and sell their customer\u2019s behavior online such as detailed Web browsing histories without their consent and any anonymization.2\nAssuming that ISPs and online trackers make browsing history data pseudonymous before sharing, a recent study has shown the fingerprintability of such data by introducing an attack which maps a given browsing history to a social media profile such as Twitter, Facebook, or Reddit accounts [36]. Although linking browsing history to social media profiles may not always lead to figuring out one\u2019s real identity, it is a stepping stone for attackers to infer real identities. This identity exposure may result in harms ranging from persecution by governments to targeted frauds [6, 10].\nThe onus is now on the users to protect their browsing history from any kind of adversaries like ISPs and online trackers. There are approaches to help users shield their web browsing history such as browser add-ons or extensions (e.g., \u2018Ghostery\u2019, \u2018Privacy Badger\u2019 and \u2018HTTPS everywhere\u2019), Virtual Private Networks (VPN) services, Tor, and HTTPS. However, none of the above solutions can prevent ISPs from collecting users\u2019 web browsing history and protect users\u2019 identities when such information is revealed because de-anonymization attacks will still work [36]. Moreover, using these solutions could result in a severe decrease in the quality of online personalization services due to the lack of customer\u2019s information. This information is critical for online vendors to profile users\u2019 preferences from their online activities to predict their future needs. So\n1https://bit.ly/1lmrNJz 2http://wapo.st/2mvYKGa\nar X\niv :1\n81 1.\n09 34\n0v 1\n[ cs\n.C R\n] 2\n3 N\nov 2\n01 8\nusers face a dilemma between user privacy and service satisfaction. Hereafter, we refer to a user\u2019s satisfaction of online personalization services, as online service utility, or simply, utility. The aforementioned challenges highlight the need to have a web browsing history anonymizer framework, which can help users strike a good balance between their privacy and utility. Traditional privacy preserving web search techniques such as [38, 40, 41] are designed for different purposes and are thus ineffective in accomplishing our goals.\nIntuitively, the more links we add to a web browsing history, the more privacy we can preserve. An extreme case is when the added links completely change a user\u2019s browsing history to perfectly obfuscate the user\u2019s fingerprints. Some existing methods include ISPPolluter,3 Noiszy,4 and RuinMyHistory5 which pollute a web browsing history by adding links randomly. However, such methods largely disturb user profiles and thus results in the loss of utility of online services. Similarly, the maximum service utility can only be achieved at the complete sacrifice of user privacy. It is challenging to design an effective browsing history anonymizer that retains high utility. In this paper, we aim to study the following problem: howmany links andwhat links should be added to a user\u2019s browsing history to boost user privacy while retaining high utility. Note that links cannot be removed from the browsing history as all of user\u2019s activities have been already recorded by ISPs. The research requires quantifying the privacy of users and the utility of their services. We address these challenges within a novel framework, called PBooster. This framework exploits publicly available information in social media networks as an auxiliary source of information to help anonymizing web browsing history while preserving utility. Our contributions can be summarized as follows. \u2022 We address the problem of anonymizing web browsing histories while retaining high service utility. We show that this problem cannot be solved in polynomial time. \u2022 We propose an efficient framework, PBooster, with measures for quantifying the trade-off between user privacy and the quality of online services. \u2022 We conduct experiments and evaluate the proposed approach in terms of privacy and utility. Results demonstrate the efficiency of PBooster in terms of privacy-utility trade-off."
        },
        {
            "heading": "2 RELATEDWORK",
            "text": "Explosive growth of the Web has not only drastically changed the way people conduct activities and acquire information, but also has raised security [1, 2] and privacy [4, 6, 27] issues for them. Identifying andmitigating user privacy issues has been studied from different aspects on the Web and social media (for a comprehensive survey see [4]). Our work is related to a number of research which we discuss below while highlighting the differences between our work and them. Tracking and Profiling. In the area of user tracking and profiling, there have been efforts to study how and to what degree that web browser tracking [12, 21, 26] and cross-device tracking [42] can be done by third parties. This line of work mainly studied the mechanisms of the user tracking techniques. To go one step further, for\n3https://github.com/essandess/isp-data-pollution 4https://noiszy.com/ 5https://github.com/FascinatedBox/RuinMyHistory\nthe protection of users from tracking and profiling, strategies such as limiting the access to sampled user profiles [34] and distorting the user profile [9] are proposed to minimize privacy risk. Privacy Preserving Web Search.Web search has become a regular activity where a user composes a query formed by one or more keywords and sends it to the search engine. The engine returns a list of web pages according to the user query. These search queries are a rich source of information for user profiling. Privacy preserving web search approaches focus on anonymizing users search queries. One group of works focused on the protection of post-hoc logs [11, 15, 40]. Another group of approaches including client-side ones focuses on search query obfuscation [3, 14, 17, 39]. These approaches are user-centric and automatically generate fake search queries on behalf of user. Web browsing history anonymization problem is different from privacy preserving web search problem. The former consists of a set of URLs a user has visited in past browsing sessions, while the latter includes a set of queries and relevant pages returned by search engine for each given query. Moreover, in web browsing history anonymization, URLs cannot be removed from a user\u2019s history (all activities have been already recorded by ISPs) while a data publisher is allowed to remove a portion of queries and pages in privacy preserving web search problem. This makes the web browsing history anonymization more challenging. Privacy Preserving Recommendation. Recommendation systems help individuals find relevant information, however, these systems can also raise privacy concerns for users [5]. Differential privacy based approaches [23, 25, 32] add noise to recommendation results so that the distribution of results is insensitive to the records of any specific user. Secure computation approaches have been also designed to take care of the computation procedure in recommender systems. Privacy-preserving matrix factorization schemes [18] are designed to avoid exposure of user information during the recommender\u2019s computation. Matrix factorization has been used in many applications such as recommendation systems and trust/distrust prediction [7]. Another work [19] studies sharing user attributes to recommenders while handling the trade-off between privacy and quality of received service. Recent work [33] also studied utilityprivacy trade-off.\nThe problem of anonymizing web browsing history is unique in this work. First, in our problem web browsing URLs cannot be removed and the original format of data will be published rather than its statistics. This also makes differential privacy based techniques ineffective for this task. Second, the user is not aware of the tasks that use his data and thus securing computation approaches is impractical for this new problem. Third, the proposed solution should be efficient and results in minimal loss in utility. All of these make this problem even more challenging."
        },
        {
            "heading": "3 THREAT MODEL AND PROBLEM STATEMENT",
            "text": "Before discussing the details of the proposed solution, we first formally define browsing history, then review the web browsing history de-anonymization and finally introduce the problem of web browsing history anonymization. For each user, web browsing history is defined as the list of web pages a user has visited in his past browsing sessions and includes the corresponding URLs of the\nvisited web pages. This log is recorded by the browser, third-party trackers and ISPs. In addition to his browsing history, other private data components such as cache, cookies and saved passwords are also saved during a browsing session which are sometimes referred to under the browsing history umbrella. However, in this work, we separate these pieces of information from web browsing history. Given a user u, we assume his web browsing historyHu is generated by a sequence of n linksHu = {l1, ...ln } where li corresponds to the i-th URL visited by the user u."
        },
        {
            "heading": "3.1 Threat Model",
            "text": "De-anonymizing browsing histories is a type of linkage attack which is introduced by Su et al. [36]. This de-anonymization attack links web browsing histories to social media profiles. The main idea behind this threat model is that people tend to click on the links in their social media feed. These links are mainly provided by the set of user\u2019s friends. Since each user has a distinctive set of friends on social media and he is more likely to click on a link posted by any of his friends rather than a random user, these distinctive web browsing patterns remain in his browsing history. Assuming that the attacker knows which links in the history have resulted from clicks on social media feeds, a maximum likelihood based framework is developed as a de-anonymization attack which identifies the feed in the system that has more probably generated the browsing history. This attack can be formally defined as:\nProblem 1. Given user u\u2019s web browsing historyHu = {l1, ...ln } which is consisted of n links, map u to a social media profile whose feed has most probably generated the browsing history [36].\nLet\u2019s assume that each user u has a personalized set of recommender links. For example, this recommendation set could be a set of links appeared in the user\u2019s social media Feed (e.g., Twitter) which includes links posted by the user\u2019s friends on the network. Su et. al. [36] assume that each user visits links in his recommendation set. Given a browsing historyHu , the attacker finds the most likely recommendation set that corresponds to the given user u: the recommendation set which contains many of the URLs in the browsing history and is not too big. This de-identifies the browsing history. For the detailed proof and implementation of this attack please refer to [36]. Twitter is selected as a mapping platform for evaluation of this attack. This work shows that users\u2019 activities in social media can be used to re-identify them. We next introduce the problem of web browsing history anonymization."
        },
        {
            "heading": "3.2 Problem Statement",
            "text": "In this work, we define a privacy preserving framework which protects user\u2019s privacy by combating the de-anonymizing web browsing history threat model we discussed in Section 3.1. In addition, utility here is also defined as user\u2019s satisfaction of online personalized services. This could also be measured by comparing the quality of manipulated web browsing history after anonymization with the original one. Given user u\u2019s browsing history Hu , the goal is to anonymize u\u2019s browsing history by adding new links to Hu in an efficient manner, such that both the user\u2019s privacy and utility are preserved, i.e., web browsing history is robust against de-identification attack and maintains its utility.\nWe first need to convert links to a structured dataset. One straightforward solution is to leverage the content of each web page and then map it to a category or a topic selected from a predefined set. This way, each user will be represented by a set of categories extracted from all of the web pages he has visited. One typical way for extracting topics is to manually define them (e.g., sports, fashion, knowledge, etc.) and then map each web page to the corresponding category. This method requires a set of keywords related to each topic and then inferring the web page\u2019s topic by calculating the similarity of its textual content to the given keywords. This solution is not feasible in practice since it needs frequent updates of keywords for each category due to the fast growth of the Internet. Moreover, this only provides a coarse-grained categorization of web pages\u2019 contents. In order to have a finer level of granularity we follow the same approach as in [29] and adopt Latent Dirichlet Allocation (LDA) topic modeling technique [8]. We use the following procedure to assign topics for each web page: (1) We retrieve a set of web pages to construct a corpus and then\nuse LDA to learn topic structures from the corpus. (2) For each web page, the learned topic model in the previous step\nis used to infer the topic proportion and topic assignment based on the textual content of the page. (3) The topic with highest probability from the topic distribution is selected as the representative topic of the page. We use T = {t1, ..., tm } to denote the set of learned topics. Then each link in the browsing historyHu is mapped to a topic in the topic set, tl \u2208 T . Matrix Tu \u2208 Rn\u00d7m is then used to represent the link-topic relationship for all the links in Hu where Tui j = 1 indicates that i-th link of user u is correlated to the topic tj . The problem of anonymizing browsing history of useru is then formally defined as:\nProblem 2. Given user u\u2019s browsing historyHu , and link-topic matrix Tu , we seek to learn an anonymizer f to create a manipulated browsing history H\u0303u by adding links to Hu to preserve the privacy of user u while keeping the utility of H\u0303u for future applications.\nf : {Hu ,Tu } \u2192 {H\u0303u } (1)\nWe stress that links cannot be removed from the browsing history as all of user\u2019s activities have been already recorded by ISPs."
        },
        {
            "heading": "4 A FRAMEWORK FOR PRIVACY BOOSTING",
            "text": "The goal of the web browsing history anonymizer is to manipulate the user\u2019s browsing history by adding links in a way that: 1) user privacy is preserved even when the adversary publishes the data with the weakest level of anonymization (i.e., just removing PIIs) and 2) browsing history still demonstrates user\u2019s preferences so that the quality of personalized online services is preserved.\nAn immediate solution that may come to mind is to add links from popular web sites. This approach cannot preserve privacy as the adversary can easily remove popular links from the history and then deploy the attack. Another solution could be adding links from the browsing history of users who are very similar to u, i.e., his friends in social media. This approach can preserve the utility of browsing history but fail to make the user robust to the adversary attack. This is also observed in [36] where it was shown that the\nmore a user\u2019s history contains links from his friends\u2019 browsing activities in social media, the more fingerprints he leaves behind. All these emphasize the need for an effective solution which can handle the utility-privacy trade-off.\nIn this section we will discuss how our proposed algorithm PBooster, can handle utility-privacy trade-off. To better guide the PBooster and to assess the quality of the altered history, we need measures for quantifying the effect of adding links on user privacy and utility. We first present these measures and then detail the PBooster."
        },
        {
            "heading": "4.1 Measuring User Privacy",
            "text": "The best case for user privacy is when a user\u2019s visited links (i.e., interests) are distributed uniformly over different topics. This improves the user privacy by increasing ambiguity of his interests distribution. This makes it harder for the adversary to infer the real characteristic of the user\u2019s preferences and then re-identify him by mapping his anonymized information to a real profile. Entropy is a metric which measures the degree of ambiguity. We leverage the entropy of the user\u2019s browsing history distribution over a set of predefined topics as a measure of privacy.\nWe first introduce the topic-frequency vector cu \u2208 Rm\u00d71 as \u27e8cu1, cu2, ..., cum\u27e9 for each user u, where cuj is the number of links in u\u2019s history related to the topic tj . Note that \u2211m j=1 cuj = |Hu | where |.| denotes the size of a set. The topic probability distribution for each user can be then defined as pu = J (cu ) = \u27e8pu1,pu2, ...,pum\u27e9 where J is the normalization function of input vector cu where puj = cuj |Hu | and \u2211m j=1 puj = 1. The privacy of user u, which is the degree of ambiguity of his browsing history, can be captured by the entropy of the topic probability distribution pu . This measures the spread of the user\u2019s interests across different topics. Given topic probability distribution, privacy is measured as:\nPrivacy(pu ) = \u2212 m\u2211 j=1 puj logpuj (2)\nThe higher this metric is, the greater the user privacy. The optimal value of this measure is thus achieved when the user\u2019s browsing links topics are distributed uniformly across the set of topics."
        },
        {
            "heading": "4.2 Measuring Utility Loss",
            "text": "Utility or quality of online services is a measurement of a user\u2019s satisfaction from the online personalized services he receives based on his online activities. Thismeasurement should be able to estimate the loss of quality of services after manipulating the user\u2019s browsing history by the PBooster. We quantify utility loss as the difference between a user\u2019s topic distribution before and after browsing history manipulation. Finding the difference between topic distributions has been exploited in other applications such as recommender systems [22]. We use the same notion used in [22] and quantify the utility loss between pu and p\u0302u as:\nutilityloss (pu , p\u0302u ) = 0.5 \u00d7 (1 \u2212 sim(pu , p\u0302u )) (3)\nwhere p\u0302u denotes the new topic probability after manipulating history. One typical choice for the sim is cosine similarity [22]:\nsim(pu , p\u0302u ) = pu .p\u0302u \u2225pu \u2225.\u2225p\u0302u \u2225\n(4)\nSince sim \u2208 [\u22121, 1], the output of utilityloss function will be in [0, 1]. According to this measure, the minimum value for utility loss is when pu = p\u0302u and the maximum is reached when p\u0302u does not have any non-zero value in common with pu .\n4.3 PBooster Algorithm We have discussed so far how to quantify a user\u2019s utility and privacy according to his browsing history. The goal is now to find a set of new links A to add to the browsing history such that, 1) privacy(p\u0302u ) is as large as possible, and 2) utilityloss (pu , p\u0302u ) is as small as possible. However, as we discussed earlier, the optimal value for privacy is reached when the user\u2019s interests are spread uniformly across different topics, while the utility loss is minimized when no changes have been done to the topic distribution pu . This raises a trade-off issue between user\u2019s privacy and utility loss. Simply put, maximizing privacy results in the loss of utility and vice versa. In order to optimize the trade-off between utility loss and privacy for each user u, we define a new scalar objective function:\nG(J (cu ), J (c\u0302u ), \u03bb) = \u03bb \u2217 privacy(J (c\u0302u )) \u2212 utilityloss (J (cu ), J (c\u0302u )) (5)\nwhere c\u0302u is the topic-frequency vector after manipulating browsing history and \u03bb controls the contribution of privacy in G. We aim to find a set of linksA by solving the following optimization problem:\nA\u2217 = argmax A G(J (cu ), J (c\u0302u ), \u03bb) (6)\nwhere c\u0302u could be made from H\u0303u = Hu \u222a A. Topic distribution p\u0302u is constructed from c\u0302u accordingly. It\u2019s notable to say that the value of \u03bb has impact on the inferred set of linksA\u2217 in a sense that larger values of \u03bb will lead to a browsing history H\u0303u with higher privacy while lower \u03bb values result in lower utility loss.\nIt is worthwhile to mention that the search space for this problem (Eq.6) is exponential to N (O(m \u00d7 2N )), where N is the maximum of the number of links w.r.t. a topic. Considering this fact, it can be expensive and even infeasible to search for the optimal solution. We thus decide to approach this problem in an alternative way. We divide the optimization problem in Eq.6 into two subproblems : (1) Topic Selection: Selecting a subset of topics and calculating\nthe number of links which should be added to each topic in order to maximize the function G as follows:\na\u2217 = argmax a G(J (cu ), J (c\u0302u ), \u03bb) (7)\nwhere a = \u27e8a1, ..,am\u27e9 \u2208 Rm\u00d71 such that each non-zero element ai indicates the number of to-be added new links which are related to the topic ti . Zero value means that none of the new links are associatedwith the topic ti . Consequently, c\u0302u is defined as c\u0302u = \u27e8cu1 +a1, .., cum +am\u27e9. This step indicates the number of links which should be added to each topic to maximize G. (2) Link Selection: Selecting a proper set of links which corresponds to the identified topics and their numbers found in the previous step.\nTo recap, the PBooster algorithm anonymizes a user\u2019s browsing history by first selecting a subset of topics with the proper number of links for each topic (topic selection phase) and then finding corresponding links for each of them (link selection phase). Next, we will discuss the possible solutions for each step."
        },
        {
            "heading": "4.4 Topic Selection",
            "text": "One brute-force solution to the optimization problem in Eq.7, is to evaluate all possible combinations of a set of topics with different sizes to find the best a\u2217. The exponential computational complexity of this algorithm makes it unacceptable and even impractical when quick results are required. We thus need a more efficient solution.\nAccording to a recent study [16], having more information in the browsing history will not necessarily increase either the utility or the privacy. In other words, with large information available on user\u2019s preferences, observing a new link would have little to no impact on enhancing utility and privacy of the user. Simply put, adding more data to the history, could make the user less secured, with no specific improvement observed in the utility. The submodularity concept formally captures this intuition. A real valued function f is submodular if for a finite set E and two of its subsets X, Y where X \u2286 Y \u2286 E, and e \u2208 E\\Y , the following property holds:\nf (X \u222a {e}) \u2212 f (X) \u2265 f (Y \u222a {e}) \u2212 f (Y) (8) This means that adding one element {e} to the set X increases f more than adding {e} to the setY which is superset of X [28]. This intuitive diminishing return property exists in different areas such as social media networks and recommender systems. Recall from Eq. 5 that the function G is consisted of two components, namely privacy and utility loss. Given \u03bb \u2208 [0, 1] and topic-frequency vector cu , we can rewrite the optimization problem in Eq.7 as:\nargmax a \u2212 \u03bb( \u2211 j p\u0302uj logp\u0302uj ) \u2212 0.5 \u00d7 (1 \u2212 \u2211 j puj p\u0302uj\u221a\u2211\nj p 2 uj \u221a\u2211 j p\u0302 2 uj )\nsubject to \u2212 c\u0302uj \u2264 \u2212cuj , c\u0302uj \u2208 N0\n(9)\nwhere p\u0302uj = c\u0302uj | H\u0303u |\nis the topic probability distribution after applying PBooster. Privacy is calculated using the entropy function which is submodular in the set of random variables [20]. The defined utility loss is also naturally submodular [22]. Since nonnegative linear combinations of submodular functions are submodular as well, the objective functionG is submodular.G is also non-monotone and thus the problem in Eq.9 is equal to maximizing a non-monotone nonnegative submodular function. This problem has been shown to be NP-hard [13] and there is no optimal solution for it in an efficient amount of time.\nHowever, the problem ofmaximizing non-monotone non-negative submodular function has been solved earlier [13]. A greedy local search algorithm, LS, has been introduced for solving this problem which was proved to guarantee a near-optimal solution. The greedy LS achieved a value of at least 13 of the optimal solution [13]. Formally speaking, if we assume solution aG is provided by the greedy LS algorithm, and \u02c6cG = cu + aG , and the optimal solution is aOPT, and OPT(cu ) = cu + aOPT, the following theorem holds:\nTheorem 4.1. If G(., .) is a nonnegative non-monotone submodular function, the set of topics aG found by the greedy algorithm has\nAlgorithm 1 Greedy local search for topic selection Input: topic-frequency vector cu , \u03bb, \u03f5 Output: a = \u27e8a1,a2, ...,am\u27e9 1: Initialize a = \u27e80, 0, ..., 0\u27e9, c\u0302u = cu + a and val \u2190\u2212 0 2: while there is increase in in value of G(J (cu ), J (c\u0302u ), \u03bb) do 3: Select tj , j \u2208 {1, ...,m} such that by updating aj \u2190\u2212 aj + 1\nand c\u0302u = cu + a, then G(J (cu ), J (c\u0302u ), \u03bb) is maximazed 4: Update val \u2190\u2212 G(J (cu ), J (c\u0302u ), \u03bb) 5: if \u2203 tj such that updating aj \u2190\u2212 aj + 1 and c\u0302u = cu + a\nresults in G(J (cu ), J (c\u0302u ), \u03bb) > (1 + \u03f5n2 ). val then 6: Update aj \u2190\u2212 aj + 1 , val \u2190\u2212 G(J (cu ), J (c\u0302u ), \u03bb) 7: Repeat from step 5 8: end if 9: if \u2203 tj such that aj \u2265 1 and updating aj \u2190\u2212 aj \u2212 1 and\nc\u0302u = cu + a results in G(J (cu ), J (c\u0302u ), \u03bb) > (1 + \u03f5n2 ). val then 10: Update aj \u2190\u2212 aj \u2212 1 , val \u2190\u2212 G(J (cu ), J (c\u0302u ), \u03bb) 11: Repeat from step 5 12: end if 13: end while\nthe following lower bound [13]:\nG(J (cu ), J (c\u0302u ), \u03bb) \u2265 ( 1 3 \u2212 \u03f5 n )G(J (cu ), J (OPT(cu )), \u03bb) (10)\nHere, \u03f5 > 0 is a small number. Local search algorithm iteratively adds an element to the final set or removes one from it to increase the value of G until no further improvement can be achieved. Algorithm 1 shows the topic selection algorithm which deploys the greedy local search. Elements of a = \u27e8a1, ..,am\u27e9 will be increased or decreased iteratively to increase value of G until it cannot be improved anymore.\nWe emphasize that according to [13], there is no efficient algorithm which could select the best set of links to maximize aggregation of both privacy and utility in polynomial time. Following the Theorem 4.1, the proposed greedy algorithm can select a set with a lower bound of 13 of the optimal solution, providing the maximum user privacy and utility in polynomial time."
        },
        {
            "heading": "4.5 Link Selection",
            "text": "Previously, we discussed the solution for selecting a subset of topics and the proper number of links for each topic to preserve user privacy while keeping the new topic distribution as close as possible to the original one. The second step in PBooster is to select links which correspond to the selected set of topics. Let us assume that user u has at least one active6 account on a social media site and PBooster has access to the list of user\u2019s friends Fu , \u2205.\nWe propose the following solution for the link selection problem. For each single update \u03c9 in the vector a, we randomly select a user v with a public social media profile from outside of the list of u\u2019s friends, v < Fu . We then simulate v\u2019s browsing historyH \u2032v , with the size of |H \u2032v | = q. The detail of this simulation is discussed in the next section. Link-topic relation matrix Tv will be constructed from the historyH \u2032v . If there is no link inH \u2032v which corresponds to the topic of \u03c9, then the process will be repeated for another 6Here, user activity does not refer to posting contents. In this work, we assume a user as active if he visits his feed and have non-empty list of friends.\nAlgorithm 2 Link selection\nInput: Fu , q, a = \u27e8a1,a2, ...,am\u27e9 Output: Set of links A 1: A = \u2205 2: for each update \u03c9 in a do 3: Let tj be the corresponding topic of update \u03c9 4: Select a user v randomly such that v < Fu 5: Simulate a browsing historyH \u2032v for v with the size of q.\nMake cv and link-topic matrix Tu fromH \u2032v 6: if cv j = 0 then : Go to line 4 and repeat, else 7: Select a non-zero row r randomly from Tv [:, j] 8: Select corresponling link l to row r 9: A = A \u222a {l} 10: end if 11: end for\nrandom user, otherwise, a random related link will be chosen. The pseudocode of this algorithm is shown in Algorithm 2.\nTo recap, PBooster uses the greedy local search algorithm for submodular maximization to first find the topics which need to be updated and then infer the number of links which should be added to those topics in a way that user privacy and utility is maximized."
        },
        {
            "heading": "5 EXPERIMENTAL EVALUATION",
            "text": "In this section we conduct experiments to evaluate the effectiveness of PBooster in terms of both privacy and utility. In particular, we seek to answer the following questions: (1) how successful is the proposed defense in protecting users\u2019 privacy? (2) how does PBooster affect the quality of online services? (3) how successful is PBooster in handling privacy-utility trade-off?"
        },
        {
            "heading": "5.1 Dataset",
            "text": "Su et al. [36] evaluate their de-anonymization strategy by examining it on a set of synthetically generated histories as well as real, usercontributed web browsing histories. Synthetic history is generated for a set of users based on their activities in social media. These users are selected semi-randomly from social media real-time streaming API\u2013 the more active a user is, the more likely he is to be chosen. The histories are simulated in a way that mimic users\u2019 real online behaviors\u2013they mostly click on links posted to their news feed, and sometimes click on links posted by their friends-of-friends [36]. These friends-of-friends links may be clicked due to the organic exploration behavior of people or the Social media\u2019s algorithmic recommendation system that tries to get users visit their friendsof-friends links [35]. Their results on real user generated browsing history is consistent with the results of synthetic histories. This confirms the procedure of simulating synthetic browsing history as well as the efficiency of the generated data [36].\nSimilar to Su et al [36], we examine the performance of PBooster on a set of synthetically generated browsing history. We follow the same procedure as in [36] to simulate the browsing history dataset. To generate the synthetic history for each user u, friend\u2019s links and friends-of-friends\u2019 links are generated accordingly [36]. Friends\u2019 links are generated by pulling links from a randomly selected friend of u. Friends-of-friends\u2019 links are also generated by first picking\none of u\u2019s friends, say v , uniformly at random, and then pulling a link from one ofv\u2019s friends. Following [36], we select Twitter as the source of users\u2019 activities to simulate data because of two reasons. First, many users activities on Twitter are public, and second Twitter has real-time API which helps avoid the need for large-scale web crawling. We select a total number of 1200 users and following [36], we generate histories of various sizes including {30, 50, 100} for each user. For each history, 16% of links are from friends-of-friends and the rest are from friends. Note that we only select links that are related to web pages in English to make the textual analysis easier."
        },
        {
            "heading": "5.2 Experiment Setting",
            "text": "To simulate the real-world browsing situation, we divide the browsing history into |H\nu | h batches of links with size of h. These batches\nwill be added to the history incrementally and PBooster will anonymize the updated history after taking each batch. We set the values h = 25, q = 20 (used in link selection algorithm) and trade-off coefficient \u03bb = {0, 0.1, 0.5, 1, 10, 20, 50, 70, 100}. We use LDA topic modeling from Python package gensim [30] and set the number of topicsm = 20 and LDA parameters \u03b1 = 0.05, \u03b2 = 0.05. We compare PBooster with the following baselines: \u2022 Random: Assuming x new links are added by PBooster, this approach selects x links randomly from the browsing history of users who are not fromu\u2019s friends. Note that this method does not consider the topics of the links. We compare our model against this method to investigate whether the topics of the chosen links will have effect on the privacy of the users, or in other words, how well topic selection technique in Algorithm 1 performs? \u2022 JustFriends: This approach is quite similar to PBooster except that in the link selection phase, it adds links from a user\u2019s friends\u2019 simulated browsing history. We use this method to see how well our link selection technique in Algorithm 2 performs. \u2022 ISPPolluter7: The goal of this method is to eliminate the mutual information between actual browsing history and the manipulated one. According to [39] mutual information vanishes if:\nnNoise \u2265 (nCalls \u2212 1) \u00d7 nPossibleCall (11) where nPossibleCall is the number of domains that a user might visit per day, and nCalls is the number of visited domains. For instance, if a user visits 100 domains and requests 200 calls per day, then ISPPolluter adds 20,000 links randomly to the history. We choose this method to see if eliminating mutual information can preserve privacy in practice."
        },
        {
            "heading": "5.3 Privacy Analysis",
            "text": "To answer the first question, we first compare each user\u2019s privacy before and after anonymization for browsing histories with size 100 (|Hu | = 100). Fig. 1 depicts box plots of the distributions of users\u2019 privacy measured using Eq.2. The privacy-utility trade-off coefficient \u03bb is also fixed to \u03bb = 10. Results demonstrate how privacy increases after deploying PBooster in comparison to JustFriends approach and original history. This shows that adding links from friends cannot make significant change in privacy. This is because of Homophily effect [24]. The Random technique leads to the most uniform topics distribution and thus highest privacy among others. 7https://github.com/essandess/isp-data-pollution\nWe now evaluate the efficiency of PBooster against the deanonymization attack introduced in [36]. We measure the attack success rate by the metricX% = ncN \u00d7100where nc is the total number of users that have been successfully mapped to their Twitter accounts, and N indicates the total number of users in the dataset. We consider the attack as successful if the user is among the top 10 results returned by the attack. Lower values of this measure translates to the higher privacy and stronger defense. We evaluate all methods on histories with different sizes. The results for browsing histories with different \u03bb are demonstrated in Fig. 2. Note due to the lack of space, we have removed the similar trend that we observed for |Hu | = 30. We observe the following: \u2022 ISPPolluter does not work properly in practice and is not robust to the attack which leverages traces of users\u2019 activities in social media. This confirms the idea of selecting links from non-friend users which inhibits the adversary to find the targeted user.\n\u2022 Random is more robust to the attack than PBooster and JustFriends. This demonstrates that adding random links from nonfriends could perform better in terms of privacy. \u2022 JustFriends decreases the privacy in comparison to the original history. This aligns well with the observations of [36] suggesting that adding links from friends can even decrease the privacy. \u2022 Attack success rate decreases to 15% after applying PBooster. We conclude that the generated history from PBooster is more robust to the attacks in comparison to original history and those generated from JustFriends and ISPPOlluter. This confirms the effectiveness of PBooster for preserving privacy. \u2022 PBooster performs better when |Hu | = 100. This means larger history can help PBooster to model user\u2019s interests better and manipulate the history accordingly. \u2022 PBooster is much more robust than JustFriends. This clearly shows the efficiency of the link selection approach. \u2022 In PBooster,the attack success rate first decreases with the increase of \u03bb and then it gets almost stable (for \u03bb \u2265 10). This makes the selection of \u03bb easier and suggests that the privacy will not increase significantly after some point, confirming that adding more links does not always necessarily lead to more privacy. \u2022 By deploying PBooster, the attack success rate decreases even when \u03bb slightly changes from 0 to 0.1, which confirms the effectiveness of PBooster in anonymizing browsing histories. To study the effect of h (size of batches of links in browsing history), we repeat the attack with different values of h for |Hu | = 100 with \u03bb = 10 which was empirically found to work well in our problem. Results are demonstrated in Table 1 suggesting that increasingh can help to model users\u2019 preferences more accurately and PBooster can further decrease the traceability of users by making\nthe profiles more ambiguous. Although this increases the privacy, it increases the anonymization waiting time which could result in sudden publishing of history without proper anonymization."
        },
        {
            "heading": "5.4 Utility Analysis",
            "text": "To answer the second question, we investigate the utility of the manipulated histories to estimate the change in quality of services. We evaluate the utility of manipulated history via a well-known machine learning task, i.e. clustering. Prior works [31, 37] have indicated the benefits of applying clustering in personalization which can help to offer similar services to same cluster of people.\nWe use k-means to cluster users into k = 5 groups based on their topic preferences distribution p\u0302u . We evaluate the utility of browsing histories according to the quality of generated clusters via Silhouette coefficient. Silhouette coefficient ranges from [\u22121, 1], where a higher value indicates better clusters while a negative value indicate that a sample has been assigned to the wrong cluster. Values near zero indicate overlapping clusters (i.e., all users are similar to each other). The results are demonstrated in Fig.3. The same trend was observed for |Hu | = 30 but we remove it due to space limitations. We make the following observations: \u2022 Clusters by ISPPolluter has the lowest Silhouette coefficient close to 0 (i.e., clusters are almost overlapping). This shows that adding a large number of random links results in making all users similar to each other and thus severe utility degradation. \u2022 The quality of clusters formed by Random decreases by increasing \u03bb. This confirms that adding links randomly decreases the utility of browsing history and thus shows the importance of the topic and link selection phases. \u2022 JustFriends can even increase the utility of the manipulated browsing history. This is not surprising and the reason is that friends havemore similar tastes to each other than random people (Homophily effect [24]). Therefore, adding links from a friends\u2019 history will not change the preferences distributions significantly. Utility also improves slightly with increase in value of \u03bb. \u2022 Generated history by PBooster has better quality when |Hu | = 100 in comparison to |Hu | = 50. This shows that PBooster works better when more user\u2019s information is fed to it. \u2022 The quality of clusters by PBooster decreases with increase in value of \u03bb. The change is even sensible when \u03bb \u2265 20. \u2022 The quality of data generated by PBooster is comparable to the original data when \u03bb \u2264 10. Moreover, PBooster reaches the optimal point in privacy-utility trade-off by fixing \u03bb = 10.\nWe repeat k-means with different values of h for |Hu | = 100 with \u03bb = 10. Results are demonstrated in Table 2 and suggest that increasing h will lead to more accurate representation of users and thus improvement in the utility of data. However, as discussed earlier, the main drawback with increasing value of h is increasing the risk of sudden history publishing without proper anonymization."
        },
        {
            "heading": "5.5 Privacy-Utility Trade-off",
            "text": "To answer the third question, we plot the privacy and utility gain values for each user after applying different approaches over histories with size 100. We measure the privacy by Eq.2 and utility gain as 1 \u2212 utilityloss using the Eq.3. Different colors and markers represent different approaches. Each marker represents a user, with measures over his manipulated history with h = 25 and \u03bb = 10. \u2022 The original history gains the utility of 1 and the privacy to some extent. Random reaches the highest privacy but loses utility. JustFriends results in higher data utility gain in comparison to other methods but reaches a lower level of privacy. The result of PBooster varies for different users, achieving different levels of privacy and utility according to their original browsing behavior, whereas all users gain similar level of privacy by Random. \u2022 Users achieve higher privacy with PBooster than the original data comparing with other approaches. The achieved utility by PBooster is more than the utility by Random but less than the utility by JustFriends. The reason lies at the intrinsic trade-off between utility and privacy\u2013higher privacy results in less utility. We compare the privacy and utility of browsing history manipulated by different techniques demonstrated in Fig.2 and Fig.3: \u2022 JustFriends achieves the highest utility among all approaches while it is the most vulnerable method. Random approach is the most robust technique against de-anonymization attack, however has the most utility lost. PBooster provides high privacy but can sacrifice utility for high values of \u03bb (\u03bb \u2265 20). \u2022 PBooster is the most efficient approach in terms of both privacy and utility. Setting \u03bb = 10, it returns the highest possible privacy while maintaining comparable utility with the original data."
        },
        {
            "heading": "6 CONCLUSION AND FUTUREWORK",
            "text": "The need arises for users to protect their sensitive information such as browsing history from potential adversaries. Some users resort to Tor, VPN and HTTPS to remove their traces from browsing history to assure their privacy. However, these solutions may hinder personalized online services by degrading the utility of browsing\nhistory. In this study, we first quantified the trade-off between user privacy and utility and then proposed an efficient framework PBooster to address the problem of anonymizing web browsing histories while retaining the utility. Our experiments demonstrate the efficiency of the proposed model by increasing the user privacy and preserving utility of browsing history for future applications. In future, we would like to investigate personalized utility-privacy trade-off, by tweaking framework parameters to fit specific needs of each user. We also plan to replicate the work by exploring other mechanisms for anonymizing web browsing histories. Last but not least, we would also like to collect real-world data and investigate the efficiency of PBooster in terms of both privacy and utility in practice."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This material is based upon the work supported, in part, by NSF #1614576, ARO W911NF-15-1-0328 and ONR N00014-17-1-2605."
        }
    ],
    "title": "Protecting User Privacy: An Approach for Untraceable Web Browsing History and Unambiguous User Profiles",
    "year": 2018
}