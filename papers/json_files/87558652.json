{
    "abstractText": "In this paper, we propose a method called Convolutional Neural Network-Markov Random Field (CNN-MRF) to estimate the crowd count in a still image. We first divide the dense crowd visible image into overlapping patches and then use a deep convolutional neural network to extract features from each patch image, followed by a fully connected neural network to regress the local patch crowd count. Since the local patches have overlapping portions, the crowd count of the adjacent patches has a high correlation. We use this correlation and the Markov random field to smooth the counting results of the local patches. Experiments show that our approach significantly outperforms the state-of-the-art methods on UCF and Shanghaitech crowd counting datasets. Code available on GitHub https://github.com/hankong/crowdcounting.",
    "authors": [
        {
            "affiliations": [],
            "name": "Kang Han"
        },
        {
            "affiliations": [],
            "name": "Wanggen Wan"
        },
        {
            "affiliations": [],
            "name": "Haiyan Yao"
        },
        {
            "affiliations": [],
            "name": "Li Hou"
        }
    ],
    "id": "SP:57134802c1f04bf5b5b7568bc340e2d83933f9cd",
    "references": [
        {
            "authors": [
                "S.A.M. Saleh",
                "S.A. Suandi",
                "H. Ibrahim"
            ],
            "title": "Recent survey on crowd density estimation and counting for visual surveillance",
            "venue": "Engineering Applications of Artificial Intelligence, 41:103\u2013114",
            "year": 2015
        },
        {
            "authors": [
                "N. Dalal",
                "B. Triggs"
            ],
            "title": "Histograms of oriented gradients for human detection",
            "venue": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201905), volume 1, pp. 886\u2013893. IEEE",
            "year": 2005
        },
        {
            "authors": [
                "R. Stewart",
                "M. Andriluka",
                "A.Y. Ng"
            ],
            "title": "End-to-end people detection in crowded scenes",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2325\u20132333",
            "year": 2016
        },
        {
            "authors": [
                "Y. Yasuoka",
                "Y. Shinomiya",
                "Y. Hoshino"
            ],
            "title": "Simulation of Human Detection System Using BRIEF and Neural Network",
            "venue": "Journal of Advanced Computational Intelligence and Intelligent Informatics, 20(7):1159\u20131164",
            "year": 2016
        },
        {
            "authors": [
                "M. Junjie",
                "D. Yaping",
                "H. Kaoru"
            ],
            "title": "A Survey of Video-Based Crowd Anomaly Detection in Dense Scenes",
            "venue": "Journal of Advanced Computational Intelligence and Intelligent Informatics, 21(2):235\u2013 246",
            "year": 2017
        },
        {
            "authors": [
                "T. Ojala",
                "M. Pietikainen",
                "T. Maenpaa"
            ],
            "title": "Multiresolution grayscale and rotation invariant texture classification with local binary patterns",
            "venue": "IEEE Transactions on pattern analysis and machine intelligence, 24(7):971\u2013987",
            "year": 2002
        },
        {
            "authors": [
                "D.G. Lowe"
            ],
            "title": "Distinctive image features from scale-invariant key- Journal of Advanced Computational Intelligence 5 and Intelligent Informatics Han Kang",
            "venue": "et al. points\u201d, International journal of computer vision, 60(2):91\u2013110",
            "year": 2004
        },
        {
            "authors": [
                "Y. Zhang",
                "D. Zhou",
                "S. Chen",
                "S. Gao",
                "Y. Ma"
            ],
            "title": "Single-image crowd counting via multi-column convolutional neural network",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 589\u2013597",
            "year": 2016
        },
        {
            "authors": [
                "H. Idrees",
                "I. Saleemi",
                "C. Seibert",
                "M. Shah"
            ],
            "title": "Multi-source multiscale counting in extremely dense crowd images",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2547\u20132554",
            "year": 2013
        },
        {
            "authors": [
                "M. Li",
                "Z. Zhang",
                "K. Huang",
                "T. Tan"
            ],
            "title": "Estimating the number of people in crowded scenes by mid based foreground segmentation and head-shoulder detection",
            "venue": "Pattern Recognition, 2008. ICPR 2008. 19th International Conference on, pp. 1\u20134. IEEE",
            "year": 2008
        },
        {
            "authors": [
                "A.M. Cheriyadat",
                "B.L. Bhaduri",
                "R.J. Radke"
            ],
            "title": "Detecting multiple moving objects in crowded environments with coherent motion regions",
            "venue": "Computer Vision and Pattern Recognition Workshops, 2008. CVPRW\u201908. IEEE Computer Society Conference on, pp. 1\u2013 8. IEEE",
            "year": 2008
        },
        {
            "authors": [
                "G.J. Brostow",
                "R. Cipolla"
            ],
            "title": "Unsupervised bayesian detection of independent motion in crowds",
            "venue": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201906), volume 1, pp. 594\u2013601. IEEE",
            "year": 2006
        },
        {
            "authors": [
                "V. Lempitsky",
                "A. Zisserman"
            ],
            "title": "Learning to count objects in images",
            "venue": "Advances in Neural Information Processing Systems, pp. 1324\u20131332",
            "year": 2010
        },
        {
            "authors": [
                "C. Shang",
                "H. Ai",
                "B. Bai"
            ],
            "title": "End-to-end crowd counting via joint learning local and global count",
            "venue": "Image Processing (ICIP), 2016 IEEE International Conference on, pp. 1215\u20131219. IEEE",
            "year": 2016
        },
        {
            "authors": [
                "C. Zhang",
                "H. Li",
                "X. Wang",
                "X. Yang"
            ],
            "title": "Cross-scene crowd counting via deep convolutional neural networks",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 833\u2013841",
            "year": 2015
        },
        {
            "authors": [
                "M. Rodriguez",
                "I. Laptev",
                "J. Sivic",
                "J.-Y. Audibert"
            ],
            "title": "Densityaware person detection and tracking in crowds",
            "venue": "2011 International Conference on Computer Vision, pp. 2423\u20132430. IEEE",
            "year": 2011
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "arXiv preprint arXiv:1512.03385",
            "year": 2015
        },
        {
            "authors": [
                "P.F. Felzenszwalb",
                "D.P. Huttenlocher"
            ],
            "title": "Efficient belief propagation for early vision",
            "venue": "International journal of computer vision, 70(1):41\u201354",
            "year": 2006
        },
        {
            "authors": [
                "A. Vedaldi",
                "K. Lenc"
            ],
            "title": "Matconvnet: Convolutional neural networks for matlab",
            "venue": "Proceedings of the 23rd ACM international conference on Multimedia, pp. 689\u2013692. ACM",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "Keywords: crowd counting, convolutional neural network, Markov random field"
        },
        {
            "heading": "1. Introduction",
            "text": "In modern society, more and more people gather to live in the city. This lifestyle provides convenience for people\u2019s lives and improves the utilization rate of urban public resources. Meanwhile, a large number of people living in cities also led to urban congestion problems. This crowding phenomenon can be observed at traffic junctions, airports, stations, stadiums and other public places. Many accidents caused by overcrowding have led to many deaths, such as massive stampede happened in Shanghai Bund in 2015, where 36 persons died and 49 persons were injured. Therefore, automatic crowd density estimation and early warning for overcrowding are important to prevent such tragedies from happening again.\nExisting methods for people density estimation and counting of the crowd can be divided into two main categories: direct and indirect approaches [1]. The main idea of the direct approach (also called object detection based) is to detect and segment each individual in crowd scenes to get the total count, while the indirect approach (also called feature based) takes an image as a whole and extracts some features, and then get the final count through\nthe regression analysis of the extracted features. The advantage of the direct method is that people or head detection have been widely studied and applied, these methods can be easily adapted to the crowd of few tens [2\u20134]. However, a crowd of more than hundreds does not have a well-defined shape as a single object does, so the direct detection method is not applicable. In this scene, the indirect methods are generally more reliable and efficient, since the overall features of a crowd image are easier to obtain and have a stronger correlation with the number of people. Some surveys of these methods can be seen in [5].\nIn this paper, we focus on the indirect method to estimate the crowd count of more than hundreds. Like other computer vision tasks, features extraction is the first step and the most important step in the crowd counting problem. Many hand-crafted computer vision features have been used to represent the density of the crowd, such as Local Binary Patterns (LBP) [6], Scale Invariant Feature Transform (SIFT) [7] and Histogram of Oriented Gradient (HOG) [2]. However, due to the variation of viewpoint, scene and crowd count, these hand-crafted features can not represent the crowd density discriminatively. In recent years, with the advancement of deep learning in computer vision, some researchers try to apply deep learning to crowd density estimation and achieved state-of-the-art results [8]. Different with the hand-crafted features extraction which follows the certain steps, deep learning can automatically learn the features from the data. Following the certain steps means that the features will not be better with the increase of the data, while deep learning can learn more discriminative features from abundant data.\nSome auxiliary methods are also used to improve the accuracy of the crowd density estimation. For example, in the crowd of more than hundreds, the density of crowd is continuously gradient, so MRF can be used to smooth the counting between adjacent patches [9].\nInspired by the superior feature representation of deep learning and the smoothness of MRF, we propose a CNN and MRF based framework for the problem of people counting in still images. Firstly, we divide the image into patches with overlaps and use a pre-trained CNN model to extract deep features from each overlapping patch, followed by a fully connected deep neural network to regress the patch people count. Finally, we use MRF to smooth the counts of adjacent patches in order to make the counts closer to the true value. The reason is that the overlap be-\nJournal of Advanced Computational Intelligence 1 and Intelligent Informatics\nar X\niv :1\n70 6.\n03 68\n6v 3\n[ cs\n.C V\n] 1\n7 O\nct 2\n01 7\nHan Kang. et al.\ntween the adjacent patches leads to the people count of adjacent patches keep a certain consistency.\nThe rest of the paper is organized as follows. In Section 2, we briefly review the related work of crowd density estimation and counting. And then the system architecture and the implement detail of the proposed approach will be illustrated in Section 3, followed by the experiment in Section 4. Finally, Section 5 concludes our paper."
        },
        {
            "heading": "2. Related work",
            "text": "Direct method. Li et al [10] proposed a people count estimation method combining the foreground segmentation and the head-shoulder detection. A Mosaic Image Difference based foreground segmentation algorithm is performed first to detect active areas, and then a headshoulder detection algorithm is utilized to detect heads and count the number from the detected foreground areas. Cheriyadat et al [11] presented an object detection system based on coherent motion region detection for counting and locating objects in the presence of high object density and inter-object occlusions. They used the locations of tracked low-level feature points to construct all possible coherent-motion-regions and chose a good disjoint set of coherent motion regions representing individual objects using a greedy algorithm. Brostow et al [12] described an unsupervised data-driven Bayesian clustering algorithm to detect individual entities. The method tracked simple image features and probabilistically group them into clusters representing independently moving entities.\nIndirect method. Lempitsky et al [13] used dense SIFT features and Maximum Excess over SubArrays distance as a loss function to train a regression model on randomly selected patches. In order to adapt to the change of the crowd density and perspective, Zhang et al [8] proposed a Multi-column CNN architecture to map the image to its crowd density map. The network structure included three parallel CNN with different sizes to extract features from different scales. The features learned by each column CNN were adaptive to variations in people/head size due to perspective effect or image resolution. Shang et al [14] proposed an end-to-end CNN architecture that directly maps the whole image to the counting result. A pretrained GoogLeNet model was used to extract high-level deep features and the long-short time memory (LSTM) decoders for the local count and fully connected layers for the final count. A cross-scene crowd counting architecture was proposed by Zhang et al [15]. Firstly, they trained a deep CNN with two related learning objectives, crowd density, and crowd count. And then a data-driven method was introduced to fine-tune the learned CNN to an unseen target scene, where the training samples similar to the target scene were retrieved from the training scenes for fine-tuning.\nSome researchers tried to combine two methods to get a more accurate estimate count. Idrees et al [9] proposed a multi-source multi-scale counting method to compute an estimation of the number of individuals presented in\nan extremely dense crowd visible in a single image. This method combined the detection approach (low confidence head detection) and the features regression approach (repetition of texture element and frequency-domain analysis) to solve the perspective, occlusion, clutter and few pixels per person problems in a crowd of more than hundreds. Then the spatial consistency constraints are employed by MRF to smooth the counting between adjacent patches. Rodriguez et al. [16] addressed the problem of person detection and tracking in crowded video scenes. They explored constraints imposed by the crowd density and formulate person detection as the optimization of a joint energy function combining crowd density estimation and the localization of individual people."
        },
        {
            "heading": "3. Proposed Method",
            "text": "For dense crowd images, the distribution of crowd density is rarely uniform due to changes in perspective and scene. Some example images can be seen in Fig. 1. Therefore, it is unreasonable to count the crowd by taking the image as an entirety. So our framework adapted the divide-count-sum strategy. The images are firstly divided into patches, then a regression model is learned to map the image patch to the local count. Finally, the global image count is computed as the total sum over these patches. The image segmentation has two advantages: Firstly, in the small image patches, the crowd density is approximately uniform distribution. Secondly, the segmentation of image increases the number of training data for the regression model. The above advantages allow us to train a more robust regression model.\nEven though the distribution of crowd density is not uniform, the overall crowd density distribution is continuous. This means that the density of adjacent image patches should be similar. Furthermore, we divide the image with overlaps, which enhances the association between image patches. The Markov random field is used to smooth the estimation count between overlapping image patches to compensate for the possible estimation errors of the image patches and to bring the overall result closer to the true density distribution. The overview of the proposed method can be seen as Fig. 2.\n2 Journal of Advanced Computational Intelligence and Intelligent Informatics\nImage Crowd Counting Using CNN and MRF"
        },
        {
            "heading": "3.1. Patches counting",
            "text": "We use a pre-trained deep residual network to extract features from image patches and a fully connected neural network to learn a map from the above features to the local count. The features learned from deep convolutional networks have been used for many computer vision tasks such as image recognition, object detection, and image segmentation [17]. This indicates that the features learned from the deep convolutional network are universal to many computer vision tasks. With the increase in the number of network layers, the representation ability of the learned features becomes stronger. However, a deeper model means that more data is needed for training. The existing crowd counting datasets are not large enough to train a very deep convolutional neural network from scratch. So we use a pre-trained deep residual network to extract features from image patches. The deep residual network was proposed by He et al. [17]. Their method addressed the degradation problem by reformulating the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We employ the residual network, which is trained on ImageNet dataset for image classification task, to extract the deep features to represent the density of the crowd. This pre-trained CNN network created a residual item for every three convolution layer to bring the layer of the network to 152. We resize the image patches to the size of 224 \u00d7 224 as the input of the model and extract the output of the fc1000 layer to get the 1000 dimensional features.\nThe features are then used to train 5 layers fully connected neural network. The network\u2019s input is 1000- dimensional, and the number of neurons in the network is given by 100-100-50-50-1. The network\u2019s output is the local crowd count. The learning task of the fully connected neural network is to minimize the mean squared error of the training patches, which can be written as:\nLoss = \u221a 1 M M \u2211 i=1 (cg\u2212 cr)2 . . . . . . . . (1)\nwhere M is the number of the training image patches and cg and cr are the ground truth count and the regression count of the image patches, respectively."
        },
        {
            "heading": "3.2. Images counting",
            "text": "Due to the overlapping of the adjacent image patches, there is a high correlation between adjacent local people count. This correlation can be used by the Markov random field to smooth the estimation count between adjacent image patches. As previously analyzed, the people count of adjacent images patches is generally similar and may change dramatically at some places due to buildings or other objects in the scene. This characteristic can be well modeled by the Markov random field. Formally, the Markov random field framework for the crowd counting can be defined as follows (we follow the notation in [18]). Let P be the set of patches in an image and C be a possible set of counts. A counting c assigns a count cp \u2208C to each patch p\u2208 P. The quality of a counting is given by an energy function:\nE(c) = \u2211 p\u2208P Dp(cp)+ \u2211 (p,q)\u2208N V (cp\u2212 cq) . . . (2)\nwhere N are the (undirected) edges in the four-connected image patch graph. Dp(cp) is the cost of assigning count cp to patch p, and is referred to as the data cost. V (cp\u2212cq) measures the cost of assigning count cp and cq to two neighboring patch, and is normally referred to as the discontinuity cost.\nFor the problem of smoothing the adjacent patches count, Dp(cp) and V (cp \u2212 cq) can take the form of the following functions:\nDp(cp) = \u03bbmin((I(p)\u2212 cp)2,DATA K) . . . (3)\nV (cp\u2212 cq) = min((cp\u2212 cq)2,DISC K) . . . (4)\nwhere \u03bb is a weight of the energy items, I(p) is the ground truth count of the patch p, DATA K and DISC K are the truncating item of Dp(cp) and V (cp \u2212 cq), respectively. The truncating item makes the cost function stop growing after the difference becomes large, which allows for large discontinuities. The above energy function minimization problem can be efficiently solved by belief propagation algorithm [18]. Fig. 3 shows the smoothing effect of the MRF on the local counting results. We can see that the density map is closer to the ground truth after smoothed by the MRF.\nJournal of Advanced Computational Intelligence 3 and Intelligent Informatics\nHan Kang. et al."
        },
        {
            "heading": "4. Experiments",
            "text": "We evaluate our method on UCF and Shanghaitech crowd counting datasets. Each image is divided with patch size 100 x 100 pixels and stride size 50 pixels. The final count of the whole image is obtained by calculating the sum of the count of all non-overlapping patches. If the image patch is on the edge and its previous image patch has been summed, then only half count of this image patch will be summed. The proposed method is implemented in Matlab, and we utilize MatConvNet [19], a Matlab toolbox implementing CNN for computer vision applications, which provides many pre-trained CNN model for image classification, segmentation, face recognition and text detection.\nWe utilize two evaluation criteria: the mean absolute error (MAE) and the mean squared error (MSE), which are defined as follows:\nMAE = 1 N\nN\n\u2211 i=1 |gi\u2212 ei| . . . . . . . . . . (5)\nMSE = \u221a 1 N N \u2211 i=1 (gi\u2212 ei)2 . . . . . . . . (6)\nwhere N is the number of test images and gi and ei are the ground truth and the estimate count of the i-th image, respectively."
        },
        {
            "heading": "4.1. UCF dataset",
            "text": "The UCF dataset [9] is a very challenging dataset because the scene of the each image are different and the crowd count of the image changes dramatically. More specifically, there are 50 images with counts ranging between 94 and 4543 with an average of 1280 individuals per image. The ground truth positions of individuals are marked by the authors and there is a total of 63705 annotations in the 50 images.\nFollowed by Idrees et al. [6], we use 5-fold crossvalidation to test the performance of our algorithm. Since the image of the UCF dataset is gray, we extend the image to three channels by copying the data. The counting result of our method and the comparison with other methods can be viewed in Table 1. The experimental results of other methods come from their papers and the same for Shanghaitech[8] dataset. We can see that our proposed CNNMRF outperforms the other methods, including the state of the art methods MCNN [8] and Shang et al. [14]. In Fig\n4 Journal of Advanced Computational Intelligence and Intelligent Informatics\nImage Crowd Counting Using CNN and MRF\n4, we compare the estimated count with the ground truth in more details. The images are divided into 10 groups according to crowd counts in an increasing order. The divide-count-sum strategy narrows the range of the crowd count so that the proposed method can give an accurate estimate of the total counts of the images at all ranges."
        },
        {
            "heading": "4.2. Shanghaitech dataset",
            "text": "Shanghaitech dataset [8] is a large-scale crowd counting dataset which contains 330,165 people heads annotation in 1,198 images. The dataset consists of two parts, Part A is collected from the Internet and Part B is taken from the busy streets of metropolitan areas in Shanghai. The average crowd count of the Part A is 501.4, and the average number of the Part B dataset is 123.6. The crowd density of Part A is significantly larger than that in Part B. This dataset has been randomly divided into training and testing: 300 images of Part A are used for training and the remaining 182 images for testing, and 400 images of Part B are for training and 316 images for testing. Table 2 reports the results of different methods in the two parts. LBP+RR [8] is a regression based method which uses Local Binary Pattern (LBP) features extracted from the original image as input and uses ridge regression (RR) to predict the crowd number for each image. Our method significantly outperforms state-of-the-art methods.\nSimilar to Fig 4, the comparison of the ground truth and the estimated count on Shanghaitech dataset can be seen in Fig 5. We can see that the proposed method can estimate the crowd count accurately and is robust to the large variation in crowd density. Some counting examples of the images with the associated ground truth counts can be seen in Fig 6."
        },
        {
            "heading": "5. Conclusion",
            "text": "We present a CNN-MRF based approach to counting the crowd in a still image from different scenes. The features extracted from the CNN model trained for other computer vision tasks show a strong ability to represent crowd density. With the overlapping patches divided strategies, the adjacent local counts are highly correlated. This correlation can be used by the MRF to smooth the adjacent local counts to obtain a more accurate overall count. Experimental results demonstrate that the proposed approach achieve superior performance compared with several recent related methods."
        },
        {
            "heading": "Acknowledgements",
            "text": "This research was partially supported by the National Nature Science Foundation of China (No.61373084).\nReferences: [1] S. A. M. Saleh, S. A. Suandi, and H. Ibrahim, \u201cRecent survey on\ncrowd density estimation and counting for visual surveillance\u201d, Engineering Applications of Artificial Intelligence, 41:103\u2013114, 2015.\n[2] N. Dalal and B. Triggs, \u201cHistograms of oriented gradients for human detection\u201d, In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201905), volume 1, pp. 886\u2013893. IEEE, 2005.\n[3] R. Stewart, M. Andriluka, and A. Y. Ng, \u201cEnd-to-end people detection in crowded scenes\u201d, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2325\u20132333, 2016.\n[4] Y. Yasuoka, Y. Shinomiya, and Y. Hoshino, \u201cSimulation of Human Detection System Using BRIEF and Neural Network\u201d, Journal of Advanced Computational Intelligence and Intelligent Informatics, 20(7):1159\u20131164, 2016.\n[5] M. Junjie, D. Yaping, and H. Kaoru, \u201cA Survey of Video-Based Crowd Anomaly Detection in Dense Scenes\u201d, Journal of Advanced Computational Intelligence and Intelligent Informatics, 21(2):235\u2013 246, 2017.\n[6] T. Ojala, M. Pietikainen, and T. Maenpaa, \u201cMultiresolution grayscale and rotation invariant texture classification with local binary patterns\u201d, IEEE Transactions on pattern analysis and machine intelligence, 24(7):971\u2013987, 2002.\n[7] D. G. Lowe, \u201cDistinctive image features from scale-invariant key-\nJournal of Advanced Computational Intelligence 5 and Intelligent Informatics\nHan Kang. et al.\npoints\u201d, International journal of computer vision, 60(2):91\u2013110, 2004. [8] Y. Zhang, D. Zhou, S. Chen, S. Gao, and Y. Ma, \u201cSingle-image crowd counting via multi-column convolutional neural network\u201d, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 589\u2013597, 2016. [9] H. Idrees, I. Saleemi, C. Seibert, and M. Shah, \u201cMulti-source multiscale counting in extremely dense crowd images\u201d, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2547\u20132554, 2013. [10] M. Li, Z. Zhang, K. Huang, and T. Tan, \u201cEstimating the number of people in crowded scenes by mid based foreground segmentation and head-shoulder detection\u201d, In Pattern Recognition, 2008. ICPR 2008. 19th International Conference on, pp. 1\u20134. IEEE, 2008. [11] A. M. Cheriyadat, B. L. Bhaduri, and R. J. Radke, \u201cDetecting multiple moving objects in crowded environments with coherent motion regions\u201d, In Computer Vision and Pattern Recognition Workshops, 2008. CVPRW\u201908. IEEE Computer Society Conference on, pp. 1\u2013 8. IEEE, 2008. [12] G. J. Brostow and R. Cipolla, \u201cUnsupervised bayesian detection of independent motion in crowds\u201d, In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201906), volume 1, pp. 594\u2013601. IEEE, 2006. [13] V. Lempitsky and A. Zisserman, \u201cLearning to count objects in images\u201d, In Advances in Neural Information Processing Systems, pp. 1324\u20131332, 2010. [14] C. Shang, H. Ai, and B. Bai, \u201cEnd-to-end crowd counting via joint learning local and global count\u201d, In Image Processing (ICIP), 2016 IEEE International Conference on, pp. 1215\u20131219. IEEE, 2016. [15] C. Zhang, H. Li, X. Wang, and X. Yang, \u201cCross-scene crowd counting via deep convolutional neural networks\u201d, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 833\u2013841, 2015. [16] M. Rodriguez, I. Laptev, J. Sivic, and J.-Y. Audibert, \u201cDensityaware person detection and tracking in crowds\u201d, In 2011 International Conference on Computer Vision, pp. 2423\u20132430. IEEE, 2011. [17] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition\u201d, arXiv preprint arXiv:1512.03385, 2015. [18] P. F. Felzenszwalb and D. P. Huttenlocher, \u201cEfficient belief propagation for early vision\u201d, International journal of computer vision, 70(1):41\u201354, 2006. [19] A. Vedaldi and K. Lenc, \u201cMatconvnet: Convolutional neural networks for matlab\u201d, In Proceedings of the 23rd ACM international conference on Multimedia, pp. 689\u2013692. ACM, 2015.\n6 Journal of Advanced Computational Intelligence and Intelligent Informatics"
        }
    ],
    "title": "Image Crowd Counting Using Convolutional Neural Network and Markov Random Field",
    "year": 2017
}