{
    "abstractText": "Interacting systems are prevalent in nature, from dynamical systems in physics to complex societal dynamics. The interplay of components can give rise to complex behavior, which can often be explained using a simple model of the system\u2019s constituent parts. In this work, we introduce the neural relational inference (NRI) model: an unsupervised model that learns to infer interactions while simultaneously learning the dynamics purely from observational data. Our model takes the form of a variational auto-encoder, in which the latent code represents the underlying interaction graph and the reconstruction is based on graph neural networks. In experiments on simulated physical systems, we show that our NRI model can accurately recover ground-truth interactions in an unsupervised manner. We further demonstrate that we can find an interpretable structure and predict complex dynamics in real motion capture and sports tracking data.",
    "authors": [
        {
            "affiliations": [],
            "name": "Thomas Kipf"
        },
        {
            "affiliations": [],
            "name": "Ethan Fetaya"
        },
        {
            "affiliations": [],
            "name": "Kuan-Chieh Wang"
        },
        {
            "affiliations": [],
            "name": "Max Welling"
        },
        {
            "affiliations": [],
            "name": "Richard Zemel"
        }
    ],
    "id": "SP:ac5e53ae1a64e09440c95fd4e512ee2eee73b3e1",
    "references": [
        {
            "authors": [
                "A. Alahi",
                "K. Goel",
                "V. Ramanathan",
                "A. Robicquet",
                "F. Li",
                "S. Savarese"
            ],
            "title": "Social LSTM: human trajectory prediction in crowded spaces",
            "venue": "In Conference on Computer Vision and Pattern Recognition",
            "year": 2016
        },
        {
            "authors": [
                "D. Bahdanau",
                "K. Cho",
                "Y. Bengio"
            ],
            "title": "Neural machine translation by jointly learning to align and translate",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2015
        },
        {
            "authors": [
                "P.W. Battaglia",
                "R. Pascanu",
                "M. Lai",
                "D.J. Rezende",
                "K. Kavukcuoglu"
            ],
            "title": "Interaction networks for learning about objects, relations and physics",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2016
        },
        {
            "authors": [
                "J. Bruna",
                "W. Zaremba",
                "A. Szlam",
                "Y. LeCun"
            ],
            "title": "Spectral networks and locally connected networks on graphs",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2014
        },
        {
            "authors": [
                "M.B. Chang",
                "T. Ullman",
                "A. Torralba",
                "J.B. Tenenbaum"
            ],
            "title": "A compositional object-based approach to learning physical dynamics",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2017
        },
        {
            "authors": [
                "X. Chen",
                "D.P. Kingma",
                "T. Salimans",
                "Y. Duan",
                "P. Dhariwal",
                "J. Schulman",
                "I. Sutskever",
                "P. Abbeel"
            ],
            "title": "Variational lossy autoencoder",
            "venue": "In International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "H. Dai",
                "B. Dai",
                "L. Song"
            ],
            "title": "Discriminative embeddings of latent variable models for structured data",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2016
        },
        {
            "authors": [
                "M. Defferrard",
                "X. Bresson",
                "P. Vandergheynst"
            ],
            "title": "Convolutional neural networks on graphs with fast localized spectral filtering",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2016
        },
        {
            "authors": [
                "Y. Duan",
                "M. Andrychowicz",
                "B.C. Stadie",
                "J. Ho",
                "J. Schneider",
                "I. Sutskever",
                "P. Abbeel",
                "W. Zaremba"
            ],
            "title": "Oneshot imitation learning",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2017
        },
        {
            "authors": [
                "D.K. Duvenaud",
                "D. Maclaurin",
                "J. Aguilera-Iparraguirre",
                "R. G\u00f3mez-Bombarelli",
                "T. Hirzel",
                "A. Aspuru-Guzik",
                "R.P. Adams"
            ],
            "title": "Convolutional networks on graphs for learning molecular fingerprints",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2015
        },
        {
            "authors": [
                "V. Garcia",
                "J. Bruna"
            ],
            "title": "Few-shot learning with graph neural networks",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2018
        },
        {
            "authors": [
                "J. Gilmer",
                "S.S. Schoenholz",
                "P.F. Riley",
                "O. Vinyals",
                "G.E. Dahl"
            ],
            "title": "Neural message passing for quantum chemistry",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2017
        },
        {
            "authors": [
                "C. Granger"
            ],
            "title": "Investigating causal relations by econometric models and cross-spectral methods",
            "year": 1969
        },
        {
            "authors": [
                "N. Guttenberg",
                "N. Virgo",
                "O. Witkowski",
                "H. Aoki",
                "R. Kanai"
            ],
            "title": "Permutation-equivariant neural networks applied to dynamics prediction",
            "venue": "arXiv preprint arXiv:1612.04530,",
            "year": 2016
        },
        {
            "authors": [
                "W. Hamilton",
                "Z. Ying",
                "J. Leskovec"
            ],
            "title": "Inductive representation learning on large graphs",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2017
        },
        {
            "authors": [
                "R. Herzig",
                "M. Raboh",
                "G. Chechik",
                "J. Berant",
                "A. Globerson"
            ],
            "title": "Mapping images to scene graphs with permutation-invariant structured prediction",
            "year": 2018
        },
        {
            "authors": [
                "S. Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural computation,",
            "year": 1997
        },
        {
            "authors": [
                "Hoshen",
                "Y. Vain"
            ],
            "title": "Attentional multi-agent predictive modeling",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2017
        },
        {
            "authors": [
                "A. Jain",
                "A.R. Zamir",
                "S. Savarese",
                "A. Saxena"
            ],
            "title": "Structural-rnn: Deep learning on spatio-temporal graphs",
            "venue": "In IEEE Conference on Computer Vision and Pattern Recognition",
            "year": 2016
        },
        {
            "authors": [
                "E. Jang",
                "S. Gu",
                "B. Poole"
            ],
            "title": "Categorical Reparameterization with Gumbel-Softmax",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2017
        },
        {
            "authors": [
                "S. Kearnes",
                "K. McCloskey",
                "M. Berndl",
                "V. Pande",
                "P. Riley"
            ],
            "title": "Molecular graph convolutions: moving beyond fingerprints",
            "venue": "Journal of computer-aided molecular design,",
            "year": 2016
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2015
        },
        {
            "authors": [
                "D.P. Kingma",
                "M. Welling"
            ],
            "title": "Auto encoding variational bayes",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2014
        },
        {
            "authors": [
                "T.N. Kipf",
                "M. Welling"
            ],
            "title": "Semi-supervised classification with graph convolutional networks",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2017
        },
        {
            "authors": [
                "Y. Kuramoto"
            ],
            "title": "Self-entrainment of a population of coupled nonlinear oscillators",
            "venue": "In International Symposium on Mathematical Problems in Theoretical Physics. (Lecture Notes in Physics,",
            "year": 1975
        },
        {
            "authors": [
                "H.M. Le",
                "Y. Yue",
                "P. Carr",
                "P. Lucey"
            ],
            "title": "Coordinated multiagent imitation learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "Y. Li",
                "D. Tarlow",
                "M. Brockschmidt",
                "R. Zemel"
            ],
            "title": "Gated graph sequence neural networks",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2016
        },
        {
            "authors": [
                "Z. Lin",
                "M. Feng",
                "C. Nogueira dos Santos",
                "M. Yu",
                "B. Xiang",
                "B. Zhou",
                "Y. Bengio"
            ],
            "title": "A structured self-attentive sentence embedding",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2017
        },
        {
            "authors": [
                "S.W. Linderman",
                "R.P. Adams"
            ],
            "title": "Discovering latent network structure in point process data",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2014
        },
        {
            "authors": [
                "S.W. Linderman",
                "R.P. Adams",
                "J.W. Pillow"
            ],
            "title": "Bayesian latent structure discovery from multi-neuron recordings",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2016
        },
        {
            "authors": [
                "Luong",
                "M.-T",
                "H. Pham",
                "C.D. Manning"
            ],
            "title": "Effective approaches to attention-based neural machine translation",
            "venue": "In Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2015
        },
        {
            "authors": [
                "C.J. Maddison",
                "A. Mnih",
                "Y.W. Teh"
            ],
            "title": "The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2017
        },
        {
            "authors": [
                "F. Monti",
                "D. Boscaini",
                "J. Masci"
            ],
            "title": "Geometric deep learning on graphs and manifolds using mixture model CNNs",
            "venue": "In IEEE Conference on Computer Vision and Pattern Recognition",
            "year": 2017
        },
        {
            "authors": [
                "M. Niepert",
                "M. Ahmed",
                "K. Kutzkov"
            ],
            "title": "Learning convolutional neural networks for graphs",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2016
        },
        {
            "authors": [
                "A. Paszke",
                "S. Gross",
                "S. Chintala",
                "G. Chanan",
                "E. Yang",
                "Z. DeVito",
                "Z. Lin",
                "A. Desmaison",
                "L. Antiga",
                "A. Lerer"
            ],
            "title": "Automatic differentiation in PyTorch",
            "venue": "NIPS Autodiff Workshop,",
            "year": 2017
        },
        {
            "authors": [
                "D.J. Rezende",
                "S. Mohamed",
                "D. Wierstra"
            ],
            "title": "Stochastic backpropagation and approximate inference in deep generative models",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2014
        },
        {
            "authors": [
                "A. Santoro",
                "D. Raposo",
                "D.G.T. Barrett",
                "M. Malinowski",
                "R. Pascanu",
                "P. Battaglia",
                "T. Lillicrap"
            ],
            "title": "A simple neural network module for relational reasoning",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2017
        },
        {
            "authors": [
                "F. Scarselli",
                "M. Gori",
                "A.C. Tsoi",
                "M. Hagenbuchner",
                "G. Monfardini"
            ],
            "title": "The graph neural network model",
            "venue": "IEEE Trans. Neural Networks,",
            "year": 2009
        },
        {
            "authors": [
                "S. Sukhbaatar",
                "A. Szlam",
                "R. Fergus"
            ],
            "title": "Learning multiagent communication with backpropagation",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2016
        },
        {
            "authors": [
                "S. van Steenkiste",
                "M. Chang",
                "K. Greff",
                "J. Schmidhuber"
            ],
            "title": "Relational neural expectation maximization: Unsupervised discovery of objects and their interactions",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2018
        },
        {
            "authors": [
                "N. Watters",
                "D. Zoran",
                "T. Weber",
                "P. Battaglia",
                "R. Pascanu",
                "A. Tacchetti"
            ],
            "title": "Visual interaction networks: Learning a physics simulator from video",
            "venue": "In Advances in Neural Information Processing Systems (NIPS),",
            "year": 2017
        }
    ],
    "sections": [
        {
            "heading": "1. Introduction",
            "text": "A wide range of dynamical systems in physics, biology, sports, and other areas can be seen as groups of interacting components, giving rise to complex dynamics at the level of individual constituents and in the system as a whole. Modeling these type of dynamics is challenging: often, we only have access to individual trajectories, without knowledge of the underlying interactions or dynamical model.\nAs a motivating example, let us take the movement of basketball players on the court. It is clear that the dynamics of a single basketball player are influenced by the other players, and observing these dynamics as a human, we are\n*Equal contribution 1University of Amsterdam, Amsterdam, The Netherlands 2University of Toronto, Toronto, Canada 3Vector Institute, Toronto, Canada 4Canadian Institute for Advanced Research, Toronto, Canada. Correspondence to: Thomas Kipf <t.n.kipf@uva.nl>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nObserved dynamics Interaction graph\nFigure 1. Physical simulation of 2D particles coupled by invisible springs (left) according to a latent interaction graph (right). In this example, solid lines between two particle nodes denote connections via springs whereas dashed lines denote the absence of a coupling. In general, multiple, directed edge types \u2013 each with a different associated relation \u2013 are possible.\nable to reason about the different types of interactions that might arise, e.g. defending a player or setting a screen for a teammate. It might be feasible, though tedious, to manually annotate certain interactions given a task of interest. It is more promising to learn the underlying interactions, perhaps shared across many tasks, in an unsupervised fashion.\nRecently there has been a considerable amount of work on learning the dynamical model of interacting systems using implicit interaction models (Sukhbaatar et al., 2016; Guttenberg et al., 2016; Santoro et al., 2017; Watters et al., 2017; Hoshen, 2017; van Steenkiste et al., 2018). These models can be seen as graph neural networks (GNNs) that send messages over the fully-connected graph, where the interactions are modeled implicitly by the message passing function (Sukhbaatar et al., 2016; Guttenberg et al., 2016; Santoro et al., 2017; Watters et al., 2017) or with the help of an attention mechanism (Hoshen, 2017; van Steenkiste et al., 2018).\nIn this work, we address the problem of inferring an explicit interaction structure while simultaneously learning the dynamical model of the interacting system in an unsupervised way. Our neural relational inference (NRI) model learns the dynamics with a GNN over a discrete latent graph, and we perform inference over these latent variables. The inferred edge types correspond to a clustering of the interactions. Using a probabilistic model allows us to incorporate prior beliefs about the graph structure, such as sparsity, in a principled manner.\nar X\niv :1\n80 2.\n04 68\n7v 2\n[ st\nat .M\nL ]\n6 J\nun 2\n01 8\nIn a range of experiments on physical simulations, we show that our NRI model possesses a favorable inductive bias that allows it to discover ground-truth physical interactions with high accuracy in a completely unsupervised way. We further show on real motion capture and NBA basketball data that our model can learn a very small number of edge types that enable it to accurately predict the dynamics many time steps into the future."
        },
        {
            "heading": "2. Background: Graph Neural Networks",
            "text": "We start by giving a brief introduction to a recent class of neural networks that operate directly on graph-structured data by passing local messages (Scarselli et al., 2009; Li et al., 2016; Gilmer et al., 2017). We refer to these models as graph neural networks (GNN). Variants of GNNs have been shown to be highly effective at relational reasoning tasks (Santoro et al., 2017), modeling interacting or multi-agent systems (Sukhbaatar et al., 2016; Battaglia et al., 2016), classification of graphs (Bruna et al., 2014; Duvenaud et al., 2015; Dai et al., 2016; Niepert et al., 2016; Defferrard et al., 2016; Kearnes et al., 2016) and classification of nodes in large graphs (Kipf & Welling, 2017; Hamilton et al., 2017). The expressive power of GNNs has also been studied theoretically in (Zaheer et al., 2017; Herzig et al., 2018).\nGiven a graph G = (V, E) with vertices v \u2208 V and edges e = (v, v\u2032) \u2208 E 1, we define a single node-to-node message passing operation in a GNN as follows, similar to Gilmer et al. (2017):\nv\u2192e : hl(i,j) = f l e([h l i,h l j ,x(i,j)]) (1)\ne\u2192v : hl+1j = f l v([ \u2211 i\u2208Nj h l (i,j),xj ]) (2)\nwhere hli is the embedding of node vi in layer l, h l (i,j) is an embedding of the edge e(i,j), and xi and x(i,j) summarize initial (or auxiliary) node and edge features, respectively (e.g. node input and edge type). Nj denotes the set of indices of neighbor nodes connected by an incoming edge and [\u00b7, \u00b7] denotes concatenation of vectors. The functions fv and fe are node- and edge-specific neural networks (e.g. small MLPs) respectively (see Figure 2). Eqs. (1)\u2013(2) allow for the composition of models that map from edge to node representations or vice-versa via multiple rounds of message passing.\nIn the original GNN formulation from Scarselli et al. (2009) the node embedding hl(i,j) depends only on h l i, the embedding of the sending node, and the edge type, but not on hlj , the embedding of the receiving node. This is of course a special case of this formulation, and more recent works such as interaction networks (Battaglia et al., 2016) or message passing neural networks (Gilmer et al., 2017) are in line with our\n1Undirected graphs can be modeled by explicitly assigning two directed edges in opposite direction for each undirected edge.\nmore general formulation. We further note that some recent works factor f le(\u00b7) into a product of two separate functions, one of which acts as a gating or attention mechanism (Monti et al., 2017; Duan et al., 2017; Hoshen, 2017; Velic\u030ckovic\u0301 et al., 2018; Garcia & Bruna, 2018; van Steenkiste et al., 2018) which in some cases can have computational benefits or introduce favorable inductive biases."
        },
        {
            "heading": "3. Neural Relational Inference Model",
            "text": "Our NRI model consists of two parts trained jointly: An encoder that predicts the interactions given the trajectories, and a decoder that learns the dynamical model given the interaction graph.\nMore formally, our input consists of trajectories of N objects. We denote by xti the feature vector of object vi at time t, e.g. location and velocity. We denote by xt = {xt1, ...,xtN} the set of features of all N objects at time t, and we denote by xi = (x1i , ...,x T i ) the trajectory of object i, where T is the total number of time steps. Lastly, we mark the whole trajectories by x = (x1, ...,xT ). We assume that the dynamics can be modeled by a GNN given an unknown graph z where zij represents the discrete edge type between objects vi and vj . The task is to simultaneously learn to predict the edge types and learn the dynamical model in an unsupervised way.\nWe formalize our model as a variational autoencoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014) that maximizes the ELBO:\nL = Eq\u03c6(z|x)[log p\u03b8(x|z)]\u2212KL[q\u03c6(z|x)||p\u03b8(z)] (3)\nThe encoder q\u03c6(z|x) returns a factorized distribution of zij , where zij is a discrete categorical variable representing the edge type between object vi and vj . We use a one-hot representation of the K interaction types for zij .\nThe decoder\np\u03b8(x|z) = \u220fT t=1 p\u03b8(x t+1|xt, ...,x1, z) (4)\nmodels p\u03b8(xt+1|xt, ...,x1, z) with a GNN given the latent graph structure z.\nThe prior p\u03b8(z) = \u220f i 6=j p\u03b8(zij) is a factorized uniform distribution over edges types. If one edge type is \u201chard coded\u201d to represent \u201cnon-edge\u201d (no messages being passed along this edge type), we can use an alternative prior with higher probability on the \u201cnon-edge\u201d label. This will encourage sparser graphs.\nThere are some notable differences between our model and the original formulation of the VAE (Kingma & Welling, 2014). First, in order to avoid the common issue in VAEs of the decoder ignoring the latent code z (Chen et al., 2017), we train the decoder to predict multiple time steps and not a single step as the VAE formulation requires. This is necessary since interactions often only have a small effect in the time scale of a single time step. Second, the latent distribution is discrete, so we use a continuous relaxation in order to use the reparameterization trick. Lastly, we note that we do not learn the probability p(x1) (i.e. for t = 1) as we are interested in the dynamics and interactions, and this does not have any effect on either (but would be easy to include if there was a need).\nThe overall model is schematically depicted in Figure 3. In the following, we describe the encoder and decoder components of the model in detail."
        },
        {
            "heading": "3.1. Encoder",
            "text": "At a high level, the goal of the encoder is to infer pairwise interaction types zij given observed trajectories x = (x1, ...,xT ). Since we do not know the underlying graph, we can use a GNN on the fully-connected graph to predict the latent graph structure.\nMore formally, we model the encoder as q\u03c6(zij |x) = softmax(fenc,\u03c6(x)ij,1:K), where fenc,\u03c6(x) is a GNN acting on the fully-connected graph (without self-loops). Given input trajectories x1, ...,xK our encoder computes the following message passing operations:\nh1j = femb(xj) (5)\nv\u2192e : h1(i,j) = f 1 e ([h 1 i ,h 1 j ]) (6) e\u2192v : h2j = f1v ( \u2211 i 6=j h 1 (i,j)) (7)\nv\u2192e : h2(i,j) = f 2 e ([h 2 i ,h 2 j ]) (8)\nFinally, we model the edge type posterior as q\u03c6(zij |x) = softmax(h2(i,j)) where \u03c6 summarizes the parameters of the neural networks in Eqs. (5)\u2013(8). The use of multiple passes, two in the model presented here, allows the model to \u201cdisentangle\u201d multiple interactions while still using only binary terms. In a single pass, Eqs. (5)\u2013(6), the embedding h1(i,j) only depends on xi and xj ignoring interactions with other nodes, while h2j uses information from the whole graph.\nThe functions f(...) are neural networks that map between the respective representations. In our experiments we used either fully-connected networks (MLPs) or 1D convolutional networks (CNNs) with attentive pooling similar to (Lin et al., 2017) for the f(...) functions. See supplementary material for further details.\nWhile this model falls into the general framework presented in Sec. 3, there is a conceptual difference in how hl(i,j)\nare interpreted. Unlike in a typical GNN, the messages hl(i,j) are no longer considered just a transient part of the computation, but an integral part of the model that represents the edge embedding used to perform edge classification."
        },
        {
            "heading": "3.2. Sampling",
            "text": "It is straightforward to sample from q\u03c6(zij |x), however we cannot use the reparametrization trick to backpropagate though the sampling as our latent variables are discrete. A recently popular approach to handle this difficulty is to sample from a continuous approximation of the discrete distribution (Maddison et al., 2017; Jang et al., 2017) and use the repramatrization trick to get (biased) gradients from this approximation. We used the concrete distribution (Maddison et al., 2017) where samples are drawn as:\nzij = softmax((h 2 (i,j) + g)/\u03c4) (9)\nwhere g \u2208 RK is a vector of i.i.d. samples drawn from a Gumbel(0, 1) distribution and \u03c4 (softmax temperature) is a parameter that controls the \u201csmoothness\u201d of the samples. This distribution converges to one-hot samples from our categorical distribution when \u03c4 \u2192 0."
        },
        {
            "heading": "3.3. Decoder",
            "text": "The task of the decoder is to predict the future continuation of the interacting system\u2019s dynamics p\u03b8(xt+1|xt, ...,x1, z). Since the decoder is conditioned on the graph z we can in general use any GNN algorithm as our decoder.\nFor physics simulations the dynamics is Markovian p\u03b8(x\nt+1|xt, ...,x1, z) = p\u03b8(xt+1|xt, z), if the state is location and velocity and z is the ground-truth graph. For this reason we use a GNN similar to interaction networks; unlike interaction networks we have a separate neural network for each edge type. More formally:\nv\u2192e : h\u0303t(i,j) = \u2211 k zij,kf\u0303 k e ([x t i,x t j ]) (10)\ne\u2192v : \u00b5t+1j = x t j + f\u0303v( \u2211 i 6=j h\u0303 t (i,j)) (11)\np(xt+1j |x t, z) = N (\u00b5t+1j , \u03c3 2I) (12)\nNote that zij,k denotes the k-th element of the vector zij and \u03c32 is a fixed variance. When zij,k is a discrete one-hot sample the messages h\u0303t(i,j) are f\u0303 k e ([x t i,x t j ]) for the selected edge type k, and for the continuous relaxation we get a weighted sum. Also note that since in Eq. 11 we add the present state xtj our model only learns the change in state \u2206xtj ."
        },
        {
            "heading": "3.4. Avoiding degenerate decoders",
            "text": "If we look at the ELBO, Eq. 3, the reconstruction loss term has the form \u2211T t=1 log[p(x t|xt\u22121, z)] which involves only\nsingle step predictions. One issue with optimizing this objective is that the interactions can have a small effect on short-term dynamics. For example, in physics simulations a fixed velocity assumption can be a good approximation for a short time period. This leads to a sub-optimal decoder that ignores the latent edges completely and achieves only a marginally worse reconstruction loss.\nWe address this issue in two ways: First, we predict multiple steps into the future, where a \u201cdegenerate\u201d decoder (which ignores the latent edges) would perform much worse. Second, instead of having one neural network that computes the messages given [xti,x t j , zij ], as was done in (Battaglia et al., 2016), we have a separate MLP for each edge type. This makes the dependence on the edge type more explicit and harder to be ignored by the model.\nPredicting multiple steps is implemented by replacing the correct input xt, with the predicted mean \u00b5t for M steps (we used M = 10 in our experiments), then feed in the correct previous step and reiterate. More formally, if we denote our decoder as \u00b5t+1j = fdec(x t j) then we have:\n\u00b52j = fdec(x 1 j )\n\u00b5t+1j = fdec(\u00b5 t j) t = 2, . . . ,M\n\u00b5M+2j = fdec(x M+1 j )\n\u00b5t+1j = fdec(\u00b5 t j) t = M + 2, . . . , 2M\n\u00b7 \u00b7 \u00b7\nWe are backpropagating through this whole process, and since the errors accumulate for M steps the degenerate decoder is now highly suboptimal."
        },
        {
            "heading": "3.5. Recurrent decoder",
            "text": "In many applications the Markovian assumption used in Sec. 3.3 does not hold. To handle such applications we use a recurrent decoder that can model p\u03b8(xt+1|xt, ...,x1, z). Our recurrent decoder adds a GRU (Cho et al., 2014) unit to the GNN message passing operation. More formally:\nv\u2192e : h\u0303t(i,j) = \u2211 k zij,kf\u0303 k e ([h\u0303 t i, h\u0303 t j ]) (13)\ne\u2192v : MSGtj = \u2211 i 6=j h\u0303 t (i,j) (14)\nh\u0303t+1j = GRU([MSG t j ,x t j ], h\u0303 t j) (15)\n\u00b5t+1j = x t j + fout(h\u0303 t+1 j ) (16)\np(xt+1|xt, z) = N (\u00b5t+1, \u03c32I) (17)\nThe input to the message passing operation is the recurrent hidden state at the previous time step. fout denotes an output transformation, modeled by a small MLP. For each node vj the input to the GRU update is the concatenation of the aggregated messages MSGt+1j , the current input x t+1 j , and the previous hidden state h\u0303tj .\nIf we wish to predict multiple time steps in the recurrent setting, the method suggested in Sec. 3.4 will be problematic. Feeding in the predicted (potentially incorrect) path and then periodically jumping back to the true path will generate artifacts in the learned trajectories. In order to avoid this issue we provide the correct input xtj in the first (T \u2212M) steps, and only utilize our predicted mean \u00b5tj as input at the last M time steps."
        },
        {
            "heading": "3.6. Training",
            "text": "Now that we have described all the elements, the training goes as follows: Given training example x we first run the encoder and compute q\u03c6(zij |x), then we sample zij from the concrete reparameterizable approximation of q\u03c6(zij |x). We then run the decoder to compute \u00b52, ...,\u00b5T . The ELBO objective, Eq. 3, has two terms: the reconstruction error Eq\u03c6(z|x)[log p\u03b8(x|z)] and KL divergence KL[q\u03c6(z|x)||p\u03b8(z)]. The reconstruction error is estimated by:\n\u2212 \u2211 j T\u2211 t=2 ||xtj \u2212 \u00b5tj ||2 2\u03c32 + const (18)\nwhile the KL term for a uniform prior is just the sum of entropies (plus a constant):\u2211\ni 6=j\nH(q\u03c6(zij |x)) + const. (19)\nAs we use a reparameterizable approximation, we can compute gradients by backpropagation and optimize."
        },
        {
            "heading": "4. Related Work",
            "text": "Several recent works have studied the problem of learning the dynamics of a physical system from simulated trajectories (Battaglia et al., 2016; Guttenberg et al., 2016; Chang et al., 2017) and from generated video data (Watters et al., 2017; van Steenkiste et al., 2018) with a graph neural network. Unlike our work they either assume a known graph structure or infer interactions implicitly.\nRecent related works on graph-based methods for human motion prediction include (Alahi et al., 2016) where the graph is not learned but is based on proximity and (Le et al., 2017) tries to cluster agents into roles.\nA number of recent works (Monti et al., 2017; Duan et al., 2017; Hoshen, 2017; Velic\u030ckovic\u0301 et al., 2018; Garcia & Bruna, 2018; van Steenkiste et al., 2018) parameterize messages in GNNs with a soft attention mechanism (Luong et al., 2015; Bahdanau et al., 2015). This equips these models with the ability to focus on specific interactions with neighbors when aggregating messages. Our work is different from this line of research, as we explicitly perform inference over the latent graph structure. This allows for the\nincorporation of prior beliefs (such as sparsity) and for an interpretable discrete structure with multiple relation types.\nThe problem of inferring interactions or latent graph structure has been investigated in other settings in different fields. For example, in causal reasoning Granger causality (Granger, 1969) infers causal relations. Another example from computational neuroscience is (Linderman et al., 2016; Linderman & Adams, 2014) where they infer interactions between neural spike trains."
        },
        {
            "heading": "5. Experiments",
            "text": "Our encoder implementation uses fully-connected networks (MLPs) or 1D CNNs with attentive pooling as our message passing function. For our decoder we used fully-connected networks or alternatively a recurrent decoder. Optimization was performed using the Adam algorithm (Kingma & Ba, 2015). We provide full implementation details in the supplementary material. Our implementation uses PyTorch (Paszke et al., 2017) and is available online2."
        },
        {
            "heading": "5.1. Physics simulations",
            "text": "We experimented with three simulated systems: particles connected by springs, charged particles and phase-coupled oscillators (Kuramoto model) (Kuramoto, 1975). These settings allow us to attempt to learn the dynamics and interactions when the interactions are known. These systems, controlled by simple rules, can exhibit complex dynamics. For the springs and Kuramoto experiments the objects do or do not interact with equal probability. For the charged particles experiment they attract or repel with equal probability. Example trajectories can be seen in Fig. 4. We generate 50k training examples, and 10k validation and test examples for all tasks. Further details on the data generation and implementation are in the supplementary material.\nWe note that the simulations are differentiable and so we can use it as a ground-truth decoder to train the encoder. The charged particles simulation, however, suffers from instabil-\n2https://github.com/ethanfetaya/nri\nity which led to some performance issues when calculating gradients; see supplementary material for further details. We used an external code base (Laszuk, 2017) for stable integration of the Kuramoto ODE and therefore do not have access to gradient information in this particular simulation.\nResults We ran our NRI model on all three simulated physical systems and compared our performance, both in future state prediction and in accuracy of estimating the edge type in an unsupervised manner.\nFor edge prediction, we compare to the \u201cgold standard\u201d i.e. training our encoder in a supervised way given the ground-truth labels. We also compare to the following baselines: Our NRI model with the ground-truth simulation decoder, NRI (sim.), and two correlation based baselines,\nCorr. (path) and Corr. (LSTM). Corr. (path) estimates the interaction graph by thresholding the matrix of correlations between trajectory feature vectors. Corr. (LSTM) trains an LSTM (Hochreiter & Schmidhuber, 1997) with shared parameters to model each trajectory individually and calculates correlations between the final hidden states to arrive at an interaction matrix after thresholding. We provide further details on these baselines in the supplementary material.\nResults for the unsupervised interaction recovery task are summarized in Table 1 (average over 5 runs and standard error). As can be seen, the unsupervised NRI model, NRI (learned), greatly surpasses the baselines and recovers the ground-truth interaction graph with high accuracy on most tasks. For the springs model our unsupervised method is comparable to the supervised \u201cgold standard\u201d benchmark. We note that our supervised baseline is similar to the work by (Santoro et al., 2017), with the difference that we perform multiple rounds of message passing in the graph. Additional results on experiments with more than two edge types and non-interacting particles are described in the supplementary material.\nFor future state prediction we compare to the static baseline, i.e. xt+1 = xt, two LSTM baselines, and a full graph baseline. One LSTM baseline, marked as \u201csingle\u201d, runs a separate LSTM (with shared weights) for each object. The second, marked as \u201cjoint\u201d concatenates all state vectors and feeds it into one LSTM that is trained to predict all future states simultaneously. Note that the latter will only be able to operate on a fixed number of objects (in contrast to the other models).\nIn the full graph baseline, we use our message passing decoder on the fully-connected graph without edge types, i.e. without inferring edges. This is similar to the model\nused in (Watters et al., 2017). We also compare to the \u201cgold standard\u201d model, denoted as NRI (true graph), which is training only a decoder using the ground-truth graph as input. The latter baseline is comparable to previous works such as interaction networks (Battaglia et al., 2016).\nIn order to have a fair comparison, we generate longer test trajectories and only evaluate on the last part unseen by the encoder. Specifically, we run the encoder on the first 49 time steps (same as in training and validation), then predict with our decoder the following 20 unseen time steps. For the LSTM baselines, we first have a \u201cburn-in\u201d phase where we feed the LSTM the first 49 time steps, and then predict the next 20 time steps. This way both algorithms have access to the first 49 steps when predicting the next 20 steps. We show mean squared error (MSE) results in Table 2, and note that our results are better than using LSTM for long term prediction. Example trajectories predicted by our NRI (learned) model for up to 50 time steps are shown in Fig. 5.\nFor the Kuramoto model, we observe that the LSTM baselines excel at smoothly continuing the shape of the waveform for short time frames, but fail to model the long-term dynamics of the interacting system. We provide further qualitative analysis for these results in the supplementary material.\nIt is interesting to note that the charged particles experiment achieves an MSE score which is on par with the NRI model\ngiven the true graph, while only predicting 82.6% of the edges accurately. This is explained by the fact that far away particles have weak interactions, which have only small effects on future prediction. An example can be seen in Fig. 5 in the top row where the blue particle is repelled instead of being attracted."
        },
        {
            "heading": "5.2. Motion capture data",
            "text": "The CMU Motion Capture Database (CMU, 2003) is a large collection of motion capture recordings for various tasks (such as walking, running, and dancing) performed by human subjects. We here focus on recorded walking motion data of a single subject (subject #35). The data is in the form of 31 3D trajectories, each tracking a single joint. We split the different walking trials into non-overlapping training (11 trials), validation (4 trials) and test sets (7 trials). We provide both position and velocity data. See supplementary material for further details. We train our NRI model with an MLP encoder and RNN decoder on this data using 2 or 4 edge types where one edge type is \u201chard-coded\u201d as non-edge, i.e. messages are only passed on the other edge types. We found that experiments with 2 and 4 edge types give almost identical results, with two edge types being comparable in capacity to the fully connected graph baseline while four edge types (with sparsity prior) are more interpretable and allow for easier visualization.\nDynamic graph re-evaluation We find that the learned graph depends on the particular phase of the motion (Fig. 7), which indicates that the ideal underlying graph is dynamic. To account for this, we dynamically re-evaluate the NRI encoder for every time step during testing, effectively resulting in a dynamically changing latent graph that the decoder can utilize for more accurate predictions.\nResults The qualitative results for our method and the same baselines used in Sec. 5.1 can be seen in Fig. 6. As one can see, we outperform the fully-connected graph setting in long-term predictions, and both models outperform the LSTM baselines. Dynamic graph re-evaluation significantly\nimproves predictive performance for this dataset compared to a static baseline. One interesting observation is that the skeleton graph is quite suboptimal, which is surprising as the skeleton is the \u201cnatural\u201d graph. When examining the edges found by our model (trained with 4 edge types and a sparsity prior) we see an edge type that mostly connects a hand to other extremities, especially the opposite hand, as seen in Fig. 7. This can seem counter-intuitive as one might assume that the important connections are local, however we note that some leading approaches for modeling motion capture data (Jain et al., 2016) do indeed include hand to hand interactions."
        },
        {
            "heading": "5.3. Pick and Roll NBA data",
            "text": "The National Basketball Association (NBA) uses the SportVU tracking system to collect player tracking data, where each frame contains the location of all ten players and the ball. Similar to our previous experiments, we test our model on the task of future trajectory prediction. Since the interactions between players are dynamic, and our current formulation assumes fixed interactions during training, we focus on the short Pick and Roll (PnR) instances of the games. PnR is one of the most common offensive tactics in the NBA where an offensive player sets a screen for the ball handler, attempting to create separation between the ball handler and his matchup.\nWe extracted 12k segments from the 2016 season and used 10k, 1k, 1k for training, validation, and testing respectively. The segments are 25 frames long (i.e. 4 seconds) and consist of only 5 nodes: the ball, ball hander, screener, and defensive matchup for each of the players.\n4The first edge type is \u201chard-coded\u201d as non-edge and was trained with a prior probability of 0.91. All other edge types received a prior of 0.03 to favor sparse graphs that are easier to visualize. We visualize test data not seen during training.\nWe trained a CNN encoder and a RNN decoder with 2 edge types. For fair comparison, and because the trajectory continuation is not PnR anymore, the encoder is trained on only the first 17 time steps (as deployed in testing). Further details are in the supplementary material. Results for test MSE are shown in Figure 6. Our model outperforms a baseline LSTM model, and is on par with the full graph.\nTo understand the latent edge types we show in Fig. 8 how they are distributed between the players and the ball. As we can see, one edge type mostly connects ball and ball handler (off-ball) to all other players, while the other is mostly inner connections between the other three players. As the ball and ball handler are the key elements in the PnR play, we see that our model does learn an important semantic structure by separating them from the rest."
        },
        {
            "heading": "6. Conclusion",
            "text": "In this work we introduced NRI, a method to simultaneously infer relational structure while learning the dynamical model of an interacting system. In a range of experiments with physical simulations we demonstrate that our NRI model is highly effective at unsupervised recovery of ground-truth interaction graphs. We further found that it can model the dynamics of interacting physical systems, of real motion tracking and of sports analytics data at a high precision, while learning reasonably interpretable edge types.\nMany real-world examples, in particular multi-agent systems such as traffic, can be understood as an interacting system where the interactions are dynamic. While our model is trained to discover static interaction graphs, we demonstrate that it is possible to apply a trained NRI model to this evolving case by dynamically re-estimating the latent graph. Nonetheless, our solution is limited to static graphs during training and future work will investigate an extension of the NRI model that can explicitly account for dynamic latent interactions even at training time."
        },
        {
            "heading": "Acknowledgements",
            "text": "The authors would like to thank the Toronto Raptors and the NBA for the use of the SportVU data. We would further like to thank Christos Louizos and Elise van der Pol for helpful discussions. This project is supported by the SAP Innovation Center Network."
        },
        {
            "heading": "A. Further experimental analysis",
            "text": ""
        },
        {
            "heading": "A.1. Kuramoto LSTM vs. NRI comparison",
            "text": "From the results in our main paper it became evident that a simple LSTM model excels at predicting the dynamics of a network of phase-coupled oscillators (Kuramoto model) for short periods of time, while predictive performance deteriorates for longer sequences. It is interesting to compare the qualitative predictive behavior of this fully recurrent model with our NRI (learned) model that models the state xt+1 at time t+ 1 solely based on the state xt at time t and the learned latent interaction graph. In Fig. 9 we provide visualizations of model predictions for the LSTM (joint) and the NRI (learned) model, compared to the ground truth continuation of the simulation.\nIt can be seen that the LSTM model correctly captures the shape of the sinusoidal waveform but fails to model the phase dynamics that arise due to the interactions between the oscillators. Our NRI (learned) model captures the qualitative behavior of the original coupled model at a very high precision and only in some cases slightly misses the phase dynamics (e.g. in the purple and green curve in the lower right plot). The LSTM model rarely matches the phase of the ground truth trajectory in the last few time steps and often completely goes \u201cout of sync\u201d by up to half a wavelength.\nA.2. Spring simulation variants\nIn addition to the experiments presented in the main paper, we analyze the following two variants of the spring simulation experimental setting: i) we test a trained model on completely non-interacting (free-floating) particles, and ii) we add a third edge type with a lower coupling constant.\nTo test whether our model can infer an empty graph, we create a test set of 1000 simulations with 5 non-interacting particles and test an unsupervised NRI model which was trained on the spring simulation dataset with 5 particles as before. We find that it achieves an accuracy of 98.4% in identifying \u201dno interaction\u201d edges (i.e. the empty graph).\nThe last variant explores a simulation with more than two known edge types. We follow the same procedure for the spring simulation with 5 particles as before with the exception of adding an additional edge type with coupling constant kij = 0.5 (all three edge types are sampled with equal probability). We fit an unsupervised NRI model to this data (K = 3 in this case, other settings as before) and find that it achieves an accuracy of 99.2% in discovering the correct edge types.\nA.3. Motion capture visualizations\nIn Fig. 10 we visualize predictions of a trained NRI model with learned latent graph for the motion capture dataset. We show 30 predicted time steps of future movement, conditioned on 49 time steps that are provided as ground truth to the model. It can be seen that the model can capture the overall form of the movement with high precision. Mistakes (e.g. the misplaced toe node in frame 30) are possible due to the accumulation of small errors when predicting over long sequences with little chance of recovery. Curriculum learning schemes where noise is gradually added to training sequences can potentially alleviate this issue."
        },
        {
            "heading": "A.4. NBA visualizations",
            "text": "We show examples of three pick and roll trajectories in Fig. 11. In the left column we show the ground truth, in the middle we show our prediction and in the right we show the edges that where sampled by our encoder. As we can see even when our model does not predict the true future path, which is extremely challenging for this data, it still makes semantically reasonable predictions. For example in the middle row it predicts that the player defending the ball handler passes between him and the screener (going over the screen) which is a reasonable outcome even though in reality the defenders switched players."
        },
        {
            "heading": "B. Simulation data",
            "text": ""
        },
        {
            "heading": "B.1. Springs model",
            "text": "We simulate N \u2208 {5, 10} particles (point masses) in a 2D box with no external forces (besides elastic collisions with the box). We randomly connect, with probability 0.5, each pair of particles with a spring. The particles connected by springs interact via forces given by Hooke\u2019s law Fij = \u2212k(ri \u2212 rj) where Fij is the force applied to particle vi by particle vj , k is the spring constant and ri is the 2D location vector of particle vi. The initial location is sampled from a Gaussian N (0, 0.5), and the initial velocity is a random vector of norm 0.5. Given the initial locations and velocity we can simulate the trajectories by solving Newton\u2019s equations of motion PDE. We do this by leapfrog integration using a step size of 0.001 and then subsample each 100 steps to get our training and testing trajectories.\nWe note that since the leapfrog integration is differentiable, we are able to use it as a ground-truth decoder and backpropagate through it to train the encoder. We implemented the leapfrog integration in PyTorch, which allows us to compare model performance with a learned decoder versus the ground-truth simulation decoder.\nB.2. Charged particles model\nSimilar to the springs model, we simulate N \u2208 {5, 10} particles in a 2D box, but instead of springs now our particles carry positive or negative charges qi \u2208 {\u00b1q}, sampled with uniform probability, and interact via Coulomb forces: Fij = C \u00b7 sign(qi \u00b7 qj) ri\u2212rj||ri\u2212rj ||3 where C is some constant. Unlike the springs simulations, here every two particles interact, although the interaction might be weak if they stay far apart, but they can either attract or repel each other.\nSince the forces diverge when the distance between particles goes to zero, this can cause issues when integrating with a fixed step size. The problem might be solved by using a much smaller step size, but this would slow the generation considerably. To circumvent this problem, we clip the forces to some maximum absolute value. While not being exactly physically accurate, the trajectories are indistinguishable to a human observer and the generation process is now stable.\nThe force clipping does, however, create a problem for the simulation ground-truth decoder, as gradients become zero when the forces are clipped during the simulation. We attempted to fix this by using \u201csoft\u201d clipping with a softplus(x) = log(1 + ex) function in the differentiable simulation decoder, but this similarly resulted in vanishing gradients once the model gets stuck in an unfavorable regime with large forces."
        },
        {
            "heading": "B.3. Phase-coupled oscillators",
            "text": "The Kuramoto model is a nonlinear system of phase-coupled oscillators that can exhibit a range of complicated dynamics\nbased on the distribution of the oscillators\u2019 internal frequencies and their coupling strengths. We use the common form for the Kuramoto model given by the following differential equation:\nd\u03c6i dt = \u03c9i + \u2211 j 6=i kij sin(\u03c6i \u2212 \u03c6j) (20)\nwith phases \u03c6i, coupling constants kij , and intrinsic frequencies \u03c9i. We simulate 1D trajectories by solving Eq. (20) with a fourth-order Runge-Kutta integrator with step size 0.01.\nWe simulate N \u2208 {5, 10} phase-coupled oscillators in 1D with intrinsic frequencies \u03c9i and initial phases \u03c6t=1i sampled uniformly from [1, 10) and [0, 2\u03c0), respectively. We randomly, with probability of 0.5, connect pairs of oscillators vi and vj (undirected) with a coupling constant kij = 1. All other coupling constants are set to 0. We subsample the simulated \u03c6i by a factor of 10 and create trajectories xi by concatenating d\u03c6idt , sin\u03c6i, and the intrinsic frequencies \u03c9i (copied for every time step as \u03c9i are static).\nC. Implementation details We will describe here the details of our encoder and decoder implementations.\nC.1. Vectorized implementation\nThe message passing operations v\u2192e and v\u2192e can be evaluated in parallel for all nodes (or edges) in the graph and allow for an efficient vectorized implementation. More specifi-\ncally, the node-to-edge message passing function fv\u2192e can be vectorized as:\nH1e = fe([M in v\u2192eH 1 v,M out v\u2192eH 1 v]) (21)\nwith Hv = [h>1 ,h > 2 , . . . ,h > N ] > \u2208 RN\u00d7F and He \u2208 RE\u00d7F defined analogously (layer index omitted), where F and E are the total number of features and edges, respectively. (\u00b7)> denotes transposition. Both message passing matrices Mv\u2192e \u2208 RE\u00d7N are dependent on the graph structure and can be computed in advance if the underlying graph is static. Minv\u2192e is a sparse binary matrix with M in v\u2192e,ij = 1 when the j-th node is connected to the i-th edge (arbitrary ordering) via an incoming link and 0 otherwise. Moutv\u2192e is defined analogously for outgoing edges.\nSimilarly, we can vectorize the edge-to-node message passing function fe\u2192v as:\nH2v = fv(M in e\u2192vH 1 e) (22)\nwith Mine\u2192v = (M in v\u2192e) >. For large sparse graphs (e.g. by constraining interactions to nearest neighbors), it can be beneficial to make use of sparse-dense matrix multiplications, effectively allowing for an O(E) algorithm."
        },
        {
            "heading": "C.2. MLP Encoder",
            "text": "The basic building block of our MLP encoder is a 2-layer MLP with hidden and output dimension of 256, with batch normalization, dropout, and ELU activations. Given this, the forward model for our encoder is given by the code snippet in Fig. 12. The node2edge module returns for each edge\nthe concatenation of the receiver and sender features. The edge2node module accumulates all incoming edge features via a sum.\nx = self.mlp1(x) # 2\u2212layer ELU net per node x = self.node2edge(x) x = self.mlp2(x) x skip = x\nx = self.edge2node(x) x = self.mlp3(x) x = self.node2edge(x) x = torch.cat((x, x skip), dim=2) x = self.mlp4(x) return self.fully connected out(x)\nFigure 12. PyTorch code snippet of the MLP encoder forward pass."
        },
        {
            "heading": "C.3. CNN Encoder",
            "text": "The CNN encoder uses another block which performs 1D convolutions with attention. This allows for encoding with changing trajectory size, and is also appropriate for tasks like the charged particle simulations when the interaction can be strong for a small fraction of time. The forward computation of this module is presented in Fig. 13 and the overall decoder in Fig. 14."
        },
        {
            "heading": "C.4. MLP Decoder",
            "text": "In Fig. 15 we present the code for a single time-step prediction using our MLP decoder for Markovian data.\n# CNN block # inputs is of shape ExFxT, E: number of edges, # T: sequence length, F: num. features x = F.relu(self.conv1(inputs)) x = self.batch norm1(x) x = self.pool(x) x = F.relu(self.conv2(x)) x = self.batch norm2(x) out = self.conv out(x) attention = softmax(self.conv attn(x), axis=2)\nout = (out \u2217 attention).mean(dim=2) return out\nFigure 13. PyTorch code snippet of the CNN block forward pass, used in the CNN encoder.\n# CNN encoder x = self.node2edge(x) x = self.cnn(x) # CNN block from above x = self.mlp1(x) # 2\u2212layer ELU net per node x skip = x\nx = self.edge2node(x) x = self.mlp2(x) x = self.node2edge(x) x = torch.cat((x, x skip), dim=2) x = self.mlp3(x) return self.fully connected out(x)\nFigure 14. PyTorch code snippet of the CNN encoder model forward pass.\n# Single prediction step pre msg = self.node2edge(inputs)\n# Run separate MLP for every edge type # For non\u2212edge: start idx=1, otherwise 0 for i in range(start idx, num edges):\nmsg = F.relu(self.msg fc1[i](pre msg)) msg = F.relu(self.msg fc2[i](msg)) msg = msg \u2217 edge type[:, :, :, i:i + 1] all msgs += msg\n# Aggregate all msgs to receiver agg msgs = self.edge2node(all msgs) hidden = torch.cat([inputs, agg msgs], dim=\u22121)\n# Output MLP pred = F.relu(self.out fc1(hidden) pred = F.relu(self.out fc2(pred) pred = self.out fc3(pred)\nreturn inputs + pred\nFigure 15. PyTorch code snippet of a single prediction step in the MLP decoder."
        },
        {
            "heading": "C.5. RNN Decoder",
            "text": "The RNN decoder adds a GRU style update to the single step prediction, the code snippet for the GRU module is presented in Fig. 16 and the overall RNN decoder in Fig. 17.\n# GRU block # Takes arguments: inputs, agg msgs, hidden r = F.sigmoid(self.input r(inputs) + self.hidden r(agg msgs)) i = F.sigmoid(self.input i(inputs) + self.hidden i(agg msgs)) n = F.tanh(self.input n(inputs) + r \u2217 self.hidden h(agg msgs)) hidden = (1 \u2212 i) \u2217 n + i \u2217 hidden return hidden\nFigure 16. PyTorch code snippet of a GRU block, used in the RNN decoder.\n# Single prediction step pre msg = self.node2edge(inputs)\n# Run separate MLP for every edge type # For non\u2212edge: start idx=1, otherwise 0 for i in range(start idx, num edges):\nmsg = F.relu(self.msg fc1[i](pre msg)) msg = F.relu(self.msg fc2[i](msg)) msg = msg \u2217 edge type[:, :, :, i:i + 1] # Average over types for stability all msgs += msg/(num edges\u2212start idx)\n# Aggregate all msgs to receiver agg msgs = self.edge2node(all msgs)\n# GRU\u2212style gated aggregation (see GRU block) hidden = self.gru(inputs, agg msgs, hidden)\n# Output MLP pred = F.relu(self.out fc1(hidden)) pred = F.relu(self.out fc2(pred)) pred = self.out fc3(pred)\n# Predict position/velocity difference pred = inputs + pred\nreturn pred, hidden\nFigure 17. PyTorch code snippet of a single prediction step in the RNN decoder."
        },
        {
            "heading": "D. Experiment details",
            "text": "All experiments were run using the Adam optimizer (Kingma & Ba, 2015) with a learning rate of 0.0005, decayed by a factor of 0.5 every 200 epochs. Unless otherwise noted, we train with a batch size of 128. The concrete distribution is used with \u03c4 = 0.5. During testing, we replace the concrete distribution with a categorical distribution to obtain\ndiscrete latent edge types. Physical simulation and sports tracking experiments were run for 500 training epochs. For motion capture data we used 200 training epochs, as models tended to converge earlier. We saved model checkpoints after every epoch whenever the validation set performance (measured by path prediction MSE) improved and loaded the best performing model for test set evaluation. We observed that using significantly higher learning rates than 0.0005 often produced suboptimal decoders that ignored the latent graph structure.\nD.1. Physics simulations experiments\nThe springs, charged particles and Kuramoto datasets each contain 50k training instances and 10k validation and test instances. Training and validation trajectories where of length 49 while test trajectories continue for another 20 time steps (50 for visualization). We train an MLP encoder for the springs experiment, and CNN encoder for the charged particles and Kuramoto experiments. All experiments used MLP decoders and two edge types. For the Kuramoto model experiments, we explicitly hard-coded the first edge type as a \u201cnon-edge\u201d, i.e. no messages are passed along edges of this type.\nAs noted previously, all of our MLPs have hidden and output dimension of 256. The overall input/output dimension of our model is 4 for the springs and charged particles experiments (2D position and velocity) and 3 for the Kuramoto model experiments (phase-difference, amplitude and intrinsic frequency). During training, we use teacher forcing in every 10-th time step (i.e. every 10th time step, the model receives a ground truth input, otherwise it receives its previous prediction as input). As we always have two edge types in these experiments and their ordering is arbitrary (apart from the Kuramoto model where we assign a special role to edge type 1), we choose the ordering for which the accuracy is highest."
        },
        {
            "heading": "D.1.1. BASELINES",
            "text": "Edge recovery experiments In edge recovery experiments, we report the following baselines along with the performance of our NRI (learned) model:\n\u2022 Corr. (path): We calculate a correlation matrix R, where Rij =\nCij\u221a CiiCjj with Cij being the covariance\nbetween all trajectories xi and xj (for objects vi and vj) in the training and validation sets. We determine an ideal threshold \u03b8 so that Aij = 1 if Rij > \u03b8 and Aij = 0 otherwise, based on predictive accuracy on the combined training and validation set. Aij denotes the presence of an interaction edge (arbitrary type) between object vi and vj . We repeat the same procedure for the absolute value of Rij , i.e. Aij = 1 if |Rij | > \u03b8\u2032\nand Aij = 0 otherwise. Lastly, we pick whichever of the two (\u03b8 or \u03b8\u2032) produced the best match with the ground truth graph (i.e. highest accuracy score) and report test set accuracy with this setting.\n\u2022 Corr. (LSTM): Here, we train a two-layer LSTM with shared parameters and 256 hidden units that models each trajectory individually. It is trained to predict the position and velocity for every time step directly and is conditioned on the previous time steps. The input to the model is passed through a two-layer MLP (256 hidden units and ReLU activations) before it is passed to the LSTM, similarly we pass the LSTM output (last time step) through a two-layer MLP (256 hidden units and ReLU activation on the hidden layer). We provide ground truth trajectory information as input at every time step. We train to minimize MSE between model prediction and ground truth path. We train this model for 10 epochs and finally apply the same correlation matrix procedure as in Corr. (path), but this time calculating correlations between the output of the second LSTM layer at the last time step (instead of using the raw trajectory features). The LSTM is only trained on the training set. The optimal correlation threshold is estimated using the combined training and validation set.\n\u2022 NRI (sim.): In this setting, we replace the decoder of the NRI model with the ground-truth simulator (i.e. the integrator of the Newtonian equations of motion). We implement both the charged particle and the springs simulator in PyTorch which gives us access to gradient information. We train the overall model with the same settings as the original NRI (learned) model by backpropagating directly through the simulator. We find that for the springs simulation, a single leap-frog integration step is sufficient to closely approximate the trajectory of the original simulation, which was generated with 100 leap-frog steps per time step. For the charged particle simulation, 100 leap-frog steps per time step are necessary to match the original trajectory when testing the simulation decoder in isolation. We find, however, that due to the force clipping necessary to stabilize the original charged particle simulation, gradients will often become zero, making model training difficult or infeasible.\n\u2022 Supervised: For this baseline, we train the encoder in isolation and provide ground-truth interaction graphs as labels. We train using a cross-entropy error and monitor the validation accuracy (edge prediction) for model checkpointing. We train with dropout of p = 0.5 on the hidden layer representation of every MLP in the encoder model, in order to avoid overfitting.\nPath prediction experiments Here, we use the following baselines along with our NRI (learned) model:\n\u2022 Static: This baseline simply copies the previous state vector xt+1 = xt.\n\u2022 LSTM (single): Same as the LSTM model in Corr. (LSTM), but trained to predict the state vector difference at every time step (as in the NRI model). Instead of providing ground truth input at every time step, we use the same training protocol as for an NRI model with recurrent decoder (see main paper).\n\u2022 LSTM (joint): This baseline differs from LSTM (single) in that it concatenates the input representations from all objects after passing them through the input MLP. This concatenated representation is fed into a single LSTM where the hidden unit number is multiplied by the number of objects\u2014otherwise same setting as LSTM (single). The output of the second LSTM layer at the last time step is then divided into vectors of same size, one for each object, and fed through the output MLP to predict the state difference for each object separately. LSTM (joint) is trained with same training protocol as the LSTM (single) model.\n\u2022 NRI (full graph): For this model, we keep the latent graph fixed (fully-connected on edge type 2; note that edge types are exclusive, i.e. edges of type 1 are not present in this case) and train the decoder in isolation in the otherwise same setting as the NRI (learned) model.\n\u2022 NRI (true graph): Here, we train the decoder in isolation and provide the ground truth interaction graph as latent graph representation.\nD.2. Motion capture data experiments\nOur extracted motion capture dataset has a total size of 8,063 frames for 31 tracked points each. We normalize all features (position/velocity) to maximum absolute value of 1. Training and validation set samples are 49 frames long (non-overlapping segments extracted from the respective trials). Test set samples are 99 frames long. In the main paper, we report results on the last 50 frames of this test set data.\nWe choose the same hyperparameter settings as in the physical simulation experiments, with the exception that we train models for 200 epochs and with a batch size of 8. Our model here uses an MLP encoder and an RNN decoder (as the dynamics are not Markovian). We further take samples from the discrete distribution during the forward pass in training and calculate gradients via the concrete relaxation. The baselines are identical to before (path prediction experiments for physical simulations) with the following\nexception: For LSTM (joint) we choose a smaller hidden layer size of 128 units and train with a batch size of 1, as the model did otherwise not fit in GPU memory."
        },
        {
            "heading": "D.3. NBA experiments",
            "text": "For the NBA data each example is a 25 step trajectory of a pick and roll (PnR) instance, subsampled from the original 25 frames-per-second SportVU data. Unlike the physical simulation where the dynamics of the interactions do not change over time and the motion capture data where the dynamics are approximately periodic, the dynamics here change considerably over time. The middle of the trajectory is, more or less, the pick and roll itself and the behavior before and after are quite different. This poses a problem for fair comparison, as it is problematic to evaluate on the next time steps, i.e. after the PnR event, since they are quite different from our training data. Therefore in test time we feed in the first 17 time-steps to the encoder and then predict the last 8 steps.\nIf we train the model normally as an autoencoder, i.e. feeding in the first N = 17 or 25 time-steps to the encoder and having the decoder predict the same N , then this creates a large difference between training and testing setting, resulting in poor predictive performance. This is expected, as a model trained with N = 17 never sees the post-PnR dynamics and the encoder trained with N = 25 has a much easier task than one trained on N = 17. Therefore in order for our training to be consistent with our testing, we feed during training the first 17 steps to the encoder and predict all 25 with the decoder.\nWe used a CNN encoder and RNN decoder with two edge types to have comparable capacity to the full graph model. If we \u201chard code\u201d one edge type to represent \u201cnon-edge\u201d then our model learns the full graph as all players are highly connected. We also experimented with 10 and 20 edge types which did not perform as well on validation data, probably due to over-fitting."
        }
    ],
    "title": "Neural Relational Inference for Interacting Systems",
    "year": 2018
}